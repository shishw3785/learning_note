git
	git log 显示最近到最远的提交日志

	HEAD -> 表示当前版本
	HEAD^  上一版本
	HEAD^^  上上版本

	指向版本
		git reset --hard commit_id
		git reset --hard HEAD^ 退回到上一版本

	查看提交历史,以便回到哪个版本
		git log

	要回到最新的版本就要指向最新的commit ID
		git reflog 查看命令历史


	工作区就是电脑上的目录，如learning目录，.git目录是版本库,暂存区就是index或stage.
		步聚
			git add 把文件添加到暂存区
			git commit 把文件从暂存区提交到当前分支(git创建版本库时自动创建了一个master分支)

			可以理解为工作区文件修改通通添加到暂存区，然后一次性提交所有修改到分支

	git跟踪并管理的是修改
	git commit 只负责把暂存区的修改提交到分区

	git checkout -- file   把文件在工作区的修改全部撤消
		file修改没添加到暂存区,checkout后file恢复成与版本库一样的状态
		file修改后已添加到暂存区,又对了file做修改, checkout后file恢得到添加到暂存区后的状态

	暂存区的修改撤消
		假如已经把readme.txt add到暂存区了
		git reset HEAD readme.txt #丢弃暂存区readme的修改
		然后就可以继续丢弃工作区的readme.txt


	删除文件
		本地删除test.txt,远程仓库删除文件 git rm test.txt,并且要commit
		如果误删除本地test.txt,可以git checkout -- test.txt恢复





	本地库关联远程仓库
		git remote add origin git@server-name:path/repo-name.git
		第一次推送
			git push -u origin master #之后推送不用-u

	本地克隆远程仓库
		git clone git@egegegegeeg.git
		clone支持https和ssh协议,ssh速度，https每次推送需要账密

	分支
		查看分支 git branch
		创建分支 git branch <name> 或 git switch <name>
		切换分支 git checkout <name> 或 git switch <name>
		创建加切换分支  git checkout <name> 或 git switch -c <name>
		合并分支到当前分支  git merge <name>
			如当前分支为master,合并dev到当前分支
			git merge dev
		删除分支 git branch -d <dev>

		冲突
			GIT无法自动合并分支时，必须先解决冲突文件(手动修改文件内容一样)。解决冲突后，先提交后再合并.

			git log --graph 查看分支合并图



linux
	目录权限
		rwx对于目录，内容是文件名。
			r 读到目录的文件名
			w 修改文件名(文件或目录),建立新的文件与目录，移动或更名
			x cd 能进入到目录里面





20200421
普通合并，不使用fast forward合并
master为主分支,dev分支有作了修改，切换回master后
git merge --no-ff -m "修改信息" dev

查看历史合并信息
git log --graph --pretty=oneline --abbrev-commit
#普通合并能看出分支合并信息, fast forward不行

保存现场
	如在dev分支上正在进行代码工作，此时master要改临时的bug，所以先要保存dev的工作现场(dev已添加修改到暂存区，不添加保存不了现场)
	git stash
	Saved working directory and index state WIP on dev: f52c633 add merge

	保存后就切换到master分支然后创建临时分支issue-1,在issu-1分支上修改完后再切回master分支普通合并issue分支

	然后再切换到dev分支
	git stash list 查看保存的工作现场

	恢复工作现场
		git stash pop #恢复的同时把stash内容也删除

	最后因为dev分支是从master出来的,dev分支上也同样有bug，此时需要把master修复的提效复制到dev
	git cherry-pick <commit ID>

强行删除没有合并的分支
	git branch -D commit_ID   #开发一个新的feature(功能)最好新建一个分支.若新分支修改完成后没有被合并到分支(如dev)就要删除，要加上 -D




推送分支
git push origin master #推送本地master分支到远程origin库
git push origin dev   #推送本地开发分支到远程origin库

本地创建和远程分支对应的分支，如dev分支#默认clone时只创建master对应
	创建dev对应
		git checkout -b dev origin/dev

	多人协作
		1 首先，先试图用git push origin 分支到远程仓库
		2 如果推送失败，则是因为远程仓库分比本地要新，则先git pull试图将远程库分支合并到本地
		3 如果合并有冲突，先解决冲突后在本地commit提交，最后就能push到远程分支

		如果git pull 提示no tracking information,则说明本地分支与远程会支的链路接关系没有创建。
			用命令git branch --set-upstream-to=origin/dev dev
			dev为分支

	标签
		git tag <tagname> 用于新建标签 ，默认最新HEAD，也可以指定COMMIT_ID
		git tag -a <tagname> -m "信息" 指定标签信息

		git tag #查看所有标签
		git show <tagname> #查看标签信息
		标签与commit_id挂钩,如果这个commit有master与dev分支，则两个分支都可以看到标签 

		推送一个本地tag到远程
			git push origin <tagname>
		推送全部未推送的标签到远程
			git push origin --tags
		本地删除一个标签 
			git tag -d <tagname>
		删除远程标签 
			先在本地删除
			git push origin :refs/tags/<tagname>
		分支与标签很像，但分支可以移动，标签不行

	.gitignore
		忽回文件原则
			1 忽略系统自动生成的文件，比如缩略图等
			2 忽略包含敏感信息文件，比如方账密或数据库文件
			3 忽略编译产生的中间文件，可执行文件

		如果你确实想添加该文件，可以用-f强制添加到Git：

		$ git add -f App.class
		或者你发现，可能是.gitignore写得有问题，需要找出来到底哪个规则写错了，可以用git check-ignore命令检查：

		$ git check-ignore -v App.class
		.gitignore:3:*.class	App.class


	git reset --hard commitid 指向某一版本
	git checkout -- file





20200420
监控主机看要被监控主机的地域来开设机房的机子，传输稳定减少变数
被监控机子要提供验收范围(port与服务)

windows设置远程桌面白名单
	入站规则先找到对应的PORT,然后
	在“作用域”中的“远程IP地址”，点击“添加”按钮，添加白名单ip，点击确定



20200425
mysql all数据库备份与还原
备份
	mysqldump -uroot -pabc123 --all-databases > all.sql
还原
	mysql -uroot -pabc123 < all.sql
bash
	\rm -r 目录  #\忽略掉alias的指定选项
	cp 链接文件 文件  #命令指行后的文件不是链路接文件而是被链路接指向的源文件
	cp -d 链接文件 文件 # 得出的文件也是链路接文件
	cp -a #将文件的所有属性一起复制

20200427
数据库用户，如果网站不是太重要，或是内部服务器，数据库的用户可以是 root

修改时区命令
	timedatectl
touch #创建空文件或修改文件时间
	touch 文件 #修改时间与读取时间与状态时间都会变成当前时间
	touch -d "2 days ago" 文件 #文件的读取与修改时间会变成2天前,状太时间为当时间

20200429
mysqldump -uroot -p -B database > database.sql
#使用-B的好处就是导出的数据库文件中已经存在创建库和使用库的语句，不需要手动在要还原的机子上创建库的操作，可直接还原。
还原
	mysq -u root -p '123456' < database.sql #还原时不需要指定恢复的数据库

linux
	查找etc目录下容量大于50K且小于60K的文件并ls -l查看详细信息
		find /etc -size +50k -a -size -60k -exec ls -l {} \;
	查找etc目录下容量大于1500K以及容量等于0的文件
		find /etc -size +1500k -o -size 0 -exec ls -l {} \;
		# -a 且 , -o 或
	查看文件的隐藏属性
		lsattr file
	设置隐藏属性
		chattr [+aiS]

	locate 文件 #locate通过数据库/var/lib/mlocate查找文件,不用找硬盘速度快

20200430
SUID
	文件具有suid权限时，代表当用户执行此二进制文件时会暂时具有文件拥有者的权限
SGID
	目录具有sgid时,代表用户在此目录下新建的文件的用户组会与该目录的组名相同
SBIT
	目录具有sbit时，代表该目录下用户建立的文件只有自己与root能删除
设置
	SUID 4
	SGID 2
	SBIT 1
	如 4775 #4为设置suid
	   7775 #设置 suid,sgid,sbit

计算机安全，通信
	截获
		被动攻击，如cain软件利用ARP欺骗把自身的mac地址(假网关地址)发给同网段各主机,这样同网段各主机发送报文都能截获，如user/pass
	篡改
		主动攻击,如cain软件利用arp欺骗把自身的mac地址(假网关地址)发给网段，各主机访问外网时cain提供假域名给各主机,cain主要去访问真域名，再把信息转给各主机，这是一种DNS劫持。
	中断
		后端主机控制大量肉鸡发送大量无用的数据包给服务器，占用下载带宽，使其正常服务不能使用.DDOS攻击
	伪造
		同一网段ip邦定mac来上网，若这一台机子关机，另一台机子可以有机会使用相网的ip上网，达到伪造的效果

磁盘/硬盘
	磁片
	主轴马达
	机械手臂与磁头

文件系统
	通常是一个分区对应一个文件系统，现在多数是一个挂载点对应一个文件系统
	一个文件有文件实际内容与文件的权限属性等相关的参数
	inode
		记录文件的权限与属性相关的参数，一个文件站用一个inode，同时记录该文件的实际数据所在的区块号码，有编号
	数据区块
		实际记录文件的内容，若文件太大会占用多个区块，有编号
	超级区块
		记录文件系统的整体信息，包括Inode与数据区块的总容量，使用量，剩余量，以及文件系统的格式与相关信息

	索引式文件系统
		通过Indode可以一口气读取所有的数据区块,读写性能较好
		FAT(u盘类)是非索引式文件系统，没有inode,每个区块的号码都记录在前一个区块中,不能一次性读取。所谓的碎片整理就是把太过于离散的区块整理集中。

	ext2文件系统
		文件系统一开始就会将inode和数据区块规划好，除非重新格式化，否则inode和数据区块是不会变的
		如果文件系统高达数百G，将所有的inode和数据区块放在一起不易管理，所以会有多个区块组(block group)

		文件系统最前面有一个启动扇区(boot sector),可以安装引导程序，我们可以安装不同的启动引导到别的的文件系统的的boot sector，这样就不用覆盖磁盘的唯一MBR，实现多引导
		区块组
			每个区块组都有独立的超级区块，Inode,数据区块

			数据区块
			inode table
				inode,记录区块号码可以有12个直接指向区块的号码，
				一个间接
					如果文件太,再拿一个区块来当作记录区块号码的记录区
				一个双间接，一个三间接
			inode对应表
				记录空白的与使用的In(空区块)ode,哪些可以使用哪些不可以使用
			区块对应表
				记录可使用的区块(空区块)，不可使用的区块
			文件系统描述
			超级区块
				事实上除了第一扇区会有超级区块外，后续的区块组不一定含有超级区块。若含有则是主要为第一个超级区块做备份

		目录
			linux下新建一个目录时，会分配一个Inode与至少一块区块给目录，inode记录目录相关的权限与属性，并可记录分配到哪块区块号码，而区块则是记录目录下的文件名与该文件名占用的Inode号码数据

		文件
			新建一个文件时，会分配一个inode与相对该文件大小的区块数量给文件

		/ 
			由于目录树是由根开始，因此系统通过挂载的信息可以找到挂载点的Inode号码，就能找到根目录的inode内容，再通过该inode读取根目录区块内的文件名数据，再一层一层往下读到正确的文件名

		日志文件系统
			inode对照表，数据块对照表，超级区块经常变动，称为元数据
			inode tabes，数据块区块称为数据存放区域
			万一如果出现停电或发生错误导致系统中断，数据存放区域与元数据产生不一致的情况，那么系统重新启动时就要通过超级区块和文件系统状态来进行数据一致性检查，浪费大量时间，所以就有日志文件系统的出现。

			日志文件系统，系统中规划了一个区块专门记录文件写入与修改的步聚，当数据出现不一致性时，只需检查该区块即可，不用针对整个文件系统检查。

		异步处理
			cpu处理文件时，文件要先放到内存中，如果编辑文件太大，因为内存比磁盘速度快，所以等待读写入磁盘的时间太久，没效率。
			异步处理就是当系统加载一个文件到内存后，如果该文件没有被修改，则内存区段的数据就设置为clean,若修改则设置为dirty,此时操作都还在内存中进行，并没有写入磁盘。系统会不定时的把内存中dirty的数据写入磁盘，保持数据一致性。也可以手动sync命令

			系统会将常用的数据放置到内存缓冲，加快文件系统的读写操作，所以Linux的物理内存都会被用光，正常现象，加速系统性能。


20200501
linux的内核通过VFS来管理读取文件系统

xfs	
	centos7.x默认的文件系统
	数据三个部分
		数据区(data section)
			与ext2的区块群组一样，不同的是xfs的inode与区块都是系统需要用到时动态配置产生，所以格式化操作超快
		文件系统登录区
			有点日志区块，还可以指定外部磁盘来作为xfs文件系统的日志区块
		实时运行区
			当有文件新建立时，xfs会在这个区段里面找一个到数个的extent区，将文件放置在这个区块内，等分配完毕后再写入到data section的inodae与区块中

20200504
硬链接
	不能跨文件系统
	不能跨接目录
		如果链接的比如是etc目录,那目录下的所有文件都要硬链路接，工作环境太过复杂

	硬链接就是多个文件名指向同一个Inode，文件系统的inode与数据区块一般是不会变化的

	创建硬链接
		ln /etc/crontab .  #创建硬链接到当前目录

	[root@localhost ~]# ls -il crontab /etc/crontab 
	4372557 -rw-r--r--. 2 root root 451 Jun 10  2014 crontab
	4372557 -rw-r--r--. 2 root root 451 Jun 10  2014 /etc/crontab
	第3个字段2，代表是有多少个文件名链路接到这个Inode

软链接（快捷方程式)
	符号链接就是建立一个独立的文件，而这个文件会让数据的读取指向它链接的那个文件的文件名

	创建软链
		ln -s /etc/crontab crontab2

		[root@localhost ~]# ll -i crontab2
		8414548 lrwxrwxrwx. 1 root root 12 Apr 30 00:48 crontab2 -> /etc/crontab

	当源文件被删除后，符号链接文件会打不开，实际上是找不到原始文件名而已

	符号链接所建立的文件为一个独立的新文件，所以会占用inode与区块

	目录链接数
		当我们建立一个新目录时，新的目录链接数为2，上层目录的链接数增加1

磁盘分区
	lsblk #列出系统上的所有磁盘列表
	blkid #列出设备的uuid参数， uuid全局唯一标识符，linux会将系统内所有的设备给于一个标识符，标识符可以拿来挂载或使用
	parted /dev/sda print   #列出磁盘的分区表类型与分区信息

	gdisk/fdisk /dev/sdb   #对/dev/sdb磁盘进行分区管理(增删等)，q退出不保存，注意不要去处理一个正在使用的分区

	一般先用lsblk找到磁盘，然后用parted找出分区格式(gpt or MBR), 再利用fdisk分区(MBR格式的话)

	用fdisk分好区并w保存后，分区表并没有立即更新，需要
		partprobe -s   #更新linux内核的分区信息

	查看内核分区的信息
		lsblk
		cat /proc/partitions

磁盘格式化(创建文件系统)
	mkfs.xfs /dev/sdb6  #一般使用默认参数就行，除非有其它额外的要求，如-f, 强制格式化,如果原来已有文件系统
	mkfs.ext4   

文件系统检验
	xfs_repair /dev/sdb4   #恢复命令,万一服务器停电或硬件软件出错导致文件系统发生错乱
		通常文件系统出问题时才使用(单人模式下)，正常状况使用此命令可能会造成系统损坏，且被检验的硬盘分区不能挂载，要在卸载状态下使用




20200505
挂载与卸载
	单一文件系统对应单一目录(挂载点)，目录应该是空目录才行，如果不是那原先存在目录下的文件在该目录被挂截之后会暂时先隐藏起来(并不是消失)，当目卸载之后才会看到

	mount #什么都不接就是列出目前挂载信息
	mount -a  #依照配置/etc/fstab的数据把所有没挂载的磁盘都挂载上来
	mount -t #指定挂载的文件系统种类。ceoto 7 会自动分析文件系统种类来尝试挂载设备(根据文件系统的超级区块与linux自己的驱动程序去测试)，测试成功则自动挂载.
	主要参考这两个文件来
		/etc/filesystems 系统指定的测试挂载文件系统类型的优先级
		/proc/filesystems linux系统已加载的文件系统类型 

	如何知道系统有没有相关的文件系统的驱动程序呢
		/lib/modules/$(uname -r)/kernel/fs/

	mount 文件系统 挂载点
	如  mount /dev/sdb6 /newfile
		mount UUID /newfile

	挂载cd/dvd, u盘(vfat格式)
		先blkid查看设备名称,再mount挂载,一般cd/dvd挂载后都是只能只读，使用率为100%，u盘最后是vfat格式,linux本身不支持ntfs格式，如果有中文文件名的话，可以指定挂载参数语系

	重新挂载或挂载不特定目录
		如当/为只读状态，可以重启系统或重新挂载
			mount -o remount,rw,auto /
		可以将某个目录挂载到另一个目录，有点类似软链，特殊时才会用
			mount /var /test/var  #将/var这个目录暂时挂载到/test/var下面

	卸载
		umount 文件系统设备名/挂载点
		umount /dev/sdb6
		umount /test

磁盘/文件系统自定义参数
	mknod #设置如/dev/sda 文件名，一般系统会自动帮设置好
	xfs_admin #设置lable name与uuid


20200507
启动挂载
	/etc/fstab #开机就启动的文件挂载文件，注意 / 必须是要先挂载的且必须挂载
	六字段意义
		[设备/uuid] [挂载点] [文件系统类型如xfs] [文件系统参数] [dump] [fsck为]

		设备/uuid
			可以是设备名如/dev/sda2,也可以是uuid,也可以是label名称
		挂载点
			一般是目录
		文件系统类型
			xfs, ext4，nfs等
		文件系统参数
			rw,auto,exec等相关参数
		dump
			备份方案太多一般不用,为0即可
		fsck
			检验扇区,早期的系统使用,xfs不使用,xfs会自己检验,为0即可

	/etc/fstab修改好后，一定要测试语法正确性, mount -a 检验成功与否

	/etc/fstab是启动配置文件，不过实际挂载信息是记录到/etc/mtab与/proc/mounts这两个文件，万一如果/etc/fstab写入的数据出错导致无法顺利启动而进入单人维护模式,就得重新挂载 /, 此时/为只读mtab这两个文件不能写。
	mount -n -o remount,rw /

特殊设备loop挂载(镜像文件不刻录就挂载使用)
	cd/dvd镜像文件
		mkdir  -p /data/centos_dvd
		mount -o loop /tmp/Centos-7.0.XXXDVD.iso  /data/ceotos_dvd #这就就能够不需要将iso刻录成dvd或光盘就读取到内部的数据了，并且可以修改里面的文件，这就了为什么镜像文件会提供md5验证码给用户确认该镜像没有问题

	建立大文件以制作loop设备文件
		比如一开始分区不合理，只有/目录有多余的容量，可以在/里面制作出一个大文件用来挂载，就相当于多了一个分区
		dd if=/dev/zero of=/srv/loopdev bs=1M count=512
			#if input file,输入文件,/dev/zero是会一直输出0的装备
			#of outputfile 将一堆0写入到后面的文件中，
			block 相当于文件系统的区块
			count 总共有多少bs
		mkfs.xfs -f /srv/loopdev
		mount -o loop /srv/loopdev /data/file

交换分区
	交换分区就是如果内存不足时，会把内存中不常用的数据或程序暂时放到磁盘上的交换分区里，以空出内存给后续程序或数据使用
	两种创建交换分区的方式
		使用磁盘分区来格式化一个swap文件系统
			先用分区出来一块如1G的分区
			mkswap /dev/sdb6 #格式他生成一个是swap文件系统
			swapon /devsdb6 #启动交换分区
			swapon -s #查看交换分区或使用free 查看
			开机启动vi /etc/fstab
				/dev/sdb6 swap swap defaults 0 0  #第二栏没有挂载点
		使用大文件来格式化生成一个swap文件系统
			dd if=/dev/sero of=/srv/swap_dev bs=1M count=1024 #生成大文件
			mkswap /srv/swap_dev #格式化swap文件
			swapon /srv/swap_dev #启动
			开机启动vi /etc/fstab
				/srv/swap_dev swap swap defaults 0 0 # 第一栏必须是设备名不能是uuid,因为系统只会查询设备的uuid

		关闭swap
			swapoff /dev/sdb6
			swapoff /srv/swap_dev

		ls -l 显示的total数值
			ll -sh,目录下的total值是文件数据区块数量*区块大小值

				root@localhost ~]# ll -sh
				total 10M
				4.0K -rw-r--r--. 1 root root  120 Apr 19 11:23 1.txt.tar.gz
				4.0K -rw-------. 1 root root 1.3K Aug 11  2019 anaconda-ks.cfg
				4.0K -rw-r--r--. 2 root root  451 Jun 10  2014 crontab
				crontab的实际大小是451bytes，但这个文件占用一个区块(4k大小)



20200509
文件压缩
	压缩技技原理
		如数字1用1个字节表示,事实计算机的最小计算单位是1bit，所以数字1就是00000001,利用一些特殊的算法通过把前7个0"丢掉“就达到了节省空间的目的
		如1111111111111111111111110，前面有十几个1甚至更多,可以用15*1来表示存储之类达到节省空间

gzip
	替代compress,最常用的压缩命令,gzip压缩后的文件可以被windows的winrar和7.zip解压

	gzip 1.txt # 会自动生成1.txt.gz，.gz后缀名文件,注意源文件1.txt会不再存在
	gzip -d 1.txt.gz #解压缩得到1.txt,  gz文件会不再存在
	gzip -v 1.txt #压缩的同时显示压缩比
	zcat/zmore/zless/zgrep 可以用来查看或查找被压缩的文件

	gzip -9 -c service > service.gz  #-c将原本要压缩的内容变成文字类型从屏幕输出，然后利用>输出到service.gz(手动建立)，这样原文件与压缩文件都同时存在

	bzip2 与gzip用法一样，压缩比更好，后缀名bz2

	xz用法与gzip用法一样，压缩比更好，后缀名 xz
	xz -l abc.xz #显示压缩前后容量对比
	xz -k abc.txt    #压宿文件同时保留源文件

tar
	gzip等压缩软件只能对单一文件解压缩,tar是将多个文件或目录进行打包并能结合gzip解压缩命令
	tar [-jzJ]cv -f 打包的文件名 要打包的文件      #打包并压缩
	tar [-jzJ]tv -f 压缩的文件    #查看文件
	tar [-jzJ]xv -f 压缩的文件    [-C 目录]    #解压文件
		-p #保留备份数据的原始权限与属性
		-P #保留绝对路径,即允许备份数据中含有根目录,慎用
		--exclude=文件  #不包含某个文件
	备份/etc
		tar -zpcvf /root/etc.tar.gz /etc
	查看tar内部文件
		tar -ztvf /root/etc.tar.gz
	解压.tar.gz 到/tmp目录下
		tar -zxvf /root/etc.tar.gz -C /tmp
	打包某目录但不包含特定目录
		tar -zcvf /root/system.tar.gz --exclude=/root/etc* \
			--exclude=/root/system.tar.gz /etc /root #打包etc和root目录但不包含root目录下的etc相关文件与自己本身,exclude最好放在tar.gz后面

	备份比某个时刻要新的文件
		[root@localhost ~]# ll /etc/passwd
		-rw-r--r--. 1 root root 1498 Apr 29 05:09 /etc/passwd  #日期为20200429

		tar -zcvf /root/etc.newer.then.passwd.tar.gz --newer-mtime="20200429" /etc/* #打包比20200429要新的mtime的文件
		tar -ztvf /root/etc.newer.than.passwd.tar.gz | grep -v "/$" # 调用grep找出非/结尾的文件就是我们要的

		tar -cvf file.tar # 仅是打包文件称为tarfile
		tar -zcvf file.tar.gz #有压缩的支持称为tarball

		tar可以将文件打包到某些特定的设备中，如磁带tab,磁带是一次性读取/写入设备，不能用cp来复制,如将/home /root /etc备份到磁带/dev/st0
			tar -cvf /dev/st0 /home /root /etc

xfs文件系统的备份与恢复
	xfsdump #备份，可以完整备份，增量备份，注意只能备份已挂载的文件系经
	xfsrestore #还原，可以还原守整备份，增量备份(要安顺序level0->level1---),可以还原指定的文件, -i交互模式

光盘写入工具	
	先将所需要备份的数据创建成为一个镜像文件iso
	将该镜像文件刻录到cd或dvd中

	一般用图形界面软件来操作即可，无需用命令行工具



20200511
dd
	制做文件或备份功能(基本直接读取扇区)

	dd if="input file" of="output_file" bs="block_size" count="number"

	if  就是Inputfile ,可以是设备
	of  主是outputfile, 可以是设备
	bs  设置一个block大小默认512byte(扇区大小)
	count 多少个bs

	复制/etc/passwd到/tmp/passwd.back中
	dd if=/etc/passwd of=/tmp/passwd.back  #

	dd if=/dev/sr0 of=/tmp/system.iso #复制刻录好的光盘的内容备份成为镜像文件

	把上面的iso刻录到U盘，假设/dev/sda为u盘
	dd if=/tmp/system.iso of=/dev/sda  #可以linux镜像文件写样做u盘就具有可启动功能了，然后可以安装Linux系统
	
	将/boot文件系统通过dd备份下来，假设/boot挂载设备为/dev/vda2
	dd if=/dev/vda2 of=/tmp/vda2.img  #文件大小与磁盘大小一样，哪怕磁盘只使用50%

	将/dev/vda2完整地复制到另一个硬盘分区上，假设我们已经分区好一个比vda2大的分区sda1
	不需要格式化sda1
		dd if=/dev/vda2 of=/dev/sda1

		xfs_repair -L /dev/sda1 #先清楚一堆log

		#] uuidgen
		948gjei-egeg-48g05656-56

		xfs_admin -U 948gjei-egeg-48g05656-56 /dev/sda1 #这两行是用于创建新的uuid，因为dd复制时连同uuid都复制过来了

		mount /dev/sda1 /mnt #挂载发现/mnt与/boot一模一样

		xfs_growfs /mnt #系统放大空间

		dd是将原本旧的硬盘分区上面的扇区数据整个复制过来，连同超级区块，启动扇区元数据等，所以不用格式化

		如果想创建两块一模一样的磁盘，只要执行类似 dd if=/dev/sda of=/dev/sdb,  sdb不用分区与格式化，因为命令包括MBR与分区表都复制过sdb了

cpio
	可以备份任何东西，包括设备文件，要结合find与管道 | 
	也可以将系统数据完整的备份到磁带

	备/boot下的所有文件到/tmp

	cd /
	find boot | cpio -ocvB > /tmp/boot.cpio  #需要去掉根目录，与tar 的-P一个道理





20200512
vim
	一般命令模式
		ctrl + f 向下移动一页
		ctrl + b 向上移动一页
		0或Home键，移动到一行的最前面的字符处
		$ 或END， 移动到一行的最后面的字符处
		G移动到文件的最后一行
		gg移动到文件的第一行
		/word 向光标之下寻找一个名为word的字符串
		?word  向光标之上寻找word
		n  重复前一个查找的操作,如/word继续查找
		N  与n相反，反向查找
		:n1,n2s/word1/word2/g  替换n1到n2行的word1变成word2
		:1,$s/word1/word2/g    从第一行到最后一行全都替换在word2
		:1,$s/word1/word2/gc   从第一行到最后一行都替换，但替换前让客户确认
		x, X   x向后删除一个字符, X向前删除一个字符
		dd    删除光标所在的那一行
		ndd    n为数字,向下删除n行
		yy    复制光标所在那一行
		nyy    复制光标以下的n行
		p与P     p为将已复制的内容在光标下一行粘巾,P为上一行
		u   恢复前一个		ctrf + r  重做上一个操作
		.   重复前一个操作


	一般模式切换到编辑模式
		i与I， i在光标处插入, I在本行的第一个非空字符处插入
		a与A   a在光标下一个字符出插入, A在光标所在行的最后一个字符处插入
		o与O   o在光标所在的下一行插入新的一行,O在光标所在处的上一行插入新的一行
		r和R   r替光标所在的字符一次, R一直替换直到esc


	编辑模式
	命令行模式
		:w 保存
		:w! 强制保存
		:q  退出
		:q!  强制退出
		:wq  退出后保存
		:w filename   将编辑的数据保存为另一个文件
		:! command    暂时退出vim执行下命令
		:set nu  显示行号
		:set nonu 取消行号

	vim缓存，恢复与打开警告
		当修改还没来得及保存退出时，再重新vim时会出现警告,缓存文件为.file.swp。或多人打开并编辑了file
		如果是其他人在编辑，可以选 择O模式只读
		如果是未来得及保存则可以
			选R，使用swp来恢复文件再决定要不要保存，这样可以救回来之前没保存的修改，退出后记得删除file.swp
			或者不要恢复修改直接删除.swp文件

	可视区块
		Ctrl + v   选中之后可以d删除或y复制后再p粘贴

	多文件

	多窗口
		在用vim打开一个文件后，在命令行输入
		:sp filename , 打开一个新窗口，如果有file表示打开一个新文件，没有file则打开同一个文件

		ctrl + w + 下 先按住ctrl再按w,然后放开所有的健, 再下 下 则光标移动到下方的窗口
		ctrl + w + 上  移动到上方的窗口
		:q 退出窗口

	命令补全




20200514

利用iconv可以进行文件编码的转换

dos2unix, unix2dos可以变更文件的每一行的换行符,如windows与linux文件的换行符不一样
	dos(windows)文件的换行符为^M$,称为CRLF
	unix换行符为 $,  区别少了^M
bash
	控制计算机硬件的是操作系统的内核,我们用过shell输入命令与内核沟通，让内核来操作硬件准确工作，bash属于壳程序(shell),其它应用程序也称为壳程序

	type 命令可以查看命令是外部命令还是bash内置的命令,后接执行命令，不能是文件
		[root@localhost ~]# type cd
		cd is a shell builtin

	# cp /test/1.txt /12/2.txt /3/3.txt \
	>/5/5/txt /root   #复制4个文件到/root目录下, \转义回车键，\后面要紧接着ENTER,不能多空格,因为\仅转义下一个字符

	提示符命令行下
	ctrl + u 或 ctrl + k 从光标处向前删除命令或向后删除命令
	ctrl + a 或 ctrl +e  从光标处移动到整个命令的最前面或最后面

	一般登录后,linux会根据/etc/passwd设置一个shell，默认bash

	环境变量通常以大写字符表示

	变量，类型默认字符串
		变量的设置，变量与变量内容以一个=号来连接
			name=VBird
		等号两边不能接空格,变量内容有空格需用双引号或单引号结合起来
			name = VBird   name=Vbird good  #错误
		变量只能是英文与数字且不能数字开头
			2myname=VBird  #错误
		双引号内的特殊字符可以保持原本的属性
			var="lang is $LANG"  -> echo $var -> lang is zh_CN.UTF8
		单引号内的特殊字符为一般字符
			var=‘lang is $LANG' -> echo $var -> lang is $LANG
		可用\转义符将特殊字符([ENter], \ , ', 空格等)变成一般字符
			name=Vbird\'s\ good  -> echo $name -> Vbird's good
		在一串命令中需要借由其它命令提供信息时,可以使用反单引号`或$()
			version=$(uname -r)
		变量扩增内容可以用${}字符
			PATH=${PATH}:/home/hello
		若变量需要在子进程中执行，
			export 变量 #使其在为环境变量
		取消变量
			unset 变量

		设置变量代替工作目录
			work="/home/good" #不用""也行

		env 显示所有的环境变量

		RANDOM 生成随机数的变量, 0~32767


		set 观察显示所有的环境变量与用户自定义变量

		PS1='[\u@\h \W]\$ '  命令提示符就是 [root@www~]#

		$ shell的PID
			echo $$ 2787

		? 上个执行命令的返回值
			ls -h -> echo $? -> 0  #命令能成功执行就返回0，否则就返回非0

		export 自定变量转成环境变量
			export myname #使myname变成环境变量，这样myname就可以在子进程中使用，export后没接变量时，会列出所有的环境变量

		父进程与子进程
			Linux登录之后得到一个BASH(父进程),在这Bash下面所执行的任何命令(子进程)都是由这个BASH所衍生出来的.如在父进程的bash下面执行bash进入到另一个界面(子进程)，原本的Bash就会暂时sleep，当子进程bash exit退出后才回到原本的BASH。

			子进程仅继承父进程的环境变量,不会继承自定义变量

		declare 将环境变量转成自定义变量


		为什么环境变量的数据可以被字进程引用?
			因为内存配置关系，启动一个shell时，操作系统会给这个SHELL在内存中分配一个区域，些内存中的变量就可以让子进程使用。若父进程用export功能，就可以让自定义的变量的内容写到上述内存区域中(环境变量)，当加载另一个子进程时(离开父进程),子shell可以调用父进程的环境变量所在内存区域到自己的环境变量内存区域中

		语系 locale

			查看语系
				locale 
			查看支持的所有语系
				locale -a   #没有的话可以安装语言包

			修时修改语系
				LANG=en_US.utf8
			永处修改要写到配置文件去
				cat /etc/locale.conf
				LANG=en_US.utf8



		read   读取来自键盘输入的变量内容
			-p  后面接提示字符
			-t 	接等待的秒数

			read -p "please enter your name: " -t 30 name -> hello -> echo $name -> hello

		declare 声明变量的类型 
			-a 将后面的变量定义为数组(array)类型 
			-i 将后面的变量定义为整数类型 
			-x 用法与export一样，将后面的变量变成环境变量
			-r 交后面的变量设置成为readonly，不可更改内容与不能unset
			-P 单独列出变量的类型 
			declare -i sum=100+200+300 -> echo $sum -> 600    #变量类型默认为字符串所以要声明为整数类型,BASH的数值运算中,默认最多仅能到达整数形态，所以1/3结果是0

		数组
			设置数组 var[index]=content
				var[1]="small min"
				var[2]="big min"
				var[3]="nice min"

				echo ${var[1]} -> "small min"
				echo "${var[1]}, ${var[2]}, ${var[3]}"

		ulimit
			可以限制用户某些资源，如可以开启的文件数量,可以使用的cpu时间，使用的内存总量等
			-a 列出所有的限制额度
			-f 此shell可以建立的最大文件容量，单位为kbytes

		变量的删除与替换
			[root@localhost ~]# echo ${path}
			/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

			删除/usr/local/sbin 第一个目录
			[root@localhost ~]# echo ${path#/*local/sbin:}
			/usr/local/bin:/usr/sbin:/usr/bin:/root/bin

			删除前面所有的目录只保留 /root/bin
			[root@localhost ~]# echo ${path##/*bin:}
			/root/bin

			# 删除符合文字的最短那一个
			## 删除符合文字的最长那一个

			删除最后一个目录
			[root@localhost ~]# echo ${path%:*bin}
			/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin
			
			只保留第一个目录
			[root@localhost ~]# echo ${path%%:*bin}
			/usr/local/sbin

			% %% 与# ##类似，但是从后面匹配

			${变量/旧字符/新字符} 替换符合的第一个旧字符
			￥{变量//旧字符/新字符} 全部替换


20200519

prtg添加https域名监控,add sensor要选择HTTP Advanced类型，然后域名填http://abc.com就行,Require Keyword要选择Set sensor to error if keyword is missing,对应的字符串可以填要监控的字符串(检测有没有劫持),也可以随便填比如(abc.com)

变量的测试与内容转换
	root@localhost ~]# echo $username

	username变量没有设置时
	[root@localhost ~]# username=${username-root}
	[root@localhost ~]# echo $username 
	root

	变量为空时
	[root@localhost ~]# username=""
	[root@localhost ~]# username=${username-root}
	[root@localhost ~]# echo $username 

	[root@localhost ~]# username=${username:-root}
	[root@localhost ~]# echo $username 
	root
	其它先跳过

命令别名
	alias, 可以将常用或长的命令创建成一个新的命令
		alias lm='ls -al|mort' # 
	也可以替换命令
		alias rm='rm -i' #这样rm就变成了新的有-i参数的命令

	alias 直接列出所有别名

	unalias 取消别名

历史命令
	history
		-n 列出最近n条命令
		-c 将目前的shell中的所有history内容全部清除
		-w 将目前的history记录到histfiles中

		当以bash登录后,系统会主动同~/.bash_history读取以前执行
		过的命令。~/.bash_history能记录的数量与HISTFILESIZE变量有关.假设这次登录后执行了100条命令,那当注销时,系统会将101~1100更新到~/.bash_history中，也就是说注销时会把最近的HISTFILESIZE记录到记录文件中,也可以用history -w强制写入

		多用户登录命令写入为最后注销那个

bash shell的操作环境
	路径与命令查找顺序
		1, 相对/绝对路径执行命令, 如/bin/ls 
		2, 由alias找到该命令执行
		3, 由bahs内置的(builtin)命令来执行
		4, 通过$PATH变的的顺序找到的第一个变量来执行
	可以通过type -a ls 查看顺序

	bash登录与欢迎信息
		/etc/issue #登录就看到的欢迎信息如操作系统与硬件等级，可以修改
		/etc/motd  #可以设置让用户登录就看到的信息,如某时间点系统维护

	bash的环境配置文件
		一进入Bash就会取得一些有用的变量是因为系统有一些环境配置文件，让bash启动时就直接读取这些文件，这些环境配置文件又分为全局系统配置文件与文人偏好配置文件，alias与自定义的变量在bash注销时会失效，要想保留就得写得配置文件中

		login shell 与non-login shell
			区别在于有没有登录
			login shell
				取得bash时需要完整的登录流程,如tty1~tty6登录需要账密,些时取得的bash称为login shell
			non-login shell
				如在X的图形界面中启动终端或在原本的bash环境下再次输入bash命令,都是不需要账密的
			login shell与non-loginshell读取的配置文件不一样
			
			一般来说,login shell只会读取两个配置文件
				/etc/profile, 系统的整体设置，最好不要修改
				~/.bash_profile 或~/.bash_login 或 ~/.profile 属于用户个人设置,用户要添加的自己的数据就写入这里

			/etc/profile(login shell才会读)
				可以利用用户的标识符(uid)在、来决定很多重要的变量数据,也是每个用户登录取得bash时一定会读取的配置文件，想要帮所有用户设置整体环境就是改这里,主要变量有

				PATH
				MAIL
				USER
				HOSTNAME
				HISTSIZE
				umask

				/etc/profile还会云调用外部的配置文件，下面的文件会依序被调用
					/etc/profile.d/*.sh
					/etc/locale.conf #语系相关
					/usr/share/bash-comletion/completion/* #命令与文件补齐等
				默认情况下读取的整体环境配置文件其实只有/etc/profile，但/etc/profile会调用其它的配置文件

			读完整体环境设置后就会读取用户的个人配置文件,一般是这三个
				/.bash_profile 
				或~/.bash_login 
				或 ~/.profile
			只实只会读取其中的一个,读取顺序从上到下，前面的不存在才会云读取下面的
			[leison@localhost ~]$ cat ~/.bash_profile 
			# .bash_profile

			# Get the aliases and functions
			if [ -f ~/.bashrc ]; then
				. ~/.bashrc
			fi

			# User specific environment and startup programs

			PATH=$PATH:$HOME/.local/bin:$HOME/bin

			export PATH

			如PATH变量有设置，以累加的方式并export,-f ~/.bashrc则是存在bashrc就读入bashrc的配置，. ~/.bashrc 等于sorce ~/.bashrc,也就是说~/.bash_profile其实还会再调用~/.bashrc的内容，所以最终读取的文件是~/.bashrc,可以将自己的偏好设置写入该文件

		source 配置文件
			配置文件/etc/profile等都是在取得login shell后才会读取的配置文件，所以如果将自己的偏好设置写入上述文件，那就要注销再登录后设置才会生效.source可以直接读取配置文件而不再注销登录

			source /etc/profile
			. /etc/profile   #两条命令等效

		non-login shell
			该bash只会读取~/.bashrc而已

		~/.bashrc
			[root@localhost ~]# cat ~/.bashrc 
			# .bashrc

			# User specific aliases and functions

			alias rm='rm -i'
			alias cp='cp -i'
			alias mv='mv -i'

			# Source global definitions
			if [ -f /etc/bashrc ]; then
				. /etc/bashrc
			fi

			root的bashrc已规范好命令别名的安全选项,centos 7.x还会主动调用/etc/bashrc文件,因为/etc/bashrc帮我们的BASH定义下面内容
				根据不同的uid设置umask的值
				根据不同的uid设置提示字符(PS1变量)
				调用/etc/profile.d/*.sh设置

		其它相关
			/etc/man_db.conf
				规范使用man page的该去哪查看数据的路径,tarball安装的软件的命令帮助man可能需要修改
			~/.bash_history 
				登录bash后读取此文件到内存，在BASH内就可以看到历史命令了
			~/.bash_logout
				注销bash后,系统再帮我做什么操作后才离开,如清屏

	终端的环境设置 stty set
		一般不修改,本身设置已经很好
		
		stty erase ^h  #用ctrl + h 删除字符(原来是Backspace)

		set 
			-u,默认不启用，若启用，当使用未设置变量时，会显示错误信息

			echo $- # $-变量内容就是set的所有设置

			set -u 
			echo $virbird # 期待virdbird变量不存在,则会报错，没启用-u时会显示空

		BASH默认的组合键
			ctrl + c 终止目前的命令
			ctrl + d 输入结束EOF，例如由件结束的时候
			ctrl + m 回车
			ctrl + s 停止屏幕输出
			ctrl + q 恢复屏幕输出
			ctrl + u 在提示符下将整行命令删除
			ctrl + z 暂停目前的命令

	通配符与特殊符号

		通配符

			* 代表0到无穷个任意字符
			? 代表一定有一个任意字符
			[] 代表一定有一个在括号内的字符(非任意字符),如[[abcd],代表一定有a或b或c或d的中的任意一个字符
			[ - ] 代表在编码顺序内的所有字符,如[0-9]代表0和9之间的所有数字
			[^ ]  ^反向选择, [^abc]代表一定有一个字符,但不是a,b,c

			例找出/etc下面以cron为开头的文件
			ll -d /etc/cron*

			找出/etc下面刚好是5个字母的文件名
			ll -d /etc/?????

			找出/etc下面含有数字的文件
			ll -d /etc/*[0-9]*

			找出/etc下面文件名开头为非小写字母开头的文件
			ll -d /etc/[^a-z]*

		特殊符号

			# 注释符号，写脚本常用
			\ 转义符,将特殊字符与通配符还原成一般符号
			| 管道
			; 连续命令执行分隔符
			~ 用户家目录
			$ 使用变量前导符
			!　逻辑运算上的非(not)
			/ 路径分隔符，目录符号
			>, >>  重定向输出
			<, <<  重定向输入
			'' 单引号,不具备变量替换功能,单引号内的$变量为纯文本
			"" 双引号,具备变量替换功能
			`` 反单引号,`中间的命令可先执行，等于$()
			( ) 在中间为子shell的起始与结束
			{ } 在中间为命令区块的组合

数据流重定向

	standard output 与 standar error output
		标准输出指的是命令执行所返回的正确信息,标准错误输出指的是命令执行失败返回的错误信息

		标准输入(sdin): 代码为0, 使用< 或 <<
		标准输出(stdout): 代码为1， 使用> 或>>  # 1> 1不写也行
		标准错误输出(stderr): 代码为2, 合用 2> 或2>>

		ll / > test # 把ll / 输出的信息写入文件或设备, 若test不存在系统则自动建立

		1> 以覆盖的方法将正确的数据输出到指定的文件或设备上
		1>> 以累加的方法将正确的数据输出到指定的文件或设备上
		2> 以覆盖的方法将错误的数据输出到指定的文件或设备上
		2>> 以累加的方法将错误的数据输出到指定的文件或设备上
		注意  1>> 或 2>> 中间是没有空格的

		[ABC@localhost ~]$ find /home -name .bashrc 
		/home/leison/.bashrc
		find: ‘/home/arod’: Permission denied

		find /home -name .bashrc > list_right 2> list_error

		/dev/null 垃圾黑洞,可以吃掉导向这个设备的任何信息
			[leison@localhost ~]$ find /home -name .bashrc 2> /dev/null  
			/home/leison/.bashrc #正确的输出屏幕,错误写出黑洞


		将正确与错误的信息都写list
		find /home -name .bashrc >list 2>&1  #stderro输出到stout,2的转到1
		find /home -name .bashrc &> list 两条都可以

	standard input  <与<< 
		$ cat > test
		hello
		#ctrl + d 退出

		cat test
		hello

		$ cat > test < ~/.bashrc #用文件替代键盘的输入
		cat test
		# .bashrc

		# Source global definitions
		if [ -f /etc/bashrc ]; then
			. /etc/bashrc
			.....
			.....

		$ cat > test << "eof"
		> hello 
		> good 
		> eof
		[leison@localhost ~]$ cat test
		hello 
		good 

		利用<<可以不用ctrl + d，对写脚本有帮助

	命令的执行的判断根据 ; && ||

		cmd;cmd (不考虑命令相关性的连续命令执行)
			如 $ sync;sync;shutdown -h now #关机前先执行两次sync同步写入磁盘操作

		$? (命令返回值)与 && 或 ||
			若前一个命令执行的结果为正确,在Linux下面会返回一个$?=0的值
			cmd1 && cmd2, 若cmd1执行完毕且正确执行($?=0),则开始执行cmd2
						  若cmd1执行完毕且为错误($?不等于0),则cmd2不执行

			cmd1 || cmd2, 若cmd1执行完毕且正确执行($?=0),则cmd2不执行
						  若cmd1执行完毕且为错误($?不等于0),则开始执行cmd2

			例若存在/tmp/abc,则建立/tmp/abc/hehe文件
			假设存在
				ls /tmp/abc && /tmp/abc/hehe
			例测试/tmp/abc是否存在,若在则不创建 ，不存在则创建
				ls /tmp/abc || mkdir /tmp/abc 
			例不清楚/tmp/abc是否存在,但就是要建立/tmp/abc/hehe
				ls /tmp/abc || mkdir /tmp/abc && touch /tmp/abc/hehe
				若存在/tmp/abc则不执行mkdir,$?=0向后转, &&遇到0,执行touch
				若不存在/tmp/abc,则执行mkdir,后$?=0向后转,touch照样会执行

			例判断/tmp/virding是否存在,存在显示"exist",不存在显示"not exist"
				ls /tmp/virding && echo "exist" || echo "not exsit" #顺序重要

20200523
管道命令(pipe)
	管道命令仅会处理标准输出,对于标准错误会予以忽略
	管道命令必须能够接受来自前一个命令的数据成为标准输入继续输入处理才行

	管道命令
		less more head tail等

	选取命令 cut grep
		[root@localhost ~]# echo $PATH
		/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
		[root@localhost ~]# echo $PATH | cut -d ':' -f 5
		/root/bin

		[root@localhost ~]# echo $PATH | cut -d ':' -f 3,5
		/usr/sbin:/root/bin

		[root@localhost ~]# export
		declare -x HISTCONTROL="ignoredups"
		declare -x HISTSIZE="1000"
		declare -x HOME="/root"
		declare -x HOSTNAME="localhost.localdomain"
		declare -x LANG="en_US.UTF-8"
		.......

		[root@localhost ~]# export | cut -c 12-
		HISTCONTROL="ignoredups"
		HISTSIZE="1000"
		HOME="/root"
		HOSTNAME="localhost.localdomain"

		grep 

		[root@localhost ~]# last
		root     pts/0        192.168.1.8      Fri May 22 22:15   still logged in   
		root     pts/1        192.168.1.3      Fri May 22 18:59 - 23:43  (04:43)    
		root     tty1                          Fri May 22 18:59   still logged in   
		root     pts/0        192.168.1.5      Fri May 22 11:04 - 20:51  (09:47)    
		reboot   system boot  3.10.0-957.el7.x Fri May 22 10:59 - 03:28  (16:28) 

		有出现root的一行就找出来
		root@localhost ~]# last | grep 'root'
		root     pts/0        192.168.1.8      Fri May 22 22:15   still logged in   
		root     pts/1        192.168.1.3      Fri May 22 18:59 - 23:43  (04:43)    
		root     tty1                          Fri May 22 18:59   still logged in   
		root     pts/0        192.168.1.5      Fri May 22 11:04 - 20:51  (09:47) 

		取反
		[root@localhost ~]# last | grep -v 'root'
		reboot   system boot  3.10.0-957.el7.x Fri May 22 10:59 - 03:29  (16:30)    
		reboot   system boot  3.10.0-957.el7.x Tue Apr 28 12:37 - 03:29 (24+14:52)  
		reboot   system boot  3.10.0-957.el7.x Sat Apr 18 14:33 - 03:29 (34+12:56) 

		[root@localhost ~]# last | grep 'root' | cut -d ' ' -f 1
		root
		root
		root

	排序命令
		sort
			-n 以纯数字来排序
			-r 反向排序
			-t 分隔符,默认[Tab]
			-k 指定那个区间来进行排序

			普通排序,sort默认以第一条信息来排，且以文字形式排序
			[root@localhost ~]# cat /etc/passwd | sort
			adm:x:3:4:adm:/var/adm:/sbin/nologin
			alex:x:1001:1001::/home/alex:/bin/bash
			apache:x:48:48:Apache:/usr/share/httpd:/sbin/nologin
			arod:x:1002:1002::/home/arod:/bin/bash
			bin:x:1:1:bin:/bin:/sbin/nologin
			chrony:x:998:996::/var/lib/chrony:/sbin/nologin
			daemon:x:2:2:daemon:/sbin:/sbin/nologin


			以第3段且以纯数字来排序
			[root@localhost ~]# cat /etc/passwd | sort -t ':' -k 3 -n
			root:x:0:0:root:/root:/bin/bash
			bin:x:1:1:bin:/bin:/sbin/nologin
			daemon:x:2:2:daemon:/sbin:/sbin/nologin
			adm:x:3:4:adm:/var/adm:/sbin/nologin
			lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
			sync:x:5:0:sync:/sbin:/bin/sync

		uniq (去重)
			-c 进行计数

			使用last取出账号栏,仅取出账号，进行排序后取出一位
			[root@localhost ~]# last | cut -d ' ' -f 1| sort|uniq 

			reboot
			root
			wtmp

			加多账号登录次数
			root@localhost ~]# last | cut -d ' ' -f 1 | sort | uniq -c #先sort
      1 
		     16 reboot
		     89 root
		      1 wtmp   #空白与wtmp是默认字符可以忽略

		wc (统计行或字符)
			-l 统计行数
			-m 统计字符
			[root@localhost ~]# cat /etc/man_db.conf |wc
   			 131     723    5171
   			 # 行	字数		字符数

   			统计登录次数
   			[root@localhost ~]# last | grep [a-zA-Z]|grep -v 'wtmp'|grep -v reboot | wc -l
			89


	双向重定向 tee
		可以让standoutput转存一份到文件内并将同样的数据在屏幕去处理
		-a 以累加的方式将数据加入文件中

		[root@localhost ~]# last | tee last.list | cut -d ' ' -f 1
		root
		root
		root

		# ls -l | tee ~/homefile |more

		ls -l / | tee -a ~/homefile | more

	字符转换命令
		tr
			可以删除字符或替换字符
			-d 删除字符
			-s 替换字符

			所有小写变成大字
			last | tr '[a-z]' '[A-Z]' #不用''也可以

			先把unix文件变成dos换行符文件
			cp /etc/passwd ~/passwd && unix2dos ~/passwd

			查看换行符
			cat -A ~/passwd
			root:x:0:0:root:/root:/bin/bash^M$
			bin:x:1:1:bin:/bin:/sbin/nologin^M$
			daemon:x:2:2:daemon:/sbin:/sbin/nologin^M$

			删除^M
			cat ~/passwd | tr -d '\r' > ~/passwd.linux

		col
			-x 将tab键转换成对等的空格键
			[root@localhost ~]# cat -A /etc/man_db.conf 
			.....
			SECTION^I^I1 1p 8...
			......

			^I为1个tab键

			[root@localhost ~]# cat /etc/man_db.conf |col -x | cat -A
			.....
			SECTION         1 1p 8 2 3 3p 4 5
			......

		join
			合并两个文件,有相同数据的那一行才将它加在一起
			-t join默认以空格分隔数据,并且比对第一栏位
			-1 数字1，代表第一个文件要用哪个栏位比对 
			-2 代表第二个文件要用哪个栏位比对

			[root@localhost ~]# head -n 3 /etc/passwd /etc/shadow
			==> /etc/passwd <==
			root:x:0:0:root:/root:/bin/bash
			bin:x:1:1:bin:/bin:/sbin/nologin
			daemon:x:2:2:daemon:/sbin:/sbin/nologin

			==> /etc/shadow <==
			root:$6$esu2az6WJraoEBnx$4qVMw/P4z4gn2S/RFhDD/SiyY2MZsM6xlfro8EFxrcvldSweyqFcF.OWrm2/vUG/.VXc5a4R2yDioqr1NS3Aw/::0:99999:7:::
			bin:*:17834:0:99999:7:::
			daemon:*:17834:0:99999:7:::

			默认以第一栏比对并合并文件,第二文件的第一栏就不显不
			[root@localhost ~]# join -t ':' /etc/passwd /etc/shadow | head -n 3
			root:x:0:0:root:/root:/bin/bash:$6$esu2az6WJraoEBnx$4qVMw/P4z4gn2S/RFhDD/SiyY2MZsM6xlfro8EFxrcvldSweyqFcF.OWrm2/vUG/.VXc5a4R2yDioqr1NS3Aw/::0:99999:7:::
			bin:x:1:1:bin:/bin:/sbin/nologin:*:17834:0:99999:7:::
			daemon:x:2:2:daemon:/sbin:/sbin/nologin:*:17834:0:99999:7:::

			例2
			[root@localhost ~]# head -n 3 /etc/passwd /etc/group
			==> /etc/passwd <==
			root:x:0:0:root:/root:/bin/bash
			bin:x:1:1:bin:/bin:/sbin/nologin
			daemon:x:2:2:daemon:/sbin:/sbin/nologin

			==> /etc/group <==
			root:x:0:
			bin:x:1:
			daemon:x:2:

			[root@localhost ~]# join -t ':' -1 4 /etc/passwd -2 3 /etc/group | head -n 3
			join: /etc/passwd:6: is not sorted: sync:x:5:0:sync:/sbin:/bin/sync
			join: /etc/group:11: is not sorted: wheel:x:10:
			0:root:x:0:root:/root:/bin/bash:root:x:
			1:bin:x:1:bin:/bin:/sbin/nologin:bin:x:
			2:daemon:x:2:daemon:/sbin:/sbin/nologin:daemon:x:
			#第一个文件4第4栏与第二文件的第三栏都是gid所以比对这一栏,相同的栏位被称到第一栏,剩下的第二文件的同行补到第一文件，注意join前所需处理的文件应该要事先排序

		paste
			也是将两个文件合并，直接将两行巾在一起，且以tab键隔开，不需要比对两个文件的数据

			-d 可接分隔符,默认tab的数据
			-  file部分写成-，表示来自标准输入

			root@localhost ~]# paste /etc/passwd /etc/group
			root:x:0:0:root:/root:/bin/bash	root:x:0:
			bin:x:1:1:bin:/bin:/sbin/nologin	bin:x:1:
			daemon:x:2:2:daemon:/sbin:/sbin/nologin	daemon:x:2:

			group的内容作为标准输入给paste
			[root@localhost ~]# cat /etc/group | paste /etc/passwd /etc/shadow - | head -n 3
			root:x:0:0:root:/root:/bin/bash	root:$6$esu2az6WJraoEBnx$4qVMw/P4z4gn2S/RFhDD/SiyY2MZsM6xlfro8EFxrcvldSweyqFcF.OWrm2/vUG/.VXc5a4R2yDioqr1NS3Aw/::0:99999:7:::	root:x:0:
			bin:x:1:1:bin:/bin:/sbin/nologin	bin:*:17834:0:99999:7:::	bin:x:1:

		expand
			将tab按键转成空格键
			-t 后面接数字,一般是一个tab可以用8个空格键替换，可以自定义
			[root@localhost ~]# grep '^MANPATH' /etc/man_db.conf |head -n 3 | expand -t 6| cat -A
			MANPATH_MAP /bin              /usr/share/man$
			MANPATH_MAP /usr/bin          /usr/share/man$
			MANPATH_MAP /sbin             /usr/share/man$

			已将tab转成6个空格
			unexpand 可以将空格转为tab键

	split
		划分命令
		-b 后接谷划分的文件大小，单侠,b,k,m等
		-l 以行数来划分

		[root@localhost tmp]# split -b 300k /etc/services services
		[root@localhost tmp]# ll
		total 656
		drwxr-xr-x. 2 root root     18 May 22 22:36 abc
		-rw-r--r--. 1 root root 307200 May 23 22:47 servicesaa
		-rw-r--r--. 1 root root 307200 May 23 22:47 servicesab
		-rw-r--r--. 1 root root  55893 May 23 22:47 servicesac

		services，划分的文件名任取，被划分的取名xxxaa,xxxab,xxxac等

		将上面三个划分的文件合成一个文件
		root@localhost tmp]# cat servicesa* >> serviceback
		[root@localhost tmp]# ll
		total 1312
		drwxr-xr-x. 2 root root     18 May 22 22:36 abc
		-rw-r--r--. 1 root root 670293 May 23 22:48 serviceback
		-rw-r--r--. 1 root root 307200 May 23 22:47 servicesaa
		-rw-r--r--. 1 root root 307200 May 23 22:47 servicesab
		-rw-r--r--. 1 root root  55893 May 23 22:47 servicesac

		例ls -al / 的信息每10行划分一个文件
		[root@localhost tmp]# ls -al / | split -l 10 - lsroot
		[root@localhost tmp]# wc -l lsroot*
		  10 lsrootaa
		  10 lsrootab
		   8 lsrootac
		  28 total

		重点是-, 如果需要输入或输出时没有文件,-就会被当成stdin或stdout

	xargs(参数代换)
		很多命令其实不支持管道命令,可以通过xargs来提供命令使用,标准输入
		-0 如果输入的stdin含有特殊字符,如 ` \ 空格等时,-0可以将它还原成一般字符
		-e EOF的意思,后面可以接一个字符,当xargs分析到这个字符时,就会停止工作
		-p 在执行每个命令时,都会询问使用者
		-n 后面接次数,每次command命令执行时,要使用几个参数的意思

		cut -d ':' -f 1 /etc/passwd | head -n 3 | xargs -n 1 id
		uid=0(root) gid=0(root) groups=0(root)
		uid=1(bin) gid=1(bin) groups=1(bin)
		uid=2(daemon) gid=2(daemon) groups=2(daemon)

		#因为id后面只能接一个参数,所以要-n 1 来一个一个参数给id，不然直接给3个出出错

		加多询问
		cut -d ':' -f 1 /etc/passwd | head -n 3 | xargs -p -n 1 id
		id root ?...y
		uid=0(root) gid=0(root) groups=0(root)
		id bin ?...y
		uid=1(bin) gid=1(bin) groups=1(bin)
		id daemon ?...y

		将所有的/etc/passwd内的账号都以id来查看,但查到sync时就结束命令
		$ cut -d ':' -f 1 /etc/passwd | xargs -e'sync' -n 1 id
		uid=0(root) gid=0(root) groups=0(root)
		uid=1(bin) gid=1(bin) groups=1(bin)
		uid=2(daemon) gid=2(daemon) groups=2(daemon)
		uid=3(adm) gid=4(adm) groups=4(adm)
		uid=4(lp) gid=7(lp) groups=7(lp)
		#注意-e后面没空格,因为sync是在第6行，-e为eof，查到sync就结束命令(包括sync那行)

		找出/usr/sbin下的有特殊权限的文件并使用ls -l列出
		find /usr/sbin -perm /7000 | xargs ls -l
		-rwsr-xr-x. 1 root root     117504 Nov  8  2018 /usr/sbin/mount.nfs
		-rwxr-sr-x. 1 root root       7208 Oct 31  2018 /usr/sbin/netreport
		-rwsr-xr-x. 1 root root      11216 Apr 11  2018 /usr/sbin/pam_timestamp_check
		-rwxr-sr-x. 1 root postdrop 218632 Oct 31  2018 /usr/sbin/postdrop
		-rwxr-sr-x. 1 root postdrop 260112 Oct 31  2018 /usr/sbin/postqueue
		-rwsr-xr-x. 1 root root      36280 Apr 11  2018 /usr/sbin/unix_chkpwd
		-rwsr-xr-x. 1 root root      11376 Oct 31  2018 /usr/sbin/usernetctl
		#ls 并不是管道命令所以要用xargs替代，也可用下面的命令
		ls -l $(find /usr/sbin -perm /7000)

	- （减号的用途)
		mkdir /tmp/homeback
		tar -cvf - /home | tar -xvf - -C /tmp/homeback
		#tar打包并不是记录下来而是转送到stdout,后面的-则是使用前一个命令的stdout,这样就不需要文件名了

正则表达式(regular expression)
	处理字符串的方法,它以行为单位来进行字符串的处理操作，通过一些特殊符号的辅助,可以让用户轻易地完成查找删除替换某特定字符串的处理过程
	正则表达式是一种表示法,只要程序支持这种表示法,那该程序就可以用来作为正则表达式的字符串之用，如vi, grep, awk, sed等,像ls ,cp这类不支持正则表达式的程序就只能使用bash自己本身的通配符而已

	通配符只是bash操作接口的一个功能,正则表达式是字符串处理的表示方式,两者完全不同

	基础正则表达式与扩展正则表达式
		依照不同的严谨度而分,扩展正则表达式可以使用()与| 来组合

	基础正则表达式

		语系对正则表达式的影响
			文字编码系统里文件其实记录的只有0和1,我们看到的字符与数字都是通过编码表转换来的。所以不同的语系的编码数据并不相同,所以造成的选取结果可能会有差异.如在英文大小写的编码顺序中, zh_CN.big5与C这两种语系的输出结果:
				LANG=C时,0,1,2,3,4.....A,B,C....a,b,c.....z
				LANG=zh_CN时,0,1,2,3.....,a,A,b,B,c,C.......

			如果想选取[A-Z]时,那LANG=C时就可以仅识别到大写字符,而zh_CN时就会连abc等小写字符一起选 出来，所以语意要留意

			特殊符号
				[:alnum:] 代表英文大小写字符及数字,0-9,a-z,A-Z
				[:alpha:] 代表任何英文大小写字符,A-Z,a-z
				[:upper:] 代表大写字符,A-Z
				[:lower:] 代表小写字符 a-z
				[:digit:] 代表数字 0-9

		grep高级用法
			-A 后面接数字,after的意思,除了列出该行外,后续的n行也一起列出
			-B 后面接数字,before的意思,除了列出该行外,前面的n行也一起列出
			-n 显示行号

			[root@localhost tmp]# cat lsrootaa | grep 'etc'     
			drwxr-xr-x.  84 root root 8192 May 22 23:18 etc
			[root@localhost tmp]# cat lsrootaa | grep -A 2 'etc'
			drwxr-xr-x.  84 root root 8192 May 22 23:18 etc
			drwxr-xr-x.   4 root root   32 Apr 29 05:09 home
			lrwxrwxrwx.   1 root root    7 Aug 11  2019 lib -> usr/lib
			[root@localhost tmp]# cat lsrootaa | grep -B1 'home'
			drwxr-xr-x.  84 root root 8192 May 22 23:18 etc
			drwxr-xr-x.   4 root root   32 Apr 29 05:09 home

			--color=auto #默认已经加入在alias当中了,不需额外添加

	基础正则表达式练习
		查找包含test或taste的行
		grep -n 't[ae]st' regular_expree.txt # -n显示行号

		查找oo前面无g的行
		grep -n '[^g]oo' regular_expree.txt

		oo前面不想要有小写字符
		grep -n '[^a-z]oo' regular_expree.txt
			#由于小写字符在编码上是顺序的,所以可以用a-z连续表示

		取得有数字那一行
		grep -n '[0-9]' regular_expree.txt

		由于考虑到语系对于编码的顺序，上面那个例子可以表示为
		grep -n '[^[:lower:]]oo' regular_express.txt
		grep -n '[[:digit:]]' regular_express.txt

		行首^与行尾$
		在行首列出the
		grep '^the' regular_express.txt

		开头是小写字符
		grep -n '^[a-z]' regular_expree.txt

		开头不是英文字母
		grep -n '^[^a-zA-Z]' regular_express.txt

		行尾.结束
		grep -n '\.$' regular_express.txt #小数点.有其它意义,所以要转义

		找出空白行
		grep -n '^$' regular_express.txt

		忽略空白行与#开头的行
		cat /etc/rsyslog.conf | grep -v '^#'| grep -v '^$'

		任意一个字符 . 与重复字符*
			. 代表一定有一个任意字符
			* 代表重复前面一个字符0到无穷多次
				#在bash中*可以代表0到多个字符,两者不同

		找出g??d字符
		grep 'g..d' r.txt

		至少两个o以字
		grep 'ooo*' r.txt 

		g开头与g结尾的字符串,中间可有可无
		grep 'g.*g' r.txt # .* 代表0或多个任意字符

		找出任意数字的行
		grep '[0-9][0-9]*' r.txt
			# grep '[0-9]' r.txt 也可以

		限定连续字符区间 {}
			因为{}在shell中有特殊意义,所以必须要使用转义符 \ 来让它失去意义

		找到两个o的字符
		grep 'o\{2\}' r.txt

		g后面接2到5个o，再g
		grep 'go\{2,5\}g' r.txt

		两个o以上
		grep 'go\{2,\}g' r.txt
			# grep 'gooo*' r.txt 也可以

	基础正则表达式字符集合
		通过以上的例子可以知道集合如下

		^word 待查找的字符在行首

		word$ 在行尾

		. 代表一定有一个任意字符

		\ 转义符,将特殊符号的特殊意义去除
			例 要找含有单引号 ' 的一行
			grep \' regular_express.txt  #注意不能用双单引号结合

		[list] 列出想要的字符,例
						grep 'g[ld]' r.txt 则字符串可以是 gl, gd

		[n1-n2] 列出想要的字符
					grep '[A-Z]' r.txt

		[^list] 取反
					grep 'oo[^t]' r.txt 可以找到ooa,oog等,但不能oot

		\{n\} 连续n个前一个re字符
		\{n,m\} 连续n到m个前一个re字符
		\{n,\} 连续n个以上前一个re字符

	sed 
		管道命令,可以将数据进行替换,删除,新增,选取,选特定行等功能

		-n 使用安静模式,一般sed中,所有来自stdin的数据一般都会被列到屏幕上,加上-n后,则只有经过sed特珠处理的那一行(或操作)才会被列出来
		-e 直接在命令行模式上进行sed操作
		-f 直接将sed的操作写在一个文件内
		-r sed的模式使用扩展正则表达式,默认是基础正则表达式
		-i 直接修改读取的文件内容,不在屏幕输出

		操作说明 n1,n2 function
		n1,n2 不见得会存在,一般代表选择进行的行数,如操作10~20行， 10,20 操作行为
		function有如下行为
			a 新增,后面可以接字符,而这些字符会在新的一行出行(下一行)
			c 替换,后面可以接字符,这些字符可以替换n1,n2之间的行
			d 删除,因为是删除所以d后面不接任何东西
			i 插入,后接字符,在新的一行出现(上一行)
			p 打印,将某个选择的数据打印出来,通常p会与参数 sed -n 一起运行
			s 替换,通常搭配正则表达式,如 1,20s/old/new/g


		以行为单行的新增/删除功能
		将/etc/passwd的内容列出并打印行号，且将2~5行删除
		nl /etc/passwd | sed '2,5d'
	    1	root:x:0:0:root:/root:/bin/bash
	    6	sync:x:5:0:sync:/sbin:/bin/sync
	    7	shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown

	    #sed后面接的操作要用''包住

	    删除第3行到最后一行
	    nl /etc/passwd | sed '3,$d'

	    在第2行后加上字符
	    nl /etc/passwd | sed '2a drink tea'

	    在第2行前加字符
	    nl /etc/passwd | sed '2i drink tea'

	    在第2行后面加入两行
	    nl /etc/passwd | sed '2a drink tea........\
		> or drin beer'
			#用 \ 

		以行为单位的替换与显示功能
		替换第2~5行的内容
		nl /etc/passwd | sed '2,5c no_nombers'

		只显示5~7行
		nl /etc/passwd | sed -n '5,7p' 

		部分数据的查找并替换功能
		提取ip
		ifconfig | grep 'inet'
        inet 192.168.1.12  netmask 255.255.255.0  broadcast 192.168.1.255
        inet6 fe80::b767:af5c:a4e8:43b5  prefixlen 64  scopeid 0x20<link>
        ....

        ifconfig | grep '192.168.1.12'|sed 's/.*inet *//g'|sed 's/ *net.*$//g'
		192.168.1.12

		/etc/man_db.conf文件下找出MAN行,不要#开头注释与空白行
		cat /etc/man_db.conf | grep 'MAN' | sed 's/^#.*//g' | sed '/^$/d'
			#注意#.*,要连同#后面的数据也删除掉,如只有#则只删除#

		直接修改文件内容
		将regular_express.txt以每一行结尾为.的行改为!
		sed -i 's/\.$/\!/g' regular_express.txt

		最后一行新增字符#this is test
		sed -i '$a #this is test' regular_express.txt

	扩展正则表达式 egrep

		+ 代表重复一个或一个以上的前一个字符
			egrep 'go+d' r.txt

		? 代表0个或1个前一个字符
			egrep 'go?d' r.txt
		| 用或or的方式找出数个字符串
			egrep 'go|good' r.txt
		() 找出群组字符串
			egrep 'g(la|oo)d' r.txt
				可以找出glad或good
		()+ 多个重复群组
			echo 'AxyzxyzxyzxyzC' | egrep 'A(xyz)+C' #注意没空格
		
文件的格式化
	printf '%10s\t %5i\t %5i\t %5i\t %8.2f\t \n' $(cat p.txt|grep -v 'Name' )
    DmTsai	    80	    60	    92	    77.33	 
     VBird	    75	    55	    80	    70.00	 
       Ken	    60	    90	    70	    73.33	

       #对这三行格式化,%10s代表10个字符长度的字符串,\t tab， %5i, 5个字符长度的整数，%8.2f 8个字符长度的浮点数2位小数,小数点占一个字符长度 \n 输出新的一行

    [root@localhost ~]# printf '\x45\n'
	E
	#printf可以输出ascall数字与字符对应，上面就是输出16进字的45是什么字符

awk 数据化处理工具
	sed常常用于整行的处理,awk倾向于一行当中分数个字段来处理

	模式
		awk '条件类型1{操作1} 条件类型2{操作2} ...' filename
		
		awk后续可以接文件,也可以读取来自前一个命令的标准输出。主要是处理每一行的字段内的数据,默认字段分隔符为'空格键或tab'

	[root@localhost ~]# last -n 5 | awk '{print $1 "\t" $3}'
	root	desktop-kacbmdc
	root	desktop-kacbmdc
	root	192.168.1.5
	root	192.168.1.8
	root	192.168.1.8
		
	wtmp	Sun

	以上为awk最常用的操作,通过print功能将字段列出来,这里我们指定分隔符\t(tab), ',' 为空格分隔,因为不论每一行都要处理，所以就不需要'条件类型',然后我们要的是第1与第3栏

	awk每一行每个字段都有变量名称,第1栏, $1,  第2栏, $2....   $0代表一整行
	整个awk的处理流程是
		1 读入第1行,并将第1行的数据写入$0,$1,$2.....变量中
		2 根据条件类型,判断是否需要进行后面的'操作'
		3 完成所有操作与条件类型
		4 若后面还有'行操作',则重复上在1~3步骤,直到所有的数据都读完为止

		这样可以知道awk以一行为处理的单位,以字段为最小的处理单位

	变量    代表意义
	NF      每一行$0拥有的字段数
	NR      目前awk所处理的第几行数据
	FS      目前空隔符,默认空格键

	注意awk后续的所有有操作以单引号'括住,由于单引号与又引号必须成对出现,所以非变量部分要用双引号定义出来,因为单引号已经是awk的命令固定用法了

	last后列出每一行的账号,列出目前处理的行数,并且说明该行有多少字段
	last -n 5 | awk '{print $1 "\t line:" NR "\tcout numbers: "NF}'
	root	 line:1	cout numbers: 10
	root	 line:2	cout numbers: 10
	root	 line:3	cout numbers: 10
	root	 line:4	cout numbers: 10
	root	 line:5	cout numbers: 10
		 line:6	cout numbers: 0
	wtmp	 line:7	cout numbers: 7

	#注意NF等变量要用大写且不用$符号

	awk的逻辑运算符
		> 大于
		< 小于
		>= 大于或等于
		<= 小于或等于
		== 等于
		!= 不等于

		注意==是用来判断,如果是要给予一个值用=
	例/etc/passwd列出第1列账号与第3例uid且uid小于10
	awk '{FS=":"}$3<10{print $1 "\t" $3}' /etc/passwd
	root:x:0:0:root:/root:/bin/bash	
	bin	1
	daemon	2
	adm	3
	....
	#结果发现第一行没有正确显示,因为读入第一行行变量$1$2等默认的分融符还是空格,虽然有定义FS=':'，但是第二行才生效,所以要预先用BEGIN设置

	[root@localhost ~]# cat /etc/passwd | awk 'BEGIN {FS=":"} $3<10 {print $1 "\t" $3}'
	root	0
	bin	1
	daemon	2
	adm	3
	lp	4
	sync	5
	shutdown	6
	halt	7
	mail	8

	[root@localhost ~]# cat t.txt 
	name	lst  	2nd   	3th
	vbird   23000   24000   25000
	hello   26000   27000   29000
	nice    22000   28000   20000
	[root@localhost ~]# cat t.txt | awk 'NR==1{printf "%10s\t %10s\t %10s\t %10s\t %10s\n",
	> $1,$2,$3,$4,"Total"}
	> NR>=2{total=$1+$2+$3+$4
	> printf "%10d\t %10d\t %10d\t %10d\t %10.2f\n",$1,$2,$3,$4,total}'
	      name	        lst	        2nd	        3th	      Total
	         0	      23000	      24000	      25000	   72000.00
	         0	      26000	      27000	      29000	   82000.00
	         0	      22000	      28000	      20000	   70000.00
	#所有awk操作都在{}内,如多个命令辅助可以用;或直接以Enter按键隔开命令并非利用\,格式化输出时printf要用\n来分行,变量可以在awk中直接用,不需$
	awk的操作内{}也支持if条件,如上面的NR==1可以写{}内 {if(NR==1)},建议NR==1在外面统一性

文件比对工具
	什么时候会用到文件比对,通常是同一软件包的不同版本之间,比较配置文件与原始文件的差异，通常是用在ASCALL纯文本文件的比对

	diff
		比较两个文件的差异,以行为单位来比对,一般用在ascall纯文本文件比对,通常用在同一文件或软件的新旧版本差异上

		cat /etc/passwd | sed -e '4d' -e '6c no sixlines' > /tmp/testpw/newpasswd
			#sed 后面接两个以上操作时，每个命令前要-e
		diff /etc/passwd /tmp/testpw/newpasswd 
		4d3
		< adm:x:3:4:adm:/var/adm:/sbin/nologin  #左边的第4行被删除了,基准右边的是第3行
		6c5
		< sync:x:5:0:sync:/sbin:/bin/sync
		---
		> no sixlines     #左边的第6行被替换成右边的第5行

		不要用diff比对两个不相干的文件
		diff还可以比对不同目录下相同文件名的内容

	cmp
		比对非纯文本,以字节去比对

	patch
		diff -Naur oldpasswd newpasswd > passwd.patch
		cat passwd.patch 
		--- oldpasswd	2020-05-26 04:51:41.306333925 +0800
		+++ newpasswd	2020-05-26 04:22:00.064392202 +0800
		@@ -1,9 +1,8 @@ #新旧文件修改界定范围,旧1-9行,新1-8行
		 root:x:0:0:root:/root:/bin/bash
		 bin:x:1:1:bin:/bin:/sbin/nologin
		 daemon:x:2:2:daemon:/sbin:/sbin/nologin
		-adm:x:3:4:adm:/var/adm:/sbin/nologin #左侧文件删除行
		 lp:x:4:7:lp:/var/spool/lpd:/sbin/nologin
		-sync:x:5:0:sync:/sbin:/bin/sync #左侧文件删除行
		+no sixlines    #右侧文件新增行
		 shutdown:x:6:0:shutdown:/sbin:/sbin/shutdown
		 halt:x:7:0:halt:/sbin:/sbin/halt
		 mail:x:8:12:mail:/var/spool/mail:/sbin/nologin

		 #上面意思old文件要变成新文件就是第4行要删除与第6行要替换
		 新制出出来的patch文件用来更新旧文件
		 patch -p0 <passwd.patch

		 恢复旧文件内容
		 patch -R -p0 < passwd.patch

		 #-p是后面接几层的意思,因为是在同一目录下面比对,因此不需要减去目录

pr
	输出文件时顺便打印标题或面码
	如  pr /etc/man_db.conf

重要习题
	找出/etc下含有*的文件或内容
	grep '\*' $(find /etc -type f)
	或
	find /etc -type f | xargs grep '\*'   

	找出/ 下含有*的文件或内容
	grep '\*' $(find / -type f)
	-bash: /usr/bin/grep: Argument list too long #命令串长度有限制,得用xargs
	find / -type f 2> /dev/null| xargs -n 10 grep '\*'

20200530

shell脚本
	注意事项
		命令从上而下,从左而右地分析与执行
		命令,选项,与参数间的多个空格都会被忽略掉
		空白行也被忽略掉,tab所产生的空白同样视为空格
		如果读取到一个Enter符号(CR),就尝试开始执行该行(命令)
		如果一行的内容太多,则可以使用\Enter来扩展至下一行
		#注释,任何接在#后面的内容都视作为注释文字而忽略

	假设有/home/good/shell.sh命令,执行方法有
		直接命令执行,shell.sh必须有rx权限,然后
			绝对路径执行 /home/good/shell.sh
			或相对路径执行 ./shell.sh
			将shell.sh放入PATH指定目录内,如~/bin, 直接执行shell.sh
		以bash程序来执行,通过bash shell.sh或 sh shell.sh执行(只需r权限)

		#sh可以执行是因为/bin/sh其实是/bin/bash链接文件,用bash是代表要直接以bash的功能执行shell.sh文件内的相关命令,sh有-n或-x参数来检查与跟综shell.sh语法的正确性

	脚本范例
	#!/bin/bash
	#program
	#       this program show "hello world" in your screen
	#History:
	# 20200530 leison first release
	PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/root/bin
	export PATH
	echo -e "Hello world \a \n "
	exit 0

	1 因为我们使用的是bash,所以必须要用#!/bin/bash来声明文件内使用bash语法,以#!开头的行称为shebang行,那当这个程序执行时,就能够加载bash的相关环境配置文件(一般是非登录shell的~/.bashrc),并执行bash让我们下面的命令能够执行
	2 程序内容说明,#用来注释说明,可以一些基本数据,脚本用途日期作者等
	3 主要环境变量的声明,PATH或LANG等,这样程序就可以直接执行一些外部命令,而不必写绝对路径
	4 主要程序
	5 执行结果告知,定义返回值

	执行sh shell.sh或chmod +x shell.sh;./shell.sh

	简单脚本示例
		交换示脚本
		#!/bin/bash

		read -p "please enter your first name: " firstname
		read -p 'please enter your last name: ' lastname

		echo -e "\nyou full name is $firstname $lastname"

		创建三个以今天昨天前天日期名的空文件
		#!/bin/bash

		# enter a file filename
		read -p 'please enter a filename: ' fileuser

		#check filename exit or not,避免用户按到空格键或回车键
		filename=${fileuser:-"filename"}  #fileuser变量如果存在就把其变量内容给filename,否则把filename内容给filename变量

		date1=$(date --date='1 days ago' +%F)
		date2=$(date --date='2 days ago' +%F)
		date=$(date +%F)

		file1=${filename}${date1}
		file2=${filename}${date2}
		file=${filename}${date}

		touch $file1
		touch $file2
		touch $file

		数值运算
		#!/bin/bash

		read -p "pleas enter a number: " num1
		read -p "pleas enter second number: " num2

		total=$(( ${num1} * ${num2} ))

		echo "num1 * numb = $total"
		#var=$((运算内容)),也可以declare -i total=${num1}*${num2},建议$(()),方便记忆而且小括号内可以加上空格符,而且bash shell默认仅支持到整数而已

		取余echo $((13%3))
		1

		echo "12.3*5" | bc #含有小数点可以通过bc协助,但只对+-*有效,而且不能用$(())
		61.5

		通过bc求PI(圆周率),略过,可以设置多位小数值测试cpu负载

	脚本执行方式的差异
		利用直接执行的方式(绝对路径，相对路径, bash sh等)都是新的bash环境中(子进程)运行的,子进程完成后,子进程内的各项变量或操作将会结束而不会传回父进程中

		source或. 执行脚本,将会直接在父进程执行,脚本内的变量或操作在父进程中也是存在的,和source ~/.bashrc道理一样,不能 bash ./barshrc

判断式
	test
		测试的标志	代表意义
		1. 关于某个文件名的『文件名型』判断，如test -e filename 表示存在否
		-e	该『文件名』是否存在？(常用)
		-f	该『文件名』是否存在且为文件(file)？(常用)
		-d	该『文件名』是否存在且为目录(directory)？(常用)
		-b	该『文件名』是否存在且为一个block device 装置？
		-c	该『文件名』是否存在且为一个character device 装置？
		-S	该『文件名』是否存在且为一个Socket 文件？
		-p	该『文件名』是否存在且为一个FIFO (pipe) 文件？
		-L	该『文件名』是否存在且为一个连结档？
		2. 关于文件的权限侦测，如test -r filename 表示可读否(但root 权限常有例外)
		-r	侦测该文件名是否存在且具有『可读』的权限？
		-w	侦测该文件名是否存在且具有『可写』的权限？
		-x	侦测该文件名是否存在且具有『可执行』的权限？
		-u	侦测该文件名是否存在且具有『SUID』的属性？
		-g	侦测该文件名是否存在且具有『SGID』的属性？
		-k	侦测该文件名是否存在且具有『Sticky bit』的属性？
		-s	侦测该文件名是否存在且为『非空白文件』？
		3. 两个文件之间的比较，如： test file1 -nt file2
		-nt	(newer than)判断file1 是否比file2 新
		-ot	(older than)判断file1 是否比file2 旧
		-ef	判断file1 与file2 是否为同一文件，可用在判断hard link 的判定上。主要意义在判定，两个文件是否均指向同一个inode 
		4. 关于两个整数之间的判定，例如test n1 -eq n2
		-eq	两数值相等(equal)
		-ne	两数值不等(not equal)
		-gt	n1 大于n2 (greater than)
		-lt	n1 小于n2 (less than)
		-ge	n1 大于等于n2 (greater than or equal)
		-le	n1 小于等于n2 (less than or equal)
		5. 判定字串的资料
		test -z string	判定字串是否为0 ？若string 为空字串，则为true
		test -n string	判定字串是否非为0 ？若string为空字串，则为false。
		注： -n亦可省略
		test str1 == str2	判定str1 是否等于str2 ，若相等，则回传true
		test str1 != str2	判定str1 是否不等于str2 ，若相等，则回传false
		6. 多重条件判定，例如： test -r filename -a -x filename
		-a	(and)两状况同时成立！例如test -r file -a -x file，则file 同时具有r 与 x 权限时，才回传true。
		-o	(or)两状况任何一个成立！例如test -r file -o -x file，则file 具有r 或 x 权限时，就可回传true。
		!	反相状态，如test ! -x file ，当file 不具有x 时，回传true
		

		OK！现在我们就利用test 来帮我们写几个简单的例子。首先，判断一下，让使用者输入一个文件名，我们判断：

			这个文件是否存在，若不存在则给予一个『Filename does not exist』的讯息，并中断程式；
			若这个文件存在，则判断他是个文件或目录，结果输出『Filename is regular file』或 『Filename is directory』
			判断一下，执行者的身份对这个文件或目录所拥有的权限，并输出权限资料！

			#!/bin/bash
			read -p "please enter a filename: " file
			#判断输入是否为空,为空就退出
			test -z $file  &&  echo "you need enter a name" && exit
			#判断是否存在,不存在退出
			test ! -e $file && echo "not exit " && exit
			#判断是文件还是目录
			test -f $file && echo "$file is a file" || echo "$file is a direct"

			test  -r $file && echo "$file have r " 
			test  -w $file && echo "$file have w "
			test  -x $file && echo "$file have x "

	[] 和test一样
		[ -e ${HOME} ]; echo $?
		0

		[ "${HOME}" == "${MAIN}" ]
			#注意空格,其实=与==都可以，但bash中=是变量设置,==逻辑判断,建议最好==

		中括号[]内的每个组件都需要有空格分隔
		在中括号内的变量,最好都以双引号括起来
		在中括号内的常,最好都以单或双引号括起来

		test用法与[]几乎一模一样,中括号比较常用在条件判断式If...then...fi中

		例执行一个程序让用户选择Y或N,当选择y或Y时,显示OK,continue.当选择n或N时,显示Oh,interrupt,选择其它显示I don't know what your choice is
			#!/bin/bash

			read -p "please enter y/Y or n/N : " num

			[ "$num" == "y" -o "$num" == "Y" ] && echo "OK, continue" && exit
			[ "$num" == "n" -o "$num" == "N" ] && echo "Oh, interrupt" && exit

			echo " I don't know what is your choice is"
			#-o或连接

	shell脚本的默认变量
		bash 3.sh 1   2   3   4
			  $0  $1  $2  $3  $4 ....

		$# 代表后接的参数个数
		$@ 代表 "$1" "$2" "$3" "$4",变都都是独立的(用双引号括起来)
		$* 代表 "$1c$2c$3c$4", 其中c为分隔符,默认空格
			#$@与$*有所不同,记$@即可

		#!/bin/bash

		echo "script name is $0"
		echo "total have $# 参数"
		test "$#" -lt "2" && echo "参数太少" && exit
		echo "all name is $@"
		echo "first is $1"
		echo "second is $2"
		
		上面脚本输出 >>
		script name is 2.sh
		total have 4 参数
		all name is 1 2 3 4
		first is 1
		second is 2

		shitf 造成参数变量号码偏移
		#!/bin/bash

		echo "script name is $0"
		echo "total have $# 参数"
		echo "all name is $@"
		shift #偏移,移动变量
		echo "total have $# 参数"
		echo "all name is $@"
		shift 3 #偏移3
		echo "total have $# 参数"
		echo "all name is $@"

		上面脚本结果>>
		bash 3.sh 1 2 3 4 5 6 
		script name is 3.sh
		total have 6 参数
		all name is 1 2 3 4 5 6
		total have 5 参数
		all name is 2 3 4 5 6
		total have 2 参数
		all name is 5 6

	条件判断
		if....then

		单层,简单条件判断式
			if [ 条件判断式 ]; then
				当条件判断成立时,可以进行的命令内容
			fi 

		多层
			if [ 条件判断式 ]; then
				当条件判断成立时,可以进行的命令内容
			else
				当条件判断不成立时,可执行的命令
			fi

			if [ 条件判断式 ]; then
				语句
			elif [ 条件判断式 ]; then
				语句
			else
				语句
			fi

		多括号[]之间以 && 或 || 来隔开,括呈间的&&或||与命令行执行的状态不同
			&& 代表 and 
			|| 代表 or

		例
		#!/bin/bash
		read -p "please enter (y/n): " yn

		if [ "$yn" == "y" ] || [ "$yn" == "Y" ]; then
		        echo "ok,continue"
		        exit 0
		elif [ "$yn" == "n" ] || [ "$yn" == "N" ]; then
		        echo "oh, stop"
		        exit 0
		else
		        echo "i don't know what your choice is"

		fi

		例 利用$1变量
		#!/bin/bash

		if [ "$1" == "" ]; then
		        echo "you need do it like --> ${0} something"
		elif [ "$1" == "Hello" ]; then
		        echo "Hello,how are you"
		elif [ "$1" != "Hello" ]; then
		        echo "you can only input 'Hello'"
		else
		        echo "i don't know what you do"
		fi

		检测端口打开
		#!/bin/bash
		#先将netstat -tunlp的结果数据存到内存当中,不用一直执行netstat
		testfile="/dev/shm/netstat_check.txt"
		netstat -tunlp > $testfile

		testing=$(grep ":80" ${testfile})  #grep :80的结果放到变量中
		if [ "$testing" != "" ]; then     #有数据说明Port打开,为空说明没有打开
		        echo "80 port is open"
		fi
		testing=$(grep ":22" ${testfile})
		if [ "$testing" != "" ]; then
		        echo "22 port is open"
		fi


		testing=$(grep ":25" ${testfile})
		if [ "$testing" != "" ]; then
		        echo "25 port is open"
		fi

		testing=$(grep ":21" ${testfile})
		if [ "$testing" != "" ]; then
		        echo "21 port is open"
		fi


		输入退伍时间,算出剩余退伍天数
		#!/bin/bash

		read -p "please enter you 退伍 day in: " rday

		#!/bin/bash

		read -p "please enter you 退伍 day in: " rday

		#判断输入格式
		ruwu_day=$(echo $rday | grep "[0-9]\{8\}")
		if [ "$ruwu_day" == "" ]; then
		        echo "you should input 20200520"
		        exit 1
		fi

		#退伍的时间变成总共秒数
		declare -i rs=$(date --date="$rday" +%s)

		#今天时间的总共秒数
		declare -i ts=$(date +%s)

		#剩余时间秒数
		declare -i sw=$(( ${rs} -${ts} ))

		#秒数换算成天数
		declare -i day=$(( ${sw}/60/60/24 ))

		if [ "$day" -lt "0" ]; then
		        echo "你已退伍$((-1*${day}))天"
		else
		        echo "你还剩余 ${day} 天退伍"
		fi

		#秒数为自19700101累积而来的秒数

	case

		case $变量名称 in       #关键字case,变量前有美刀符号

		  "第一个变量内容")      #每个变量内容用双引号,右括号为关键字
		  程序段
		  ;;				#每个类别结尾用;;处理

		  "第二个变量内容")
		  程序段
		  ;;

		  *)    #最后一个变量内容都用*, 代表其他值,但不包含上面的变量内容
		  ;;
	esac      #结尾反过来写


		例，交换式变量
		#!/bin/bash

		read -p "please input your choicce (1/2/3): " cho

		case $cho in
		        "1")
		                echo "you choice 1"
		        ;;
		        "2")
		                echo "you choice 2"
		        ;;
		        "3")
		                echo "you choice 3"
		        ;;
		        *)
		                echo "you should input 1/2/3"
		        ;;
		esac

		利用$1
		#!/bin/bash

		case $1 in
		        "hello")
		        echo "hello,how are you"
		        ;;
		        "")
		        echo "you must enter something like -->${0} someword"
		        ;;
		        *)
		        echo "user ${0} hello"
		esac

	function(函数)

		function fname() {
			程序段
		}

		注意函数一定要放在脚本的最前面,因为脚本是从上面下从左而右执行分析

		例
		#!/bin/bash

		function printit() {
		        echo -n "your choice is " #-n后续不换行在同一行显示
		}


		case $1 in
		        "one")
		                printit; echo $1 | tr  'a-z' 'A-Z' #大小写转换
		        ;;
		        "two")
		                printit; echo $1 | tr  'a-z'  'A-Z'
		        ;;
		        "three")
		                printit; echo $1 | tr  'a-z'  'A-Z'
		        ;;
		        *)
		                echo "you should input  one/two/three"
		        ;;
		esac

	function内置变量
		#!/bin/bash

		function printit() {
		        echo  "your choice is ${1} " $$1与onw无关,要参考下面的命令执行
		        #echo "your choice is ${1} ${2}"
		}


		case $1 in
		        "one")
		                printit 1 #带参数1
		        ;;
		        "two")
		                printit 2
		                #printit 2 3      #这样会传递两个参数进函数
		        ;;
		        "three")
		                printit 3
		        ;;
		        *)
		                echo "you should input  one/two/three"
		        ;;
		esac

		#sh one -->1  sh two-->2 sh three-->3

	loop(循环)
		while do done, until do done  (不固定循环)

		while [ conditin ] 
		do          #循环开始
			程序段
		done		#循环结束

		#while是当contition成立时,就进行循环

		until [ condition ]
		do
			程序段
		donw   
		#until刚好相反,当条件满足时,终止循环

			例 while
			#!/bin/bash

			while [ "$yn" != "yes" -a "$yn" != "YES" ]
			do
			        read -p "please enter yes: " yn
			done
			#只要不是输入yes或YES就一直循环让其输入,注意 -a

			例until
			#!/bin/bash
			until [ "$yn" == "yes" -o "$yn" == "YES" ]
			do
			        read -p "plesa enter yes: " yn
			done
	        #只要是yes或YES，就停止输入

			例计算1+2+3...+99+100
			#!/bin/bash
			declare -i sum=0
			declare -i total=0
			while [ "$sum" -le "100" ]
			do
			        total=$(( $total + $sum ))
			        sum=$(( $sum + 1))
			done

			echo "1+2+3+....99+100= $total"

		for..do...done(固定循环)

			for var in con1 con2 con3....
			do
				程序段
			done

			第一次循环时,$var内容为con1
			第一次循环时,$var内容为con2
			......

			例分别输出动物名
			#!/bin/bash

			for animal in dog cat elephot
			do
			        echo "this is $animal"
			done

			例用id利用for循环查看账号
			#!/bin/bash

			for i in $(cat /etc/passwd | cut -d ':' -f 1)
			do
			        id $i
			done
			~         


			例用Ping测试主机连线
			#!/bin/bash
			ip="192.168.1."
			host=$(seq 1 20) #sed连续1到20,也可以用{1..20}代替

			for i in $host
			do
			        ping -c 1 -w 1 ${ip}${i} &> /dev/null
			        if [ "$?" == "0" ]; then
			                echo "${ip}${i} is UP"
			        else
			                echo "${ip}${i} is DOWN"
			        fi
			done

			例,输入一个目录,用for例出目录内的文件的权限
			#!/bin/bash
			read -p "please enter a dicrect name: " dic

			#判断目录不为空与存在
			if [ "${dic}" == "" -o ! -d "$dic" ]; then
			        echo "you should enter a direct"
			        exit 1
			fi

			file=$(ls $dic)

			for i in $file
			do
			        test -r ${dic}/${i} && echo "$i have r"
			        test -w ${dic}/${i} && echo "$i have w"
			        test -x ${dic}/${i} && echo "$i have x"
			done

		for..do...done(数值算理)

			for (( 初始值;限制值;赋值运算 ))
			do 
				程序段
			done

			#初始值,某个变量在循环当中的初始值,如i=1
			#限制值,当变量的值在这个限制值的范围内,就继续进行循环,如i<=100
			#赋值运算,每做一次循环,变量也变化,如i=i+1

			例,输入一个数字n然后计算1+2+...n
			#!/bin/bash

			read -p "please enter a nmuber , i will count 1+2+....number : " nu

			if [ "$nu" -le "0" ]; then
			        echo "you shoul input a number > 0"
			        exit 1
			fi

			declare -i sum=0

			for (( i=1;$i <= $nu;i++))
			do
			         sum=$(($sum + $i))
			done

			echo "1+2+....+$nu = $sum"

		例随机数与数组结合随机生成吃饭选择

			#!/bin/bash

			eat[1]="粉之都"
			eat[2]="云吞"
			eat[3]="生料粉"
			eat[4]="外卖"
			eat[5]="鸡饭"
			eat[6]="鸭饭"
			eat[7]="叉烧饭"
			eat[8]="猪肉饭"
			eat[9]="青菜饭"

			rx=9

			rand=$((${RANDOM}*${rx} / 32767 + 1))

			echo "today we eat ${eat[$rand]}"


	shell脚本的跟踪与调试
		-n 不要执行脚本,仅查询语法的问题
			如sh -n test.sh若语法没问题，则什么也不会显示
		-x 将使用到的脚本内容显示到屏幕上(会执行脚本)


20200602,
linux账号管理与ACL权限设置

	linux的账号与用户组

		用户的标识符 UID与GID
			计算机只会认ID,账号与ID对应只是方便人记忆,id与账号对应在/etc/passwd中

			每个登录的用户都会有两个ID，UID(user id)与GID(group id)

			文件有 拥有者id与拥有人组id,利用/etc/paswwd与 /etc/group对应显示

			如若修改/etc/passwd里的一般账号uid为其它数字,那原先属于该用户的文件的拥有者属性就会变成数字(因为id与user不对应),且该用户下次登录时进不了家目录(权限也跟着变了),所以实际环境中不要随意修改/etc/passwd

		用户账号
			要登录系统,账入账号与密码后
				1 先查找/etc/passwd比对是否有输入的账号,如果没有则退出,如果有就把uid与gid读了来,另外该账号的家目录与shell设置也一并读出
				2 然后再核对密码,系统会过入/etc/shadow里面找出对应的账号的Uid然后比对刚刚输入的密码与shadow文件是否一样
				3 如果一切顺便就进行shell管理阶段

			/etc/passwd文件说明
				head -n 3 /etc/passwd
				root:x:0:0:root:/root:/bin/bash
				bin:x:1:1:bin:/bin:/sbin/nologin

				每一行用:隔开，共有7段

				1 账号名称,用来对应uid
				2 密码, 只显示x，为了安全密码数据改放到/etc/shadow
				3 uid
					0 代表系统管理员,如需其它账号也具有root权限,将账号Uid改为0即可,
					不建议多个容易乱
					1~999 1000以下留给系统作为保留账号只是一个习惯
						1~200 由Linx发行版自行建立的系统账号
						201~999 若用户有系统账号需求，可以用
					1000~60000 给一般用户使用
				4 GID 与/etc/group有关,规范组名与GID对应而已
				5 用户信息栏说明
				6 家目录,可以修改
				7 shell

			/etc/shadow 文件结构
				head -n 3 /etc/shadow
				root:$6$esu2az6WJraoEBnx$4qVMw/P4z4gn2S/RFhDD/SiyY2MZsM6xlfro8EFxrcvldSweyqFcF.OWrm2/vUG/.VXc5a4R2yDioqr1NS3Aw/::0:99999:7:::
				bin:*:17834:0:99999:7:::

				1 账号名称
				2 密码(经过编码的密码(摘要)),目前常用SHA编码技术,一些软件会在可在此段前加上！或*让它(暂时失效)
				3 最近修改密码的日期,如bin17834则是以1970年1月1日到现在的天数
				4 密码不可被修改的天数(与3相比),记录最近一次被更改后需要经过几天才可以再被修改
				5 密码需要重新修改的天数(与3相比),记录最近一次更改密码后,在几天内需要再次修改密码,如上的99999就没有强制的意思
				6 密码需要修改期限前的警告天数(与5相比),当密码的有效期快要到时(5),系统会根据这个字段的设置发了警告信息给这个账号,如上面的7,密码到期前7天之内,系统会警告该用户
				7 密码过期后的账号宽限时间(密码失效日)与(5相比),密码的有效日期为3(更新日期)+5(重新修改日期),过了该期限后用户依旧没有更改密码,那密码就算过期,过期后该账号还是可以登陆系统获得shell,但登录后系统会强制要求你必须重新设置密码才能继续使用,该字段的功能就是密码过期几天后,用户还是没有改密码,那这个账号的密码将会失效,即该账号再也无法使用该密码登录
				8 账号失效时间
				9 保留

			密码忘记
				一般用户密码忘记可以用root通过passwd命令直接重置密码即可
				root密码忘记
					重启进入单人维护模式,系统会主动给予root权限的bash接口，再以passwd修改
					以live cd启动后挂载根目录云修改/etc/shadow，将root的密码字段清空,重启空再修改密码

		用户组
			/etc/group
			head -n 2 /etc/group
			root:x:0:
			bin:x:1:
			
			1 组名,3 GID 对应
			2 用户组密码(很少用)
			3 GID, /etc/passwd第四个字段使用的GID对应的用户组名,就是这里对应出来
			4 此用户组支持的账号名称,一个账号可以加入多个用户组,某账号想加入此组,将账号填入这字段即可(新版的linux中,初始用户组的用户群已经不会加入这个字段)


			有效用户组与初始用户组

				/etc/passwd的第4栏的GID,就是所谓的初始用户组,用户一登录系统就会马上拥有这个用户组的相关权限

				[root@localhost ~]# grep dmtsai /etc/passwd /etc/group /etc/gshadow
				/etc/passwd:dmtsai:x:1003:1004::/home/dmtsai:/bin/bash
				/etc/group:users:x:100:dmtsai
				/etc/group:dmtsai:x:1004:
				/etc/gshadow:users:::dmtsai
				/etc/gshadow:dmtsai:!::

				#在passwd里看到,dmtsai的GID为1004,/etc/group对应下的1004为dmtsai,这就是初始用户组,所以并不需要在第4字段写入该账号
				而users并非dmtsai的初始用户组,所以要第第4栏加入,这样dmtsai才够加入users这个组  #usermod -a -G users dmtsai
				因此dmtsai账号同时支持dmtsai与users这两个用户组,在rwx文件时,针对用户组部分，只要是users与dmtsai拥用的功能,dmtsai用户都拥有
				新文件的用户组是哪个还要看有效用户组(effctive group)

				[dmtsai@localhost ~]$ groups #查看有交与支持的用户组 
				dmtsai users
				#支持两个组，有效用户组为第一个dmtsai

				touch test
				[dmtsai@localhost ~]$ ll
				total 0
				-rw-rw-r--. 1 dmtsai dmtsai 0 Jun  2 21:26 test
				#有效用户组新建文件的属性都是dmtsai
			
				修改有效用户组,前提是想要切换的用户组必须是已经有支持的用户组
				[dmtsai@localhost ~]$ newgrp users
				[dmtsai@localhost ~]$ groups 
				users dmtsai
				[dmtsai@localhost ~]$ touch test2
				[dmtsai@localhost ~]$ ll test2
				-rw-r--r--. 1 dmtsai users 0 Jun  2 21:35 test2
				[dmtsai@localhost ~]$ groups
				users dmtsai
				[dmtsai@localhost ~]$ exit
				exit
				[dmtsai@localhost ~]$ groups 
				dmtsai users

				#注意newgrp可以修改用户的有效用户组,而且是另外以一个shell来提供这个功能的,因此要回到原来的环境中要exit

				用户加入不同的用户组有两人方法,一个是root利用usermod，另一个是通过用户组管理员以gshadow帮加入

				[root@localhost ~]# head -n 3 /etc/gshadow
				root:::
				bin:::
				daemon:::

				1 组名
				2 密码, 如为！或 空表示无合法密码,所以无用户组管理员
				3 用户组管理员的账号
				4 有加入该用户组的账号(与/etc/group相同)

				gshadow最大的功能就是建立用户组管理员,不过现在有sudo，这功能少用

		账号管理
			新增用户
			useradd [-u UID] [-g 初始用户组] [ -G 次要用户组] [-mM] \
				[-c 说明栏] [-d 家目录绝对路径] [-s shell] 账号

				-u uid,直接指定一个特定的UID给账号
				-g 接的是初始用户组,这个用户组的GID会被放到/etc/passwd的第4栏位
				-G 后面接的用户组则是该账号还可加入的用户组
				-M 强制,不要建立家目录(系统账号默认值)
				-m 强制,要建立使用者家目录(一般账号默认值)
				-c /etc/passwd第5栏,随便设置
				-d 指定某个目录成为家目录,需不使用默认值，要使用绝对路径
				-r 建立一个系统账号
				-s 后面接一个shell，默认/bin/bash
				-e 后面接一个日期,格式YYYY-MM-DD,账号失效日期
				-f shadow第7栏选项,指定密码是否会失效,0为立刻失效
					-l 永不失效

				例用默认值建立一个账号
				[root@localhost ~]# useradd virbd1
				[root@localhost ~]# ll -d /home/virbd1/
				drwx------. 2 virbd1 virbd1 62 Jun  2 22:25 /home/virbd1/
				[root@localhost ~]# grep virbd1 /etc/passwd /etc/shadow /etc/group
				/etc/passwd:virbd1:x:1004:1005::/home/virbd1:/bin/bash
				/etc/shadow:virbd1:!!:18415:0:99999:7:::
				/etc/group:virbd1:x:1005:
				#注意会在group里面加入一个与账号名称一样的组名,会在/home下面建立一个与账号同名的目录作为家目录，权限为700

				例已知有个users用户组,且UID1500不存在,请用users为初始用户组,1500为UID建立一个vbird2的账号
				useradd -u 1500 -g users vbird2
				#注意,因为是指定一个存在的用户组做为初始用户组,所以就不会在group里主动建立与账号同名的用户组了

				例建立系统账号
				 useradd -r vbird3
				[root@localhost ~]# ll -d /home/vbird3
				ls: cannot access /home/vbird3: No such file or directory
				[root@localhost ~]# grep vbird3 /etc/passwd /etc/shadow /etc/group
				/etc/passwd:vbird3:x:996:993::/home/vbird3:/bin/bash
				/etc/shadow:vbird3:!!:18415::::::
				/etc/group:vbird3:x:993:
				#系统账号uid一般应该小于1000,且默认主动不会建立家目录

			useradd参考文件
			root@localhost skel]# useradd  -D #默认值参考
			GROUP=100
			HOME=/home
			INACTIVE=-1
			EXPIRE=
			SHELL=/bin/bash
			SKEL=/etc/skel #家目录的内容数据参考目录,也可以增加文件
			CREATE_MAIL_SPOOL=yes #建立用户的mailbox,如/var/spool/mail/vbird1

			注意GROUP=100,针对用户组角度有两种机制
				私有用户组机制,系统会建立一个与账号同名的用户组给用户作为初始用户组,比较安全(centos使用私有用户组等)
				公共用户组机制,每个账号都属于user这个用户组(GID)

			uid与gid参考文件
			root@localhost skel]# cat /etc/login.defs  | grep -v "^$" | grep -v '^#'
			MAIL_DIR	/var/spool/mail
			PASS_MAX_DAYS	99999
			PASS_MIN_DAYS	0
			PASS_MIN_LEN	5
			PASS_WARN_AGE	7
			UID_MIN                  1000
			UID_MAX                 60000
			SYS_UID_MIN               201
			SYS_UID_MAX               999
			GID_MIN                  1000
			GID_MAX                 60000
			SYS_GID_MIN               201
			SYS_GID_MAX               999
			CREATE_HOME	yes
			UMASK           077
			USERGROUPS_ENAB yes
			ENCRYPT_METHOD SHA512 
			#系统设置一个账号uid时,会先是参考uid_min最小值后再找出passwd最大uid数值,两者相比找出最大的再加1就是新账号的UID
			USERGROUPS_ENAB的功能是如果使用userdel删除一个账号,且该账号所属的初始用户组已经没有人隶属于该用户组了,那么就删除掉该用户组


		passwd 
			修改密码
			--stdin 可以通过来自前一个管道的数据,作为密码输入,对shell脚本有帮助
			-l lock的意思,会将/etc/shadow第二栏最前面加上!使密码失效
			-u unlock
			-S 列出密码相关参数
			-n 后接天数,shadow第4栏位,多久不可修改密码
			-x 后接天数,shadow第5栏位,多久内必须修改密码
			-w 后接天数,shadow第6栏位,密码过期前的警告天数
			-i 后接天数,shadow第7栏位,密码失效日期

			passwd 账号 #修改一般账号密码,后不接账号为修改自己的密码
				密码不能与账号相同
				密码尽量不要选用字典里面出现的字符串
				密码必须超过8个字符
				密码尽量使用大小写符,数字,特殊字符$ - 等组合

			例用--stdin建立密码
			echo "abc123456" | passwd --stdin vbird2
				#缺点会在命令历史中出现,通常配合shell脚本

			passwd -S vbird2
			vbird2 PS 2020-06-02 0 99999 7 -1 (Password set, SHA512 crypt.)
			#密码建立时间20200602,99999修改天数,7警告日数与密码不会失效-1

			例管理vbird2密码使具有60天修改,密码过期10天后账号失效
			[root@localhost pam.d]# passwd -x 60 -i 10 vbird2
			Adjusting aging data for user vbird2.
			passwd: Success
			[root@localhost pam.d]# passwd -S vbird2
			vbird2 PS 2020-06-02 0 60 7 10 (Password set, SHA512 crypt.)

			锁住用户
			[root@localhost pam.d]# passwd -l vbird2
			Locking password for user vbird2.
			passwd: Success
			[root@localhost pam.d]# passwd -S vbird2
			vbird2 LK 2020-06-02 0 60 7 10 (Password locked.)
			[root@localhost pam.d]# grep 'vbird2' /etc/shadow
			vbird2:!!$6$.CAwZp2y$fltb7soZ6a2gY29ARCBleF7KjToV9GGrcEqX8n7.ia2dH8L.oZLRXwtFBFxYHUG5mgQCgr8IVySQyA6oresEn1:18415:0:60:7:10:: 
			[root@localhost pam.d]# passwd -u vbird2  #解锁
			Unlocking password for user vbird2.
			passwd: Success

			#锁住用户其实是在shadow第二栏加了两个！,

			chage
				chage -l vbird2
				Last password change					: Jun 02, 2020
				Password expires					: Aug 01, 2020
				Password inactive					: Aug 11, 2020
				Account expires						: never
				Minimum number of days between password change		: 0
				Maximum number of days between password change		: 60
				Number of days of warning before password expires	: 7

				chage可以更详细的显示密码参数,也可以修改设置值

				例用户一登录就强制它们一定要修改密码后才能使用
				[root@localhost pam.d]# useradd agetest
				[root@localhost pam.d]# echo "agetest" | passwd --stdin agetest 
				Changing password for user agetest.
				passwd: all authentication tokens updated successfully.
				[root@localhost pam.d]# chage -d 0 agetest 
				[root@localhost pam.d]# chage -l agetest 
				Last password change					: password must be changed
				Password expires					: password must be changed
				Password inactive					: password must be changed

			usermod 
				账号参数微调

				让账号失效
				usermod -e "2020-6-30" vbird2
				[root@localhost ~]# chage -l vbird2
				Last password change					: Jun 02, 2020
				Password expires					: Aug 01, 2020
				Password inactive					: Aug 11, 2020
				Account expires						: Jun 30, 2020

				为vbird3创建家目录
				[root@localhost ~]# ll -d /home/vbird3
				ls: cannot access /home/vbird3: No such file or directory
				[root@localhost ~]# cp -a /etc/skel /home/vbird3
				[root@localhost ~]# chown -R vbird3:vbird3 /home/vbird3
				[root@localhost ~]# chmod 700 /home/vbird3

				#chown -R 连同家目录的使用者/用户组属性都一起修改
				#chmod没有-R,因为仅修改目录的权限而非内部文件的权限

			userdel
				删除用户

				#连同家目录一起删除
				userdel -r vbird2
				userdel: user vbird2 is currently used by process 15027

				#注意如果账户只是暂时不用,可以将passwd的账号失效日期(第8字段)为0即可,确认账号真的不需要再删除,可以用find / -user username来查看整个系统属于username的文件

		用户功能
			 id
			uid=0(root) gid=0(root) groups=0(root) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
			#可以查看uidgid与支持的用户组,context是selinux先不理

			id vbird100
			id: vbird100: no such user
			#也可以利用id判断用户是否存在

			finger
				查看用户相关信息
			chfn
				change finger
			chsh
				change shell
			#以上三个少用

		新增与删除用户组
			group
				-g 后接特定GID,指定直接设置GID
				-n 建立系统用户组

				groupadd group1

			groupmod
				-g 修改即有GID
				-n 修改即有的用户组名称

				修改group1的名称为mygroup，GID为201
				groupmod -g 201 -n mygroup group1 
					#不要随意改GID,造成资源错乱

			groupdel
				删除用户组
				groupdel mygroub

				groupdel vbird1
				groupdel: cannot remove the primary group fo user 'vbird1'
				#不能删除,原因某个账号的初始用户组使用该用户组
					删除方法
						修改vbird1 GID
						删除vbird1这个用户

		用户组管理员功能
			gpasswd
				关于系统管理员(root)做的操作
				gpasswd groupname
				gpasswd [-A user1,...] [-M user3,...] groupname
				gpasswd [-rR] groupname

				  : 若没有任何参数,表示设置groupname密码
				  -A 将groupname的管理权交由后面的使用者管理
				  -M 将某些账号加入这个用户组
				  -r 将groupname的密码删除
				  -R 让groupname的密码失效

				关于用户组管理员做的操作
					-a 将某位使用者加入到groupname这个用户组中
					-d 将某位使用者删除出用户组

				groupadd testgroup #添加一个用户组
				gpasswd testgroup #设置用户组密码
				[root@localhost ~]# gpasswd -A vbird1 testgroup #加入用户组管理员为vbird1
				[root@localhost ~]# grep testgroup /etc/group /etc/gshadow
				/etc/group:testgroup:x:1502:
				/etc/gshadow:testgroup:$6$atXSm.BoB$XmXx4ZF1jhMjVTobmBHo18alp4r2vtkULI45iHDuya7bPcLicXd6Qx.bwV9UYcGHAmnsJxy/xX7OBppPi82Xf1:vbird1:
				[root@localhost ~]# su - vbird1
				[vbird1@localhost ~]$ id vbird1
				uid=1502(vbird1) gid=1503(vbird1) groups=1503(vbird1)
				[vbird1@localhost ~]$ gpasswd -a vbird1 testgroup #用户组管理员给组加入成员
				Adding user vbird1 to group testgroup
				[vbird1@localhost ~]$ id
				uid=1502(vbird1) gid=1503(vbird1) groups=1503(vbird1) context=unconfined_u:unconfined_r:unconfined_t:s0-s0:c0.c1023
				[vbird1@localhost ~]$ gpasswd -a vbird3 testgroup  #用户组管理员给组加入成员
				Adding user vbird3 to group testgroup
				[vbird1@localhost ~]$ grep testgroup /etc/group
				testgroup:x:1502:vbird1,vbird3

				例用户pro1 pro2 pro3为同一个项目计划的开发人员,让这三个用户在同一个目录下工作,但这三个目录还是拥有自己的家目录与基本的私用户组,工作目录为/srv/projecta

				[root@localhost ~]# mkdir /srv/projecta
				[root@localhost ~]# groupadd progroup #建立公共用户组
				
			
				[root@localhost ~]# chown root:progroup -R /srv/projecta/
				[root@localhost ~]# ll -d /srv/projecta/
				drwxr-xr-x. 2 root progroup 6 Jun  3 14:38 /srv/projecta/
				[root@localhost ~]# useradd -G progroup pro1 #让账号支持用户组
				[root@localhost ~]# useradd -G progroup pro2			root@localhost ~]# useradd -G progroup pro3
				[root@localhost ~]# grep 'progroup' /etc/group
				progroup:x:1508:pro1,pro2,pro3		
				[root@localhost ~]# chmod 2770 /srv/projecta/ #设置权限(包括SGID,这样用户新建的文件用户组属于公共用户组)
				[root@localhost ~]# ll -d /srv/projecta/
				drwxrws---. 2 root progroup 6 Jun  3 14:38 /srv/projecta/

				账号设置密码省略

				#以上例子不能针对某个特定账户设置专属权限,如myuser3我只想让其能查看不能修改数据,让其不加入公共组给目录其它权限rx，但这样其它用户也可以访问数据


		主机的详细权限规划 ACL
			传统的linux权限只能会对一个用户,一个用户组,非此用户组的三种身份权限设置

			ACL可以针对单一用户,用户组,单一文件或目录等来设置权限

			ACL已经默认加入了所有常见的的Linux文件系统的挂载参数中

			查看是否支持ACL
				dmesg | grep -i acl  #有数据即可

			setfacl #设置某个目录或文件的ACL
				-m 设置后续的ACL参数给文件使用,不可与-x合用
				-x 删除后续的ACL参数,不可与-m合用
				-b 删除所有的ACL设置参数
				-k 删除(默认的)ACL参数
				-R 递归设置ACL,即包括子目录都会被设置起来
				-d 设置默认acl参数,只对目录有效,在该目录新建的数据会引用止默认值

			例针对特定使用者的方式
			touch acl_test1
			[root@localhost ~]# ll acl_test1 
			-rw-r--r--. 1 root root 0 Jun  3 16:34 acl_test1
			  
			[root@localhost ~]# setfacl -m u:vbird1:rx acl_test1 
			[root@localhost ~]# ll acl_test1 
			-rw-r-xr--+ 1 root root 0 Jun  3 16:34 acl_test1 #注意后面有个+,且与原本的644权限有差异
			[root@localhost ~]# setfacl -m u::rwx acl_test1 #无用户说明是设置该文件拥有者
			[root@localhost ~]# ll acl_test1 
			-rwxr-xr--+ 1 root root 0 Jun  3 16:34 acl_test

			查看ACL
			getfacl acl_test1 
			# file: acl_test1 #文件明
			# owner: root     #文件拥有者
			# group: root     #文件所属用户组
			user::rwx         #使用者列表为空代表文件拥有者的权限
			user:vbird1:r-x   #针对vbird1的权限为rx
			group::r--        #针对文件用户组的权限设置为r
			mask::r-x         #此文件默认有效权限(mask)
			other::r--        #其他人权限

			针对特定用户组的设置
			setfacl -m g:mygroup1:rx acl_test1 
			[root@localhost ~]# getfacl acl_test1 
			# file: acl_test1
			# owner: root
			# group: root
			user::rwx
			user:vbird1:r-x
			group::r--
			group:mygroup1:r-x   #新增
			mask::r-x

			针对有效权限设置
			setfacl -m m:r acl_test1 
			[root@localhost ~]# getfacl acl_test1 
			# file: acl_test1
			# owner: root
			# group: root
			user::rwx
			user:vbird1:r-x			#effective:r--
			group::r--
			group:mygroup1:r-x		#effective:r--
			mask::r--
			other::r--

			#mask代表用户或用户组所设置的权限必须要存在于mask的权限设置范围内才会生效,上面的例子mask仅为r，所以vbird1与mygroup虽有设置rx,但却只有r权限,通常mask设置rwx

			承接pro项目例子,让myuser1只能查看目录数据,不能修改
			setfacl -m u:myuser1:rx /srv/projecta #设置rx权限
			[root@localhost ~]# su - myuser1
			Last login: Wed Jun  3 17:04:33 CST 2020 on pts/0
			[myuser1@localhost ~]$ cd /srv/projecta/
			[myuser1@localhost projecta]$ ll
			total 0
			[myuser1@localhost projecta]$ ls -la  #确实可以查询数据(也可以复制到其它目录)
			total 0
			drwxrws---+ 2 root progroup  6 Jun  3 14:38 .
			drwxr-xr-x. 5 root root     52 Jun  3 14:38 ..
			[myuser1@localhost projecta]$ touch test  #不能修改
			touch: cannot touch ‘test’: Permission denied

			例新建文件查看属性
			[root@localhost projecta]# ll
			
			drwxr-sr-x. 2 root progroup 18 Jun  3 17:19 abc
			-rw-r--r--. 1 root progroup  6 Jun  3 17:07 test
			#发现文件后面并没有+号,代表acl属性没有继承,其它人属性还有

			使用默认权限设置让acl在目录下面的数据都有继承功能
			setfacl -m d:u:myuser1:rx /srv/projecta 

			[root@localhost projecta]# ll
			total 0
			drwxrws---+ 2 root progroup 6 Jun  3 21:48 abc
			-rw-rw----+ 1 root progroup 0 Jun  3 21:40 zzz1
			drwxrws---+ 2 root progroup 6 Jun  3 21:40 zzz2
			[root@localhost projecta]# getfacl abc
			# file: abc
			# owner: root
			# group: progroup
			# flags: -s-
			user::rwx
			user:myuser1:r-x
			group::rwx
			mask::rwx
			other::---
			default:user::rwx
			default:user:myuser1:r-x
			default:group::rwx
			default:mask::rwx
			default:other::---

			#default也有了，继承成功,myuser1继续拥有子目录与文件的acl权限

			例,承接上面,取消myuser1的设置,让pro3这个用户无法使用该目录
			setfacl -x u:myuser1 /srv/projecta #取消myuser1的ACL设置
			setfacl -x d:myuser1 /srv/projecta #取消myuser1的ACL默认值设置

			setfacl -m u:pro3:- /srv/projecta
				#设置一个用户或用户组没有权限时不能留空白,用-
			[myuser1@localhost ~]$ getfacl /srv/projecta/
			getfacl: Removing leading '/' from absolute path names
			# file: srv/projecta/
			# owner: root
			# group: progroup
			# flags: -s-
			user::rwx
			user:pro3:--- #pro3没有任何权限

		用户身份切换
			一般情况下用一般用户操作,需要用户root权限时再切换

			像apache这些程序可以建立一个名为apache的用户来启动apache,相对安全,程序被攻击,不至于系统会损坏

			su
				切换身份

				- 单纯使用su - 代表使用login-shell的变量文件读取方式来登录系统,后无账号则是切换为root
				-l 与- 类似,也是login-shell登录,但后面要接账号
				-c 仅进行一次命令,所以-c后面可接命令

				一般用户切换为root,要用
					su -
				root切换为其它等用
					su -l 账号

				su - -c "head -n 3 /etc/shadow" #仅用root执行一次命令

				su缺点是一般用户都要知道root的密码,不安全

			sudo
				一开始系统默认的只有root可以执行
				-b 将后续的命令放到后台中让系统自行执行,不与目前的shell产生影响
				-u 后面可以接欲切换的使用者,若无此项则代表切换身份为root

				例以sshd身份在/tmp下建立一个mysshd文件
				sudo -u sshd touch /tmp/mysshd  #用root创建然后再chown也行

				以vbird1身份建立~vbird1/www并于其中建立index.html文件
				sudo -u vbird1 sh -c "mkdir ~vbird1/www;cd ~vbird1/www; \
				echo 'This is a test'>index.html"
					#~vbird1就是概用户根目录

			visudo
				能否执行sudo与/etc/sudoers设置有关,不建议用vi去编辑/etc/sudoers,使用visudo，退出visudo退其会自行检测语法正确性

				单一用户可使用root所有命令
				visudo
				....
				root    ALL=(ALL)       ALL
				vbird1  ALL=(ALL)       ALL
				#各字段意思 
					1 root 操作系统的哪个账号可以使用sudo
					2 ALL 登录者来源主机名,设置可以指定客户端计算机(别的机子来源),默认值root可来自任何一台主机
					3 ALL 可切换的身份 这个账号可以切换成什么身份来执行后续的命令,默认root可以切换任何人
					4 ALL 可执行的命令,可用该身份执行什么命令,命令要使用绝对路径,默认root可以切换任何身份且进行任何命令

				上面vbird1加入sudo了
				例
					[vbird1@localhost ~]$ sudo tail -n 1 /etc/shadow
						#再输入密码

				
				利用wheel用户组以及免密码的功能处理visudo
				visudo
				....
				%wheel  ALL=(ALL)       ALL

				# % 在最左边加上%代表后面接的是一个用户组

				usermod -a -G wheel pro1 #让pro1加入wheel组，这样pro1就拥有sudo权限了


				sudo免密
				# %wheel        ALL=(ALL)       NOPASSWD: ALL
					#把#去掉利用此条设置

				有限制的命令操作
				myuser1 ALL=(root)       !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, !/usr/bin/passwd root
					#给myuser1拥用给其它用户修改密码的权限,且禁止修改root密码

				别名设置visudo
				User_Alias ADMPW = pro1, pro2, pro3
				Cmnd_Alias ADMPWCOM = !/usr/bin/passwd, /usr/bin/passwd [A-Za-z]*, !/usr/bin/passwd root
				ADMPW   ALL=(root)   ADMPWCOM
				#ADMPW为创建的用户(要大写),后接实际用户，AMDPWCOM为命令别名(大写)

				sudo搭配su
				例让用户不用输入root密码而是输入自己的密码切换成root
				User_Alias ADMPW = pro1, pro2, pro3
				ADMPW   ALL=(root)   /bin/su -

		PAM模块(插入式验证模块)
			一个API,它提供一连串的验证,只要用户将验主阶段的需求告知PAM后,PAM就能够返回用户验证的结果(成功或失败),它是一套验证机制,可以给其它程序调用

			如passwd调用PAM的流程
				用户开始执行/usr/bin/passwd这个程序,并输入密码
				PAM模块会到/etc/pam.d找寻与程序(passwd)同名的配置文件
				将验证结果(成功,失败,其他信息)返回给passwd程序
				passwd程序会根据PAM返回的结果决定下一个操作(重新输入新密码或通过)

				cat  /etc/pam.d/passwd
				#%PAM-1.0       #版本说明
				auth       include	system-auth #每一行都是一个验证的过程
				account    include	system-auth
				password   substack	system-auth
				-password   optional	pam_gnome_keyring.so use_authtok
				password   substack	postlogin
				验证类别    控制标准   PAM模块与该模块的参数

				#include是包含引用后面的system-auth设置

			PAM的验证机制流程
				验证阶段(auth)
				授权阶段(account)
				密码阶段(password)
				会话阶段(session)

			详细参考鸟哥Linux13章账号管理


			其它文件
				limits.conf
					与PAM相关的文件,ulimit功能系统管理员可以通过PAM管理,ulimit命令执行只是针对当前的SHELL生效,limits.conf可以针对用户或用户组

					例设置vbird1只能建立100M的文件，且大于9000会警告
					#@student        -       maxlogins       4
					vbird1		soft	fsize	9000
					vird1 		hard    fsize   10000
					#第一栏用户或用户组(前面要加@),第4栏为限制的值,单位kb

					测试
					[vbird1@localhost ~]$ dd if=/dev/zero of=test bs=1M count=110
					File size limit exceeded

					例限制用户组，每次仅能有一个使用者登录系统（maxlogins)
					@pro1 	hard	maxlogins	1
					#注意只对初始用户组有效

					limit.conf修改完成后不用重启任何服务就生效,但是对已登录的用户无效,要下一次登录才生效,因为PAM是程序调用时才设置的

				/var/log/secure  /var/log/message
					如发生无法登录或其它错误时,可以查看这两个日志文件

		主机上的用户信息传递

			查询用户
			[root@localhost ~]# w    #与who差不多
			 14:28:35 up 8 days,  7:39,  3 users,  load average: 0.00, 0.01, 0.05
			USER     TTY      FROM             LOGIN@   IDLE   JCPU   PCPU WHAT
			root     tty1                      22May20  6days  0.71s  0.71s -bash
			root     pts/0    192.168.1.7      05Jun20  6days  0.49s  0.12s -bash
			root     pts/1    192.168.1.7      05Jun20  3.00s  0.08s  0.00s w

			[root@localhost ~]# lastlog  #与last相似
			Username         Port     From             Latest
			root             pts/1    192.168.1.7      Fri Jun  5 11:10:57 +0800 2020
			bin                                        **Never logged in**
			daemon                                     **Never logged in**
			adm                                        **Never logged in**
			#可查看所有用户(包括系统用户)登录时间

			用户对谈
				write
					针对一个用户来发送信息
				write root tty1
				hello
				....      #control + d完成发送的信息

				root用户可以mesg 拒绝收一其它用户的信息,但一般用户不能拒绝root发的信息
				mesg n   
				mesg #查看mesg是y或n


				wall
					对所有系统上面的用户发送信息

				wall "hello, i will shutdown server..."
					#用"字符发送消息",回车即发送完成

			mail
				wall write要等到用户在线才能收信息

				发送邮件
				mail -s "邮件标题" username@localhost
					寄给本机用户不用@localhost

				mail -s "hello" vbird1
				hello
				nice to meet you
				you
				.    #结束标志
				EOT

				利用数据流重定向写入内容
				mail -s "bashrc file content" vbird1 < ~/.bashrc

				通过管道将ls -al ~内容传给邮件
				ls -al ~ | mail -s "myfile" vbird1

				收邮件
				[root@localhost ~]# mail
				Heirloom Mail version 12.5 7/5/10.  Type ? for help.
				"/var/spool/mail/root": 2 messages
				>   1 leison@localhost.loc  Wed Jun  3 22:56  17/698   "*** SECURITY information for "
				    2 root                  Thu Jun 11 20:00  63/3163  "myfile"
				& 

				# & 为提示符
				  ? 可获得帮助

				 常用命令
				 	h 列出邮件标头,如要查看40封邮件左右的邮件标头 h 40
				 	d 删除邮件, 如删除第10封 d10 , 删除第20~40，d20-40
				 	s 将邮件保存为文件, 如保存第5封, s 5 ~/mail.file
				 	x 不做任何操作退出,无论刚刚是删除还是阅读x后都会无效
				 	q 保存后退出


（插入学习 iptables)
	iptables是按顺序比对规则(从上而下),若封包进入比对rule1符合时,就会对这个封包进行相应的action 1动作,而不会理会后续的rule2,rule3....,若不符合rule1,就会比对rule2,rule3...,如果所有的规则都不符合,就会透过预设动作来决定封包的去向

	例提供www服务的服务器,发现192.168.100.100恶意尝试入侵系统,拒绝它
	1 rule1 先抵挡192.168.100.100
	2 rule2 再让要求www服务的封包通过
	3 rule3 将所有封包丢弃
	以上为正确的，若如下

	1 rule2 再让要求www服务的封包通过
	2 rule1 先抵挡192.168.100.100
	3 rule3 将所有封包丢弃
	这样192IP就已经让它通过了而不会比对第2条规则

	Linux的iptables至少就有三个表格，包括管理本机进出的filter 、管理后端主机(防火墙内部的其他电脑)的nat 、管理特殊旗标使用的mangle (较少使用) 

	每个表格与其中链的用途分别是这样的：

		filter (过滤器)：主要跟进入Linux本机的封包有关，这个是预设的table喔！
		INPUT：主要与想要进入我们Linux本机的封包有关；
		OUTPUT：主要与我们Linux本机所要送出的封包有关；
		FORWARD：这个咚咚与Linux本机比较没有关系，他可以『转递封包』到后端的电脑中，与下列nat table相关性较高。

		nat (位址转换)：是Network Address Translation的缩写，这个表格主要在进行来源与目的之IP或port的转换，与Linux本机较无关，主要与Linux主机后的区域网路内电脑较有相关。
		PREROUTING：在进行路由判断之前所要进行的规则(DNAT/REDIRECT)
		POSTROUTING：在进行路由判断之后所要进行的规则(SNAT/MASQUERADE)
		OUTPUT：与发送出去的封包有关

		mangle (破坏者)：这个表格主要是与特殊的封包的路由旗标有关，早期仅有PREROUTING及OUTPUT链，不过从kernel 2.4.18之后加入了INPUT及FORWARD链。由于这个表格与特殊旗标相关性较高，所以像咱们这种单纯的环境当中，较少使用mangle这个表格。

		观察防火墙
		[root@www ~]# iptables-save [-t table] 
		选项与参数：
		-t ：可以仅针对某些表格来输出，例如仅针对nat 或filter 等等

		[root@www ~]# iptables-save
		# Generated by iptables-save v1.4.7 on Fri Jul 22 15:51:52 2011
		*filter                       <==星号开头的指的是表格，这里为filter 
		:INPUT ACCEPT [0:0]           <==冒号开头的指的是链，三条内建的链 
		:FORWARD ACCEPT [0:0]         <= =三条内建链的政策都是ACCEPT啰！
		:OUTPUT ACCEPT [680:100461]
		-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT  <==针对INPUT的规则
		-A INPUT -p icmp -j ACCEPT
		-A INPUT -i lo -j ACCEPT   <==这条很重要！针对本机内部介面开放！
		-A INPUT -p tcp -m state --state NEW -m tcp --dport 22 -j ACCEPT
		-A INPUT -j REJECT --reject-with icmp-host-prohibited
		-A FORWARD -j REJECT --reject-with icmp-host-prohibited  <==针对FORWARD的规则
		COMMIT
		# Completed on Fri Jul 22 15:51:52 2011

		清除规则
		[root@www ~]# iptables [-t tables] [-FXZ] 
		选项与参数：
		-F ：清除所有的已订定的规则；
		-X ：杀掉所有使用者"自订" 的chain (应该说的是tables ）啰；
		-Z ：将所有的chain 的计数与流量统计都归零

		范例：清除本机防火墙(filter)的所有规则 
		[root@www ~]# iptables -F 
		[root@www ~]# iptables -X 
		[root@www ~]# iptables -Z

		预定规则,当封包不在规则设定之内时,则封包的通过与否,以预定规则(policy)为准
			常都是将INPUT的policy定义为DROP啦，其他两个则定义为ACCEPT

			[root@www ~]# iptables [-t nat] -P [INPUT,OUTPUT,FORWARD] [ACCEPT,DROP] 
			选项与参数：
			-P ：定义政策( Policy )。注意，这个P 为大写啊！
			ACCEPT ：该封包可接受
			DROP ：该封包直接丢弃，不会让client 端知道为何被丢弃。

			范例：将本机的INPUT设定为DROP ，其他设定为ACCEPT 
			[root@www ~]# iptables -P INPUT DROP 
			[root@www ~]# iptables -P OUTPUT ACCEPT 
			[root@www ~]# iptables -P FORWARD ACCEPT 
			[root@www ~]# iptables-save
			# Generated by iptables-save v1.4.7 on Fri Jul 22 15:56:34 2011
			*filter
			:INPUT DROP [0:0]
			:FORWARD ACCEPT [0:0]
			:OUTPUT ACCEPT [0:0]
			COMMIT
			# Completed on Fri Jul 22 15:56:34 2011
			# 由于INPUT 设定为DROP 而又尚未有任何规则，所以上面的输出结果显示：
			# 所有的封包都无法进入你的主机！是不通的防火墙设定！(网路连线是双向的)

		基础比对语法
			[root@www ~]# iptables [-AI链名] [-io网路介面] [-p协定] \ 
			> [-s来源IP/网域] [-d目标IP/网域] -j [ACCEPT |DROP|REJECT|LOG] 
			选项与参数：
			-AI 链名：针对某的链进行规则的"插入" 或"累加"
			    -A ：新增加一条规则，该规则增加在原本规则的最后面。例如原本已经有四条规则，
			         使用-A 就可以加上第五条规则！
			    -I ：插入一条规则。如果没有指定此规则的顺序，预设是插入变成第一条规则。
			         例如原本有四条规则，使用-I 则该规则变成第一条，而原本四条变成2~5 号
			    链：有INPUT, OUTPUT, FORWARD 等，此链名称又与-io 有关，请看底下。

			-io 网路介面：设定封包进出的介面规范
			    -i ：封包所进入的那个网路介面，例如eth0, lo 等介面。需与INPUT 链配合；
			    -o ：封包所传出的那个网路介面，需与OUTPUT 链配合；

			-p 协定：设定此规则适用于哪种封包格式
			   主要的封包格式有： tcp, udp, icmp 及all 。

			-s 来源IP/网域：设定此规则之封包的来源项目，可指定单纯的IP 或包括网域，例如：
			   IP ：192.168.0.100
			   网域：192.168.0.0/24, 192.168.0.0/255.255.255.0 均可。
			   若规范为『不许』时，则加上! 即可，例如：
			   -s ! 192.168.100.0/24 表示不许192.168.100.0/24 之封包来源；

			-d 目标IP/网域：同-s ，只不过这里指的是目标的IP 或网域。

			-j ：后面接动作，主要的动作有接受(ACCEPT)、丢弃(DROP)、拒绝(REJECT)及记录(LOG)

		范例：设定lo成为受信任的装置，亦即进出lo的封包都予以接受 
		[root@www ~]# iptables -A INPUT -i lo -j ACCEPT
		没有列出-s, -d等等的规则，这表示：不论封包来自何处或去到哪里，只要是来自lo这个介面，就予以接受！这个观念挺重要的，就是『没有指定的项目，则表示该项目完全接受

		范例：只要是来自内网的(192.168.100.0/24)的封包通通接受 
		[root@www ~]# iptables -A INPUT -i eth1 -s 192.168.100.0/24 -j ACCEPT 
		#由于是内网就接受，因此也可以称之为『信任网域』啰。

		范例：只要是来自192.168.100.10就接受，但192.168.100.230这个恶意来源就丢弃 
		[root@www ~]# iptables -A INPUT -i eth1 -s 192.168.100.10 -j ACCEPT 
		[root@www ~]# iptables -A INPUT -i eth1 -s 192.168.100.230 -j DROP 
		#针对单一IP来源，可视为信任主机或者是不信任的恶意来源喔！

		记录某条规则的纪录
		iptables -A INPUT -s 192.168.2.200 -j LOG
		只要有封包来自192.168.2.200这个IP时，那么该封包的相关资讯就会被写入到核心讯息，亦即是/var/log/messages这个档案当中。 然后该封包会继续进行后续的规则比对。所以说， LOG这个动作仅在进行记录而已，并不会影响到这个封包的其他规则比对的


		TCP UDP端口比对
		[root@www ~]# iptables [-AI链] [-io网路介面] [-p tcp,udp] \ 
		> [-s来源IP/网域] [--sport埠口范围] \ 
		> [- d目标IP/网域] [--dport埠口范围] -j [ACCEPT|DROP|REJECT] 
		选项与参数：
		--sport 埠口范围：限制来源的埠口号码，埠口号码可以是连续的，例如1024:65535
		--dport 埠口范围：限制目标的埠口号码。

		范例：想要连线进入本机port 21的封包都抵挡掉： 
		[root@www ~]# iptables -A INPUT -i eth0 -p tcp --dport 21 -j DROP

		范例：想连到我这部主机的网芳(upd port 137,138 tcp port 139,445)就放行 
		[root@www ~]# iptables -A INPUT -i eth0 -p udp --dport 137:138 -j ACCEPT 
		[root @www ~]# iptables -A INPUT -i eth0 -p tcp --dport 139 -j ACCEPT 
		[root@www ~]# iptables -A INPUT -i eth0 -p tcp --dport 445 -j ACCEPT

		例如：只要来自 192.168.1.0/24 的1024:65535 埠口的封包，且想要连线到本机的ssh port 就予以抵挡，可以这样做：

		[root@www ~]# iptables -A INPUT -i eth0 -p tcp -s 192.168.1.0/24 \ 
		> --sport 1024:65534 --dport ssh -j DROP

		范例：将来自任何地方来源port 1:1023的主动连线到本机端的1:1023连线丢弃 
		[root@www ~]# iptables -A INPUT -i eth0 -p tcp --sport 1:1023 \ 
		> --dport 1:1023 --syn -j DROP


		外挂模块 mac state
		[root@www ~]# iptables -A INPUT [-m state] [--state状态] 
		选项与参数：
		-m ：一些iptables 的外挂模组，主要常见的有：
		     state ：状态模组
		     mac ：网路卡硬体位址(hardware address)
		--state ：一些封包的状态，主要有：
		     INVALID ：无效的封包，例如资料破损的封包状态
		     ESTABLISHED：已经连线成功的连线状态；
		     NEW ：想要新建立连线的封包状态；
		     RELATED ：这个最常用！表示这个封包是与我们主机发送出去的封包有关

		范例：只要已建立或相关封包就予以通过，只要是不合法封包就丢弃 
		[root@www ~]# iptables -A INPUT -m state \ 
		> --state RELATED,ESTABLISHED -j ACCEPT 
		[root@www ~] # iptables -A INPUT -m state --state INVALID -j DROP


		范例：针对区域网路内的aa:bb:cc:dd:ee:ff主机开放其连线 
		[root@www ~]# iptables -A INPUT -m mac --mac-source aa:bb:cc:dd :ee:ff \ 
		> -j ACCEPT 
		选项与参数：
		--mac-source ：就是来源主机的MAC 啦！
		#可用来针对内部有人改ip来上网,DROP掉它


20200616
磁盘配额(quota)与高级文件系统管理

磁盘配额	
	一般用途,针对网络服务
		针对网站,每个人的网页空间的容量限制
		针对邮件服务器,每个人的邮件空间限制
		针对文件服务器,每个人最大的可用网络硬盘空间

	针对linux系统主机
		限制某一用户组所能使用的最大磁盘配额，类似收费会员空间会更大
		限制某一用户的最大磁盘配额
		限制某一目录的最大磁盘配额
			旧的ext文件系统主要是针对整个文件系统来处理,新的xfs可以使用project模式针对个别的目录来配额

	使用限制
		ext文件仅能针对整个文件系统
		内核必须支持磁盘配额
		只对一般用户有效,root无效
		若启用selinux,并非所有目录可设置磁盘配额

	针对xfs文件系统
		分别针对用户，用户组或个别目录
		容量限制或文件数量限制(block或inode)
		软限制与硬限制
			如sort 400M, hard 500M,低过400正常使用,超过500系统锁住磁盘使用权，用户在400~500时每登录系统时,系统会主动发出磁盘容量将耗尽的信息,且给予一个宽限时间(默认7天),7天内不进行磁盘管理,soft的值会替换hard值，磁盘使用权会被锁住无法新增文件


	实例
		目的与帐号：现在我想要让我的专题生五个为一组，这五个人的帐号分别是myquota1, myquota2, myquota3, myquota4, myquota5，这五个用户的密码都是password ，且这五个用户所属的初始群组都是myquotagrp 。其他的帐号属性则使用预设值。

		帐号的磁碟容量限制值：我想让这五个用户都能够取得300MBytes 的磁碟使用量(hard)，档案数量则不予限制。此外，只要容量使用率超过250MBytes ，就予以警告(soft)。

		群组的限额(option 1)：由于我的系统里面还有其他用户存在，因此我仅承认myquotagrp 这个群组最多仅能使用1GBytes 的容量。这也就是说，如果myquota1, myquota2, myquota3 都用了280MBytes 的容量了，那么其他两人最多只能使用 (1000MB - 280x3 = 160MB) 的磁碟容量啰！这就是使用者与群组同时设定时会产生的后果。

		共享目录限额(option 2)：另一种设定方式，每个用户还是具有自己独立的容量限止，但是这五个人的专题共用目录在/home/myquota这里，该目录请设定为其他人没有任何权限的共享目录空间，仅有myquotagrp群组拥有全部的权限。且无论如何，该目录最多仅能够接受500MBytes的容量。请注意，群组(group)的限制与目录(directory/project)无法同时并存喔！所以底下的流程中，我们会先以群组来设计，然后再以目录限制来进一步说明！

		宽限时间的限制：最后，我希望每个使用者在超过soft 限制值之后，都还能够有14 天的宽限时间。

			#制作帐号环境时，由于有五个帐号，因此鸟哥使用script来建立环境！
			[root@study ~]# vim addaccount.sh 
			#!/bin/bash
			# 使用script 来建立实验quota 所需的环境
			groupadd myquotagrp
			for username in myquota1 myquota2 myquota3 myquota4 myquota5
			do
				useradd -g myquotagrp $username
				echo "password" | passwd --stdin $username
			done
			mkdir /home/myquota
			chgrp myquotagrp /home/myquota
			chmod 2770 /home/myquota

			[root@study ~]# sh addaccount.sh


			档案系统的支援与观察
			[root@study ~]# vim /etc/fstab 
			/dev/mapper/centos-home /home xfs defaults ,usrquota,grpquota    0 0
			 #其他项目鸟哥并没有列出来！重点在于第四栏位！于default后面加上两个参数！

			[root@study ~]# umount /home 
			[root@study ~]# mount -a 
			[root@study ~]# mount | grep home 
			/dev/mapper/centos-home on /home type xfs (rw,relatime,seclabel ,attr2,inode64, usrquota,grpquota )
			基本上，针对quota 限制的项目主要有三项，如下所示：

			uquota/usrquota/quota：针对使用者帐号的设定
			gquota/grpquota：针对群组的设定
			pquota/prjquota：针对单一目录的设定，但是不可与grpquota 同时存在！


			Quota 流程-2：观察Quota 报告资料
			[root@study ~]# xfs_quota -x -c "指令" [挂载点] 
			选项与参数：
			-x ：专家模式，后续才能够加入-c 的指令参数喔！
			-c ：后面加的就是指令，这个小节我们先来谈谈数据回报的指令
			指令：
			      print ：单纯的列出目前主机内的档案系统参数等资料
			      df ：与原本的df 一样的功能，可以加上-b (block) -i (inode) -h (加上单位) 等
			      report：列出目前的quota 项目，有-ugr (user/group/project) 及-bi 等资料
			      state ：说明目前支援quota 的档案系统的资讯，有没有起动相关项目等

			范例一：列出目前系统的各的档案系统，以及档案系统的quota挂载参数支援 
			[root@study ~]# xfs_quota -x -c "print"
			Filesystem Pathname
			/ /dev/mapper/centos-root
			/srv/myproject /dev/vda4
			/boot /dev/vda2
			/home /dev/mapper/centos-home ( uquota, gquota )   #所以这里就有显示支援啰

			范例二：列出目前/home这个支援quota的载点档案系统使用情况 
			[root@study ~]# xfs_quota -x -c "df -h" /home
			Filesystem Size Used Avail Use% Pathname
			/dev/mapper/centos-home
			               5.0G 67.0M 4.9G 1% /home
			# 如上所示，其实跟原本的df 差不多啦！只是会更正确就是了。

			范例三：列出目前/home的所有用户的quota限制值 
			[root@study ~]# xfs_quota -x -c "report -ubih" /home
			User quota on /home (/dev/mapper/centos-home)
			                        Blocks Inodes 
			User ID       Used Soft Hard Warn/Grace      Used Soft Hard Warn/Grace
			---------- --------------------------------- ------- --------------------------
			root 4K 0 0 00 [------] 4 0 0 00 [------]
			dmtsai 34.0M 0 0 00 [------] 432 0 0 00 [------]
			.....(中间省略).....
			myquota1 12K 0 0 00 [------] 7 0 0 00 [------]
			myquota2 12K 0 0 00 [------] 7 0 0 00 [------]
			myquota3 12K 0 0 00 [------] 7 0 0 00 [------]
			myquota4 12K 0 0 00 [------] 7 0 0 00 [------]
			myquota5 12K 0 0 00 [------] 7 0 0 00 [------]
			# 所以列出了所有用户的目前的档案使用情况，并且列出设定值。注意，最上面的Block
			# 代表这个是block 容量限制，而inode 则是档案数量限制喔。另外，soft/hard 若为0，代表没限制

			范例四：列出目前支援的quota档案系统是否有起动了quota功能？
			[root@study ~]# xfs_quota -x -c "state"
			User quota state on /home (/dev/mapper/centos-home)
			  Accounting: ON     #有启用计算功能 
			  Enforcement: ON    #有实际quota管制的功能 
			  Inode: #1568 (4 blocks, 4 extents)   #上面四行说明的是有启动user的限制能力
			Group quota state on /home (/dev/mapper/centos-home)
			  Accounting: ON
			  Enforcement: ON
			  Inode: #1569 (5 blocks, 5 extents)   #上面四行说明的是有启动group的限制能力
			Project quota state on /home (/dev/mapper/centos-home)
			  Accounting: OFF
			  Enforcement: OFF
			  Inode: #1569 (5 blocks, 5 extents)   #上面四行说明的是project并未支援 
			Blocks grace time: [7 days 00:00:30]   #底下则是grace time的项目
			Inodes grace time: [7 days 00:00:30]
			Realtime Blocks grace time: [7 days 00:00:30]

			Quota 流程-3：限制值设定方式
			[root@study ~]# xfs_quota -x -c "limit [-ug] b[soft|hard]=N i[soft|hard]=N name" 
			[root@study ~]# xfs_quota -x -c "timer [-ug] [-bir] Ndays" 
			选项与参数：
			limit ：实际限制的项目，可以针对user/group 来限制，限制的项目有
			        bsoft/bhard : block 的soft/hard 限制值，可以加单位
			        isoft/ihard : inode 的soft/hard 限制值
			        name : 就是用户/群组的名称啊！
			timer ：用来设定grace time 的项目喔，也是可以针对user/group 以及block/inode 设定

			范例一：设定好用户们的block限制值(题目中没有要限制inode啦！) 
			[root@study ~]# xfs_quota -x -c "limit -u bsoft=250M bhard=300M myquota1" /home 
			[root@ study ~]# xfs_quota -x -c "limit -u bsoft=250M bhard=300M myquota2" /home 
			[root@study ~]# xfs_quota -x -c "limit -u bsoft=250M bhard=300M myquota3" /home 
			[ root@study ~]# xfs_quota -x -c "limit -u bsoft=250M bhard=300M myquota4" /home 
			[root@study ~]# xfs_quota -x -c "limit -u bsoft=250M bhard=300M myquota5" / home 
			[root@study ~]# xfs_quota -x -c "report -ubih" /home
			User quota on /home (/dev/mapper/centos-home)
			                        Blocks Inodes
			User ID Used Soft Hard Warn/Grace Used Soft Hard Warn/Grace
			---------- --------------------------------- ------- --------------------------
			myquota1 12K    250M 300M   00 [------] 7 0 0 00 [------]

			范例二：设定好myquotagrp的block限制值 
			[root@study ~]# xfs_quota -x -c "limit -g bsoft=950M bhard=1G myquotagrp" /home 
			[root@study ~]# xfs_quota -x -c "report -gbih" /home
			Group quota on /home (/dev/mapper/centos-home)
			                        Blocks Inodes
			Group ID Used Soft Hard Warn/Grace Used Soft Hard Warn/Grace
			---------- --------------------------------- ------- --------------------------
			myquotagrp 60K    950M 1G   00 [------] 36 0 0 00 [------]

			范例三：设定一下grace time变成14天吧！
			[root@study ~]# xfs_quota -x -c "timer -ug -b 14days" /home 
			[root@study ~]# xfs_quota -x -c "state" /home
			User quota state on /home (/dev/mapper/centos-home)
			.....(中间省略)..... 
			Blocks grace time: [ 14 days 00:00:30]
			Inodes grace time: [7 days 00:00:30]
			Realtime Blocks grace time: [7 days 00:00:30]

			范例四：以myquota1用户测试quota是否真的实际运作呢？
			[root@study ~]# su - myquota1 
			[myquota1@study ~]$ dd if=/dev/zero of=123.img bs=1M count=310
			dd: error writing '123.img': Disk quota exceeded
			300+0 records in
			299+0 records out
			314552320 bytes (315 MB) copied, 0.181088 s, 1.7 GB/s
			[myquota1@study ~]$ ll -h 
			-rw-r--r--. 1 myquota1 myquotagrp 300M Jul 24 21:38 123.img

			[myquota1@study ~]$ exit 
			[root@study ~]# xfs_quota -x -c "report -ubh" /home
			User quota on /home (/dev/mapper/centos-home)
			                        Blocks
			User ID Used Soft Hard Warn/Grace
			---------- ---------------------------------
			myquota1 300M 250M 300M 00 [13 days]
			myquota2 12K 250M 300M 00 [------]
			# 因为myquota1 的磁碟用量已经破表，所以当然就会出现那个可怕的grace time 啰！