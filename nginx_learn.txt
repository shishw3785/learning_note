install nginx
	yum install
		create /etc/yum.repos.d/nginx.repo  #and write contents from nginx Centos

	
		yum install nginx # and verify GPG key

	Building nginx from Sources
		user configure command and parameters
			--help
			--prefix=path
			.......

		Example of parameters usage (all of this needs to be typed in one line):

			./configure
			    --sbin-path=/usr/local/nginx/nginx
			    --conf-path=/usr/local/nginx/nginx.conf
			    --pid-path=/usr/local/nginx/nginx.pid
			    --with-http_ssl_module
			    --with-pcre=../pcre-8.44
			    --with-zlib=../zlib-1.2.11
			After configuration, nginx is compiled and installed using make.

Beginner' s Guide
	nginx has one master process and several worker processes. The main purpose of the master process is to read and evaluate configuration, and maintain(维护) worker processes. Worker processes do actual processing of requests. nginx employs event-based model and OS-dependent mechanisms(事件驱动模型) to efficiently distribute(分发) requests among worker processes.


	start, stop and reload configureation
		To start nginx, run the executable file. Once nginx is started, it can be controlled by invoking the executable with the -s parameter. Use the following syntax:

		nginx -s signal
		Where signal may be one of the following:

		stop — fast shutdown
		quit — graceful shutdown
		reload — reloading the configuration file
		reopen — reopening the log files
		For example, to stop nginx processes with waiting for the worker processes to finish serving current requests, the following command can be executed:

		nginx -s quit

		Changes made in the configuration file will not be applied until the command to reload configuration is sent to nginx or it is restarted. To reload configuration, execute:

			nginx -s reload

			Once the master process receives the signal to reload configuration, it checks the syntax validity of the new configuration file and tries to apply the configuration provided in it. If this is a success, the master process starts new worker processes and sends messages to old worker processes, requesting them to shut down. Otherwise, the master process rolls back the changes and continues to work with the old configuration. Old worker processes, receiving a command to shut down, stop accepting new connections and continue to service current requests until all such requests are serviced. After that, the old worker processes exit.

		A signal may also be sent to nginx processes with the help of Unix tools such as the kill utility. In this case a signal is sent directly to a process with a given process ID. The process ID of the nginx master process is written, by default, to the nginx.pid in the directory /usr/local/nginx/logs or /var/run. For example, if the master process ID is 1628, to send the QUIT signal resulting in nginx’s graceful shutdown, execute:

			kill -s QUIT 1628



	Configuration file's structure
		If a block directive can have other directives inside braces, it is called a context (examples: events, http, server, and location).

		Directives placed in the configuration file outside of any contexts are considered to be in the main context. The events and http directives reside(属于) in the main context, server in http, and location in server.

	serving static content

		http {
		    server {
		    	location / {
			        root /data/www;
			    }

			    location /images/ {
			        root /data;
			    }
		    }
		}

		 For example, in response to the http://localhost/images/example.png request nginx will send the /data/images/example.png file. If such file does not exist, nginx will send a response indicating the 404 error. Requests with URIs not starting with /images/ will be mapped onto the /data/www directory. For example, in response to the http://localhost/some/example.html request nginx will send the /data/www/some/example.html file.

	Setting up a simple proxy server
		One of the frequent uses of nginx is setting it up as a proxy server, which means a server that receives requests, passes them to the proxied servers, retrieves responses from them, and sends them to the clients.

		In this example, both servers will be defined on a single nginx instance.

		First, define the proxied server by adding one more server block to the nginx’s configuration file with the following contents:

		server {
		    listen 8080;
		    root /data/up1;

		    location / {
		    }
		}

		proxy server configuration

			server {
			    location / {
			        proxy_pass http://localhost:8080/;
			    }

			    location ~ \.(gif|jpg|png)$ {
			        root /data/images;
			    }
			}

		This server will filter requests ending with .gif, .jpg, or .png and map them to the /data/images directory (by adding URI to the root directive’s parameter) and pass all other requests to the proxied server configured above.


	setting up fastcgi proxying
		nginx can be used to route requests to FastCGI servers which run applications built with various frameworks and programming languages such as PHP.

		Suppose the FastCGI server is accessible on localhost:9000.

		server {
		    location / {
		        fastcgi_pass  localhost:9000;
		        fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name;
		        fastcgi_param QUERY_STRING    $query_string;
		    }

		    location ~ \.(gif|jpg|png)$ {
		        root /data/images;
		    }
		}
		This will set up a server that will route all requests except for(除了) requests for static images to the proxied server operating on localhost:9000 through the FastCGI protocol.



nginx upgdate
	https://www.cnblogs.com/linuxk/p/9963916.html  # see help
	先查看旧的的编译参数
		nginx -v
	在新的nginx版本中编译并添加进去然后 make
	备份原来的nginx启动文件
		cd /usr/local/nginx/sbin
		mv nginx nginx_old
	cp新nginx的obj目录下的nginx到/usr/local/nginx/sbin/
	回到新的nginx目录下更新make upgrade

		[root@localhost nginx-1.14.1]# make upgrade  #这一步会将结束旧进程，并开启新的进程进行管理nginx的任务，从而达到平滑升级的效果
		/usr/local/nginx/sbin/nginx -t
		nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok
		nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful
		kill -USR2 `cat /usr/local/nginx/logs/nginx.pid`  #收到USER2信呈后,会将旧的ningx.pid改名nginx.pid.oldbin
		sleep 1
		test -f /usr/local/nginx/logs/nginx.pid.oldbin
		kill -QUIT `cat /usr/local/nginx/logs/nginx.pid.oldbin`

		这里需要注意的是，使用make upgrade进行平滑升级时，会默认发送USR2信号到/usr/local/nginx/logs/nginx.pid，但是如果你的pid文件位置不一致，就会出现文件不存在的ERROR
		而我们需要做的是，放弃使用make upgrade，而是直接使用以下命令，假设nginx.pid的路径为：/var/run/nginx.pid
		[root@localhost nginx-1.14.1]# /usr/local/nginx/sbin/nginx -t
		nginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is ok
		nginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful
		[root@localhost nginx-1.14.1]# kill -USR2 `cat /var/run/nginx.pid`
		此时会在/var/run/下生成一个nginx.pid.oldbin的pid文件
		[root@localhost nginx-1.14.1]# kill -QUIT `cat /var/run/nginx.pid.oldbin`  #退出旧进程


nginx.conf 文件结构
	全局块
	event 块
	http 块
		包含多个server块
			包含多个location块

	同一配置块中嵌套的配置块不存在次序的关系
	某个指令在两个不同层级中,则采用'就近原则',以较低层级中的配置为准

	全局块
		全局块是默认配置文件从开始到event块之间的一部分内容,主要设置一些影响nginx整体运行的配置指令,如运行nginx的用户(组),欢允许生成的work process数,nginx pid等
	event块
		涉及的指令主要影响服务器与用户的网络连接. 常用的设置包括对多work process下的网络连接进行序列化,选取哪种事件驱动模型处理连接请求,每个work process可以同时支持的最大连接数等
	http块
		重要部分,代理,缓存,日志定义等绝大多数功能和第三方模块的配置都是放在这里
		http块可以包含自己的全局块,也可以包含server块,server块中又可以包含 location块
		可以在http配置指令包括文件引入,MIME-TYPE定义,日志定义,是否使用sendfile传输文件,连接超时时间,单连接请求数上限等
	server块
		http块可以包含多个server块,server块相当于一台虚拟主机,常见的配置项是本虚拟主机的监听配置和名称或IP配置
	location块
		每个server可以包含多个location块,主要作用是基于nginx服务器收到的请求字符串,对除虚拟主机名称之外的字符串进行匹配,对特定的请求进行处理


	user user [group];
		指定Nginx运行的用户,group为可选项,如果希望所有用户都能执行Nginx,可设置为用户与组nobody,或直接#掉这行
	worker_process number | auto;
		配置允许生成的worker_process数量,理论上是越大支持的并发数量越多,但worker_process数值受软件本身与操作系统与硬件等资源的制约
	include file;
		配置文件引入,可放入任何位置,支持相对路径
	accept_mutex on|off;
		设置网络连接的序列化.(UNIX网络编程)提到的惊群问题,当有一个连接来时,多个睡眠的进程被同时唤醒,但只有一个进程可获得连接,每次唤醒的进程越多,会影响系统性能,在nginx多进程下就有可能会有惊群.默认开启On,让连接序列化.此指令在event中配置
	multi_accept on|off;
		设置欢笑许时是接收多个网络,默认为off,即每个worker process一次只能接收一个新到达的连接
	use method
		可选有select,poll,epoll等模型,在event中配置
	worker_connections numbers;
		设置允许每一个worker process同时开启的最大连接数,默认1024,在event块内配置
	定义MIME-Type
		include       mime.types;
    	default_type  application/octet-stream;
    	在常用的浏览器中,可以显示的内容有HTML,XML,GIF,FLASH等媒体资源,浏览器需要区分这些资源,使用MIME TYPE,也主浊说MIME TYPE是网络资源的媒体

    自定义服务日志
    	access_log path [format [buffer=size]];
    		path 日志的文件存放路径
    		format 
    		size 配置临时存放日志的内存缓存区大小

    		access_log logs/access.log main;
    			main为log_format指令默定义的日志格式字符串的名称
    			此指令可在http块,server块和location块

    	log_format name string....;
    		name 格式字符串的名字,默认main
    		string 日志格式字符串,在定义的过程中,可以使用Nginx配置预设的一些变量获取内容,变量的名称使用双引号括起来,string整体使用单引号括起来

    		#log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
		    #                  '$status $body_bytes_sent "$http_referer" '
		    #                  '"$http_user_agent" "$http_x_forwarded_for"';

		    此指令块只能在http配置

	sendfile on | of;
		开启sendfile()传输文件,开启后nginx性能提升,可在http,server location块中configure

	sendfile_max_chunk size;
		size如大于0,则每个worker_process每次调用sendfile()传输的数据量最大不能超过这个值,如设为0,则无限制,可在http server location中configure

	配置连接超时时间
		keepalive_timeout timeout [header_timeout];
			timeout 服务器端对连接的保持时间,默认75s
			header_timeout 可选项,在应答报文头部的Keep-Alive域设置超时时间

			如 keepalive_timeout 120s 100s
				在服务端保持连接120s,发给用户端的应答报文头部中Keep_Alive域的超时时间为100s

			可以上http,server,location块设置

	keepalive_requests numbers;
		服务器与客户端建立链接后,客户端通过此链接发送请求,这个指令用来限制请求数,默认设置100

	配置网络监听
		listen 192.168.1.10:8000 监听具体的IP和具体的端口上的连接
		listen 192.168.1.10 监听具体IP的所有端口连接
		listen 8000 监听具体port的所有IP连接,等于listen *:8000
		listen 192.168.1.10 default_server backlog=1024
			设置192.168.1.10的连接请求默认由此虚拟机处理,且允许最多1024网络连接同时处于挂起状态(因机器资源不足,暂时被淘汰调离出内存)

	基于名称的虚拟主机配置
		server_name name...;
			如server_name myserver.com www.myserver.com;
				第一个名称作为此虚拟主机的主要名称

		name中可以使用通配符*,但通配符只能用在三段字符组成的名称的首段或尾段,或两段
			server_name *.myserver.com www.myserver.*;

		name还可以使用正则表达式,并使用"~"作为正则表达式字符串的开始标记
			server_name ~^www\d+\.myserver\.com$;
				以www开头,^匹配行首, www后接1个或多个[0-9]的数字,\d代表0到9的任意一个数字, + 代表一个或多个前字符, . 在正则表达中有特殊含义,所以有用\转义, 后面是$匹配m行尾

			正则表则式捕获功能
				server_name ~^www\.(.+)\.com$;
					如www.myserver.com匹配成功,“myserver”字串就会被获取保存并记录到$1变量中,然后在server块的配置中,可以直接使用$1变量,同理也可以有$2,$3

		因server_name支持通配符又支持正则,如果都匹配成功,则顺序
			准确匹配server_name
			通配符在开始匹配server_name成功
			通配符在结尾匹配server_name成功
			正则表达式匹配成功

	基于IP的虚拟主机配置
		server
			{
				listen 80;
				server_name 192.168.1.31;
				.....
			}

		server
			{
				listen 80;
				server_name 192.168.1.32
				.....
			}
			这样来自192.168.1.31的请求就由第一台虚拟机来处理,第二台同理,个人理解就是只用IP来访问

	location [ = | ~ | ~* | ^~ ] uri [ ... ];
		= 用于标准url,要求请求字符串与uri严格匹配,如果匹配成功,就停止继续向下搜索并立即处理此请求
		~ 用于url包含正则表达式,区分大小写
		~* 用于url包含正则表达式,不区分大小写
		^~ 用于标准url,要求NGINX找到标枳url和请求字符串匹配度最高的location后,立即使用此location处理请求,而不再使用location块中的正则uri和请求符串做匹配
			浏览器传送URL时对一部分字符进行URL编码,比如空格被编码为 %20 , 问号被编译为 %3f 等, ^~ 有一个特点,它对uri中的这些符号会进行编码处理,如 location收到 /html/%20/data ,则当NGINX搜索到配置为 ^~ /html/ /data的location时可以匹配成功

	配置请求的根NGINX变量
		root path;
		path为NGINX收到请求后查找资源的根目录路径,PATH中可以包含NGINX变量
		可在http server location中配置,一般多locationf块,所以在Location配置多

		location /data/{
			root /locationtest1;
		}
		当收到/data/index.html请求时,将会到/locationtest1/data目录下找到index.html响应请求
		}

	更改location的URL alias
		alias path;

		如 location ~ ^/data/(.+\.(htm|html))$;
			{
				alias /locationtest1/other/$1;
			}

			当location收到/data/index.html的请求时,匹配成功,之后根据alias指令的配置,nginx将到/locationtest1/other目录下找index.html并响应请求

	设置网站的默认首页
		index file...;

		作用
			1 用户在发送请求访问网站时,请求地址可以不写首页名称
			2 可以根据请求内容设置不同的首页
		file 可以是多个文件名,用空格隔开,也可以是变量,变量默认为Index.html

		如 location ~ ^/data/(.+)/web/$
			{
				index index.$1.html index.my1.html index.html;
			}
			当收到/data/locationtest/web/时,匹配成功,$1为locationtest,然后到/data/locationtest/web目录下按照index顺序依次查找,index.locationtest.html index.my1.html index.html,首先找到哪个页面,就使用哪个页面响应请求

	设置网站的错误页面
		HTTP 2XX 代表请求正常完成
		HTTP 3XX 代表网站重定向
		HTTP 4XX 代表客户端出现错误
		HTTP 5XX 代表服务器端出现错误

		error_page code ... [=[response]] uri;
			code 要处理的代码
			response 可选项,将code指定的错误代码转化为新的错误代码
			uri 错误面页的路径或者网站地址,如果是路径,则是以NGINX服务器安装路径下的HTML目录为根路径的相对路径,如是网址,则NGINX服务器会直接访问该网址获取错误页面,并返回给用户端

		error_page 404 /404.html
			设置使用NGINX安装路径/html/404.html页面响应404错误

		error_page 403 http://somewebsite.com/forbidden.html;
			设置使用网址响应403

		error_page 410 =301 /empty.git
			NGINX产生410的HTTP消息时,使用NGINX安装路径/html/empty.gif 返回给用户301消息(已移动消息)

		error_page 404 /404.html
		location /404.html 
			{
				root /myserver/errorpages/
			}
			不想将错误页面放到NGINX安装路径下面,可以先获取到/404.html,然后将请求定向到新的路径

		error_page 指令可在http server location设置

	基于IP配置Nginx的访问权限
		由HTTP的标准模块nginx_http_access_module支持,通过IP来判断客户端是否拥有对NGINX的访问权限

		allow address | CIDR | all;
			address 允许访问的客户端IP, 不支持同时设置多个.需要多个要重复使用allow
			CIDR 允许客户端的CIDR地址, 如 202.80.18.23/25
			all 代表允许所有的客户端访问

			支持IPV6地址

		deny address | CIDR | all;
			addree 禁止访问的IP,重复需要使用deny
			CIDR
			all 禁止所有客户端访问

		location / {
			deny 192.168.1.1;
			allow 192.168.1.0/24;
			deny all;
		}
		192.168.1.0/24客户端可以访问,因为NGINX解析过程是按顺序匹配,匹配对应行成功后就停止继续向下搜索(与iptables类似).

	基于密码配置的nginx访问权限
		由标准模块ngx_http_auth_basic_module支持

		auth_basic string | off;
			string 开启认证功能,并配置验证时的指示信息
			off 关闭此功能

		auth_basic_user_file file;
			file 为密码文件的绝对路径

		密码文件格式,支持明文(测试不成功)与加密的格式
			name1:passwd1
			name2:passwd2:comment
			.....

		加用户ttlsa

		echo -n 'ttlsa:' >> /usr/local/nginx/conf/passwd
	    设置加密密码
		为ttlsa用户密码设置为www.ttlsa.com

		openssl passwd www.ttlsa.com >> /usr/local/nginx/conf/passwd
		
		cat /usr/local/nginx/conf/passwd
		ttlsa:I5OG.QXtiqFJs

NGINX服务器架构初探
	什么是模块化设计,了解即可
		模块化是一种思想,常用于程序设计
			一个模块就是一个功能块
			将程序进行分解,模块化编程原则,自顶向下,逐步求精原则
			一个程序被分解为多个模块,各模块间有一定的依赖关系,但依赖关系不能太强
				模块化的另一个原则,高内聚,低耦合

	NGINX模块化结构
		核心模块
			nginx服务器正常运行必不可少的模块,提供NGINX最基本最核心的服务,如进程管理,权限控制,错误日志记录等
		标准http模块
			编译NGINX后包含的模块
		可选http模块
			用于扩展标准的HTTP功能
		邮件服务模块
		第三方模块
			第三方或个人编写的可编译到NGINX的模块

	/usr/local/src/nginx-1.19.1/objs/ngx_modules.c 文件为NGINX编译后所包含的固有模块的声明(编译后才能会objs目录)

	/usr/local/src/nginx-1.19.1/objs/src 里面存放所有固有模块的源码


	Nginx服务器的WEB请求处理机制
		nginx与其它软件如IIS等其它不同的地方,一个是模块化设计,另一个是NGINX对客户端请求的处理机制

		web服务器与客户端是一对多的关系,web必须有能力同时为多个客户端服务,一般来说,完成并行处理请求的工作有三种方式可选
			多进程方式
			多线程方式
			异步方式

			(并行,同一时间有两个或两个以上事件同时发生.而并发是,是同一时间间隔发生(cpu交替切换处理))

		多进程方式
			每当收到一个客户端请求时,服务器主进程生成一个子进程出来和该客户端建立连接进行交互,直到连接断开,子进程结束
			优点
				设计与实现简单,各子进程间相互独立,处理客户端请求的过程彼此不受到干扰,且其中一个子进程产生问题时,不容易影响到其它进程,稳定
			缺点
				生成一个子进程需要进行内存复制等操作,在资源和时会上会产生一外额外开销,受到大量web并发请求时会对系统资源造成压力,系统性能下降
			apache就是使用'预生成进程'的机制改进而来

		多线程方式
			与多进程类似,当收到一个请求时,由服务器主进程派生一个线程和客户端交互
			优点
				产后一个线程开销少
			缺点
				线程管理方面有一定的不足,多个线程位于同一个进程内,可以访问同样的内存空间,彼此相互影响(会有出错风险),服务器运转时间长就越容易出错
			IIS就是使用多线程服务,通常得定期检查与重启服务器

		异步方式
			网络通信中的同步与异步机制是描述通信模式的概念
				同步
					指发送方发送请求后,需要等待接收到接收方发回的响应后,才接着发下一个请求
				异步
					刚好相反,发送一个请求后,不等待接收的响应就继续发送下一个请求

				在同步机制中,所有的请求在服务端得到同步,在异步机制中,所有来自发送方的请求形成一个队列,接收方处理完成后通知发送方

			阻塞和非阻塞用来描述进程处理调用的方式,主要是指网络套接字socket的阻塞与非阻塞(实质是IO操作)
				阻塞
					调用结果返回之前,当前线程从运行状态被挂起,一直等到调用结果返回后,才进入就绪状态,获取CPU后继续执行
				非阻塞
					如果调用结果不能马上返回,当前线程也不会被挂起,而是立即返回执行下一个调用

			所以就会有4种方式
				同步阻塞
				同步非阻塞
				异步阻塞
				异步非阻塞(通信效率最高)
					发送方向接收方发送请求后,不用等待响应,可以继续其他工作,接收方处理请求时的IO操作如果不能马上得到结果,也不等待去做其它工作,当IO操作完成后,将完成结果与状态通知接收方,然后接收方响应给发送方.例子
					超市付款,客户(发送方)向收款员(接收方)付款(发送请求)后在等待收款员找0钱的过程中,还可以做其他事情(打电话聊天等),而收款员在等待收款机处理交易(IO操作)的过程中,还可以帮助客户打包商品,当收款机产生结果后,收款员给客户结账(响应请求)


		nginx结合多进程机制与异步机制(异步非阻塞)来处理web请求,同时处理大量的并发请求
			客户端数量增长,网络负载重时,利用多进程机制来保证不增长对系统资源的压力,利用异步非阻塞方式减少进程在I/O调用上的阻塞延迟,保证了不降低对请求的处理能力

	nginx服务器的事件处理机制
		NGINX工作进程调用IO后,就去进行其它工作了,当IO调用返回时,会通知工作进程.那IO调用是如何把自己的状态与结果通知进程呢?
			一种是让工作进程进行其他工作的过程中隔一段时间就去检查一下IO的运行状态,如完成就去响应客户端,不完成就继续正在的工作
			另一种是IO调用完成后能够主动通知工作进程.理想的解决方案
				select/poll/epoll/kqueue等这样的系统调用就是用来支持第二种方案的,这类调用也称为事件驱动模型.
					它们提供了一种机制,让进程可以同时处理多个并发请求,不用关心IO调用的状态.IO调用完全由事件驱动来管理,事件准备好后就通知工作进程


nginx服务器的事件驱动模型
	事件驱动模型是NGINX服务器保证完整功能和具有良好性能的重要机制

	事件驱动是一种较古老的响应模型,在计算机,公共关系,经济活动领域等有广泛的应用

	事件驱动模型一般有事件收集器,事件发送器,事件处件器三部分基本单元组成
		事件收集器专门负责收集所有的事件,包括来自用户的(鼠标点击,键盘输入等),硬件的(时钟事件等)和软件的(如操作系统,应用程序本身等),事件发送器负责将收集到的事件发分到事件处理器中(负责响应工作,往往要到实现阶段才完全确定)

	如果一个系统是以事件驱动程序模型为编程基础的,它的架构基本是
		预先设计一个事件循环所形成的程序(事件收集器),它不断地检查目前要处理的事件信息,然后由事件发送器发给事件处理器
	windows操作系统就是基于事件驱动程序设计的


	nginx中的事件驱动模型
		nginx的响应和处理web请求过程,就是基于事件驱动模型,它也包含了事件收集器,发送器,处理器三部分

		实现事件收集器与发送器没太大特点,主要是事件处理器,有以下几种实现办法
			事件发送器每传递过来一个请求,目标对象就创建一个新的进程,调用'事件处理器'来处理该请求
			事件发送器每传递过来一个请求,目标对象就创建一个新的线程,调用'事件处理器'来处理该请求
			事件发送器每传递过来一个请求,目标对象就将其放入一个待处理事件的列表,使用非阻塞I/O方式调用事件处理器来处理该请求

		第一种开销太大,系统性能太差,第二种线程问题,线程的同步问题,线程死锁问题,较复杂,第三种编程逻辑最复杂,大多数网络服务器都使用这种,逐进形成了事件驱动处理库

		事件驱动处理库又称为IO多路复用,最常见包括以下几种
			select模型,poll模型,epoll模型

	select库
		各版本的linux与windows都支持的基本事件驱动模型
		首先创建关注事件的描述符集合,读事件,写事件,异常事件三类描述符集合,其次调用select()等待事件发生,然后轮询所有事件描述符的每一个事件描述符,检查是否有相应的事件发生,有就处理

	poll库
		linux的基本事件驱动模型,poll可以说是select的优化版
		poll与select不同在于只需创建一个集合(包含 读写异常),轮询时可以同是检查三类事事件是否发生

	epoll库
		NGINX支持的高性能事件驱动之一,公认的非常优秀的事件驱动模型,比上面两个更有效率
		与上面两个不同是把描述符列表的管理交由内核负责,一旦有某种事件发生,内核就发生事件的描述符列表通知给进程,避免了轮询整个描述符列表

	rtsgi模型
		不常用

	其他事件驱动
		NGINX服务器针对特定linux平台还提供了kqueue模型,/dev/poll模型和evetport模型

		kqueue
			和epoll没什么区别,除要用于FreeBSD 4.1以上系列平台

		/dev/poll
			Solaris 7 及等系列平台

		eventport
			Solaris 10及以上系列平台

		这三个其实就是针对不同的平台去优化使用,发挥系统本身的优势,模型的选择选对应就行



	nginx服务器架构
		nginx服务器启动后,产生一个主进程(master process),主进程执行一系列工作后产生一个或多个工作进程(work process).
			主进程主要进行nginx配置解析,数据结构初始化,模块配置注册,信号处理,网络监听生成,工作进程生成和管理工作
			工作进程主要是模块调用,请求处理工作等,是nginx提供服务的主体
		如果客户端请求动态站点,nginx服务器还涉及和后端服务的通信.
			将接收到的请求通过代理转发到后端服务器,由后端进行数据处理和页面组织,然后将结果返回
		另外,nginx主了提高对请求的响应效率,进一步降低网络压力,采用了缓存机制,将历史应答数据缓存到本地.在每次nginx启动后的一段时间内,会启动专门的进程对本地缓存的内容重新索引,保证对缓存文件的快速访问

		缓存索引重建及管理进程(cache loader & cache manager)
			缓存索引重建是在NGINX启动后一段时间内(默认一分钟)由主进程生成,在缓存元数据重建后自动退
				主要工作根据本地磁盘上的缓存文件在内存中建立索引元数据库，更新等
			缓存管理存在于主进程的整个生命周期
				对元数据是否过期做出判断

			这两个进程维护的内存索引元数据库,为工作进程对缓存数据的快速查询提供便利

		进程交互
			进程之间的交互依赖于管道(channel)机制

			Master-Work 交互
				master通赤fork()函数来生成work process,然后建立一张全局的工作进程表用来存放款退出的所有工作进程,并建立一个单向管道并将其传递给工作进程.主进程与外界通过信号机制进行通信,当接收到要处理的信号时,它通过管道向工作进程发送正确的指令,工作进程都有能力捕获管道中的可读事件,并解析指令采取措施

			work-work 交互
				和上面类似,不过要通过Master进程获取另一个进程的信息来帮助处理(因为各工作进程之间是隔离的)

		run loops 事件处理循环模型
			指的是进程内部用来不停地调配工作,对事件进行循环处理的一种模型.
			nginx服务器在工作进程中实现了runloops事件循环模型的使用,用来处理客户端发来的请求事件


nginx服务器高级配置
	针对IPv4的内核7个参数的配置优化,可以将这些内核参数的值加到/etc/sysctl.conf中,然后/sbin/sysctl -p 命令让其生效

		以下参数了解即行或直接拿来使用

	1、net.core.netdev_max_backlog参数

　　参数net.core.netdev_max_backlog表示当每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许发送到队列的数据包的最大数目，一般默认值为128（可能不同的linux系统该数值也不同）。nginx服务器中定义的NGX_LISTEN_BACKLOG默认为511。我们可以将它调整一下：

	net.core.netdev_max_backlog = 262144
	 

	2、net.core.somaxconn参数

	　　该参数用于调节系统同时发起的TCP连接数，一般默认值为128.在客户端存在高并发请求的情况下，该默认值较小，肯那个导致连接超时或重传问题，我们可以根据实际需要结合并发请求数来调节此值。

	net.core.somaxconn = 262144
	 

	3、net.ipv4.tcp_max_orphans参数

	　　该参数用于设定系统中最多允许存在多少tcp套接字不被关联到任何一个用户文件句柄上。如果超过这个数字，没有与用户文件句柄关联的tcp套接字符将立即被复位，同时给出警告信息。这个限制只是为了防止简单的DoS工具。一般在系统内存比较充足的情况下，可以增大这个参数的赋值：

	net.ipv4.tcp_max_orphans = 262144
	 

	4、net.ipv4.tcp_max_syn_backlog参数

	　　记录的那些尚未收到客户端确认信息的连接请求的最大值。对于有128M内存的系统而言，缺省值是1024，小内存的系统则是128。一般在系统内存比较充足的情况下，可以增大这个参数的赋值：

	net.ipv4.tcp_max_syn_backlog = 262144
	 

	5、net.ipv4.tcp_timestamps参数

	　　该参数用于设置时间戳，可以避免序列号的卷绕。一个1Gbps的链路肯定会遇到以前用过的序列号。时间戳能够让内核接受这种“异常”的数据包。这里需要将其关掉：

	net.ipv4.tcp_timestamps = 0
	 

	6、net.ipv4.tcp_synack_retries参数

	　　该参数用于设置内核放弃TCP连接之前向客户端发送SYN+ACK包的数量。为了建立对端的连接服务，服务器和客户端需要进行三次握手，第二次握手期间，内核需要发送SYN并附带一个回应前一个SYN的ACK，一个参数主要影响这个过程，一般赋值为1，即内核放弃连接之前发送一次SYN+ACK包，可以设置其为：

	net.ipv4.tcp_synack_retries = 1 
	 

	7、net.ipv4.tcp_syn_retries参数

	　　该参数的作用与上一个参数类似，设置内核放弃建立连接之前发送SYN包的数量，他的赋值和上个参数一样即可：

	net.ipv4.tcp_syn_retries = 1



	针对CPU的nginx配置优化的2个指令
		worker_processes
			设置nginx的worker_process进程数,一般设置为CPU的核心数一样或2倍即可(cat /proc/cpuinfo  | grep processor)

		worker_cpu_affinity	
			用来为每个进程分配CPU的工作内核

			如worker_process为4时,可以这样
			worker_cpu_affinity 0001 0100 1000 0010;


	针对网络连接相关的配置的4个指令
		keepalive_timeout
			用于设置nginx服务器与客户端保持连接的超时时间

			keepalive_timeout 60 50;
				客户端与服务器端保持连接的超时时间为60s
				第二个是可选项,指定使用keep-avle消息头保持活动的有效时间,如果不设置,nginx服务器不会向客户端发送keep-alive消息头保持与某些客户端的连接

		send_timeout
			用于设置NGINX响应客户端的超时时间,客户端与服务端建立连接后,在这段时间内,客户端没有任何活动,nginx就关闭连接

		client_header_buffer_size
			用于设置nginx允许客户端请求头部的缓冲区大小,默认1K,可以根据系统分页设置(getconfg PAGESIZE)
			若nginx有400错误,有很大部分是客户端请求头部过大有关(通常是客户端cookie中写入了较大的值引起),把值调大点可以解决,调整为4k

			client_header_buffer_size 4k;

		multi_accept
			用于配置nginx服务器是否尽可能地接收客户端的网络连接请求,默认为off,可调为on


	与事件驱动相关的配置
		use 
			选择驱动模型

		worker_connections numbers;
			用于设置nginx的每个工作进程允许同时连接客户端的最大数量,数值与操作系统进程可打开的文件句柄数量有关

			nginx日志报错
				1024 worker_connections is not enough....
			此时可更改数值解决
				worker_connections 65535;

			更改后若出现
				.....resource limit: 1024
			则可修改
				echo "2390251" > /proc/sys/fs/file-max; sysctl -p

		其它略过



nginx的Gzip压缩
	相关指令可以在http块,server块,location块中设置

	由ngx_http_gzip_module模块处理的9个指令
		主要负责gzip功能的开启与设置,对响应数据进行在线实时压缩
		
		gzip on|off
			开户或关闭gzip功能,只有on时,下列的指令设置才有效

		gzip_buffers number size;
			设置Gzip压缩文件使用缓存空间的大小

			gzip_buffers 32 4k | 16 8k;

		gzip_comp_level level;
			压缩等级,默认1级

		gzip_disable regex...;
			针对不同种类的浏览器请求,可以选择性的开启或关闭gzip功能,regex根据客户端的浏览器标志(User-Agent, UA),支持正则

			如
			gzip_disable MSIE [4-6]\.;
				#当包含MSIE4 MSIE5 MSIE6的所有浏览器,响应这些请求时,nginx不进行压缩

		gzip_http_version
			针对HTTP协议版本,设置开启Gzip功能最低HTTP版本

			gzip_http_version 1.0|1.1;
				现在一般都支持了,采用默认值即可(1.1)

		gzip_min_length length;
			根据响应页面大小选择性地开启或关闭压缩,默认值为20,建议设置为1K

			gzip_min_length 1024;

		gzip_proxied
			使用NGIX反向代理功能时有效,先略过

		gzip_types
			nginx根据响应页的MIME类型选择性地开启gzip压缩功能
			mime-type变量的取值默认为text/html,实际上在gzip指令设置为on时,nginx会对所有的text/html类型页面进行gzip压缩
			gzip_type text/plain application/x-javascript text/css text/html application/xml;

		gzip_vary
			设置在使用gzip功能时是否发送带有’vary:accept-encoding头域的响应头部,告诉接收方发送的数据经过了压缩处理



	由ngx_http_gzip_static_module模块处理的指令
		模块主要负责搜索和发送经过gzip功能预压缩的数据,这类数据以.gz作为后缀名存在服务器上.如果客户端请求的数据之前被压缩过,且客户端支持gzip压缩,就直接返回压缩后的数据

		与ngx_http_gzip_module模块不同之处在于,该模块使用的是静态压缩,在HTTP响应头部包含Cconten-Lenth头域来指明报文体的长度,用于服务器可确定响应数据长度的情况.而上面的模块默认使用Chunked编码的动态压缩,主要适用于服务器无法确定响应数据长度的情况.如大文件下载的情形,需要实时生成数据长度

		该模块有关的指令主要有
				gzip_static gzip_http_version gzip_proxied gzip_disable gzip_vary

		其中gzip_static用于开启和关闭该模块的功能
				gzip_static on | off | always;
						on 开启
						off 关闭
						always 一直发送gzip预压缩文件,而不检查客户端浏览器是否支持gzip压缩
		其它指令与上面的模块相同
			略过

		注意,该模块是可选HTTP模块,如要使用,NGINX编译时要添加 --with_http_gzip_static_module指令

	由ngx_http_gunzip_module处理的两个模块
		nginx支持响应数据流进行gzip压缩,但需要客户端浏览器有能力解压与处理gzip压缩数据,但如果客户端不支持,就需要Nginx在向其发送数据之前将该数据解压

		gunzip指令
			gunzip_static on | off;
				默认设关闭功能,开启时如果客户端浏览器不支持gzip处理,nginx将返回解压后的数据,如果客户端浏览器支持gzip处理,nginx忽略此设置,仍然返回压缩数据,解决数据解析的问题,同时保证nginx与后端服务器交互数据或者本身存储数据时仍然使用压缩数据,从而减少了服务器之间的数据传输量,降低了本地存储空间和缓存的使用率

		该模块也是可选HTTP模块

		其它略过


	gzip压缩功能的使用
		如在http块配置(所有的server块都生效)

		gzip on;   #开启gzip功能
		gzip_min_length 1024;   #响应页数据上限
		gzip_buffers 4 16k		#缓存空间大小
		gzip_comp_level 2;		#压缩级别为2
		gzip_type text/plain application/x-javascript text/css application/xml;    #压缩源文件的类型
		gzip_vary on;			#启用压缩标识
		gunzip_static on;		#检查预压缩文件

		如要在某server虚拟不启用压缩
			server {
				....
				gzip off;
			}


		gzip压缩功能与IE6浏览器运行脚本的兼容问题
			nginx开启对javascript脚本的压缩功后,IE6可能javascript脚本运行不正常,原因可能是ifame独立使用相同的javascrip脚本,也可能是跳转页响应数据头部的cache-control头域设置了no-cache指令,也可能是javascript脚本中的汉字没有被正确的编码导致解析失败(首次加载正常,刷新后不正常)
			可设置
				gzip_disable "MSIS[1-6]\.";

		nginx与其他服务器交互时产生的gzip压缩功能相关问题
			一类是多层服务器同时开启gzip压缩功能
				解决办法,前端服务器开启gzip功能,后端服务器(如fastcgi,tomcat)最好不要开启gzip
			一类是多层服务器之间对gzip压缩功能支持能力不同
				nginx与squid两类服务器交互,squid可能只支持静态压缩,则nginx可以设置
					gzip_static on;
					gzip_http_version 1.0;


Nginx的Rewrite功能

	nginx后端服务器组的配置的5个指令
	upstream
		设置后端服务器的主要指令,其中指令都在该指令中进行配置

		upstream name { ... }

			name 是给后端服务器起的组名
			{} 包含的后端服务器,其中可以使用下面介绍的命令
				server
				ip_hash
				keepalive
				least_conn

			默认情况下,某个服务器组接收到请求以后,按照轮叫调度(Round-Robin, RR)策略顺序选择组内服务器处理请求.如一个服务器请求过程出错,则请求会被顺次交给组内的下一个服务器处理,以此类推,直到返回正常响应.如果组内服务器都出错,则返回最后一个服务器处理的结果

			可以给各服务器配置不同的权重,在server指令中

		server address [parameters];
			address 服务器的地址,可以是包含port的IP地址,域名地址或者unix domain socker(进程间通信)
			parameters
				weight=number
					为服务器设置权重,权重值高的服务器优先用于处理请求,此时组内服务器的选择策略为加权轮叫策略
					默认值为1,即采用一般轮叫调度原则处理请求
				max_fails=number
					设置一个请求失败的次数,在一定时间范围内.超过这个值的请求失败,服务器被认为无效(down),默认值为1
					注意 404 状态不被认求是请求失败
				fail_timeout
					一个作用是上面的'在一定时间范围内',另一个作用是如一个服务器是down时,则该值为认为服务器无效的持续时间,在这个时间内不再检查服务器的状态
				backup
					备用.当正常的服务器down或繁忙时,该服务器才用来处理客户端
				down
					设置服务器为down状态

			例子
				upstream backend{
					server backend1.example.com weight=5;
					server 127.0.0.1:8080 max_fails=3 fail_timeout=30; #在30s内请求失败3次视为down
					server unix:/tmp/backend3;
				}

		ip_hash
			用于实现会话保持功能,将某个客户端的多次请求定向到组内的同一台服务器上

			ip_hash不能与weight一起使用,启用ip_hash对应的nginx应该处理最前端的服务器

			客户端IP地址必须是C类地址(其实是只把IP的前24位网络号地址放进hash算法里去计算,就是判断网络号的意思)

			例
			upstream backend{
				ip_hash;
				server myback1.proxy.com;
				.....
			}


		keepalive
			用于控制网络连接保持功能.通过该指令能够保证nginx的工作进程为服务器组打开一部分网络连接,并将数量控制在一定范围内

			keepalive connetions;

			此指令暂时不理解

		least_conn
			该指令在功能上实现了最少连接负载均衡算法,在选择组内服务器时,考虑服务器权重的同时,每次选择的都是当前网络连接最少的那台服务器,如果这样的服务器有多台,就选择权重最大的服务器


Rewrite功能的配置
	地址重写与地址转发

	地址重写
		实际上是为了实现地址标准化

		如输入google.cn也可以输入www.google.cn都是-->www.google.cn,而google.cn-->www.google.cn就是地址标准化,地址重定向的过程

	地址转发
		指将一个域名指到另一个已有站点的过程

	两者区别
		地址转发后客户端浏览器地址栏的地址显示是不改变的，而地址重写后客户端浏览器地址栏中的地址改变为服务器选择确定的地址

		一次转发过程只产生一次请求,一次重写一般会产生两次请求

		地址转发一般发生在同一站点项目内,而地址重写没限制

		地址转发到的页面可以不用全路径名表示,而地址重写到的页面必须使用完整的路径

		地址转发的过程中,可以将客户端请求的request范围内属性传递给新的页面,但地址重写不行

		转发的速度比重写(重定向)要快


	nginx使用ngx_http_rewrite_module模块支持URL重写功能,标准http模块


	if 指令 if ( condition) { ... }
		用来支持判断,根据条件判断结果选择不同的Nginx配置,可在server,location配置
		
		{} 为一个作用域,形成一个if配置块,条件为真时的nginx配置

		condition 为判断条件 （true/false),支持以下几种设置方法
			变量名
				if ($slow) {
					#nginx配置
				}
				#变量的值为空字符串或以 0 开头的任意字符,if认为条件为false,其他情部认为true

			使用 = 或 ！= 比较字符串是相等,相等则认为true
				if ($request_method = POST){
					return 405;
				}
				#字符不需加引号

			使用正则表达式对变量进行匹配,成功则为true
				~ 区分大小写
				~* 不区分大小写
				!~ ,!~* 这两个刚好相反,匹配失败时认为为true

				在正则表达式中还可以使用小括号对变量值进宪截取,然后在花括号中使用$1...$9引用其值

				if ($http_user_agent ~ MSIE) {
					.....    #$http_user_agent 包含MSIE字符串,为true
				} 

				if ($http_user_agent ~* "id=([^;]+)(?:;|$)"){
					.... #可以使用$1 $2或$id来截取到的值
				}

			判断请求的文件是否存在使用 -f !-f
				-f 存在认为true
				!-f 请求的文件不存在但所在的目录存在,为true

				if (-f $request_filename) {
					...
				}

				其它-d -e 略过笔记



	break 
		用于中断当前相同作用域中的其他nginx配置,位于它前面的指令配置生效,后面的无效,可在server,location块使用

		location / {
			if ($slow){
				set $id $1             #break之前的配置生效
				break;
				limit_rate 10;			#break之后的配置无效
			}
			......         #其他nginx配置,处于break指令所在作用域的上一层作用域,配置有效
		}

	return
		用于完成对请求的处理,直接向客户端返回响应的状态代码.处于该指令后的所有nginx配置都是无效的,可在server,location,if块中使用

		return [ text]   #text为返回给客户端的响应体内容,支持变量的使用
		return code URL;	#code为返回给客户端的状态代码,可返回0~999的任意HTTP状态码
		return URL;			#返回给客户端的URL地址

		详细再百度


	rewrite 指令
		URI 统一资源标识符,用来唯一的标识一个资源
		URL 统一资源定位器,它是一种具体的URI,还指明了如何locate这个资源

		指令可以在 server,location中配置

		rewrite regex replacement [flag];
			regex 用于匹配URI的正则表达式,使用()标记截取的内容,注意接收到的URI不包含host地址,如

				rewrite myweb.com http://newweb.com/permanent;
				如果rewrite 重写 http://myweb.com/source是不行的,因为rewrite接收的到的URI是 /source 而不是 myweb.com

				另外,请求URL中的请求指令不包含在rewrite指令接收到的URI内容中的
				http://myweb.com/source?arg1=value1&agr2=value2

				rewrite接收到的是 /source 而不包含 ?arg1......

			replacement 匹配成功后用于替换URI中被截取内容的字符,默认情况下,如果该字符串是由'http://'或'https//'开头的,则不会继续向下对URI进行其他处理,而直接将重写后的URI返回给客户端

				上面提到的请求指令不包含在URl中,但我们希望将其传给重写后的URI,那可以使用全局变量 $request_uri

				rewrite myweb.com http://neweb.com$request_uri? permanet;
					注意 request后有个 ? ,replacement支持nginx的全局变量使用

			flag
				用来设置rewrite对URI的处理行为,可以是以下标志中的一个

				last 终止继续在本location中处理接收到的URI,并将此处重写的URI作为一个新的URI,使用各location块进行处理

					如
					location / {
						rewrite ^(/myweb/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 last;
						rewrite ^(/myweb/.*)/audio/(.*)\..*$ $1/mp3/$2.ra last;
					}
					如URI在第2行匹配成功,NGINX不会继续使用第3行匹配处处理新的URI,而是让所有的location块重新匹配和处理新的URI

				break 将此处重写的URI作为一个新的URI,在本块中继续处理(在当前location中继续执行,不会将新的URI转向到其他location块)
					location /myweb/ {
						rewrite ^(/myweb/.*)/media/(.*)\..*$ $1/mp3/$2.mp3 break;
						rewrite ^(/myweb/.*)/audio/(.*)\..*$ $1/mp3/$2.ra break;
					}
					如URI在第2行匹配成功,nginx将在该location块使用第3行继续匹配和处理,始终在同一个location中

				redirect 将重写后的URI返回给客户端,状态码为302,指明是临时重定向的URI,主要用在replacement变量不是以 http 或 https 开头的情况下

				permanet 将重写后的URI返回给客户端,状态码301,指明永久重定向

				注意各标志的配合使用,如break第二行的break错配成last,那URI请求匹配成功后就会变成可能又被location /myweb/ 匹配到,又回到 第2行匹配,无限循环

	rewrite_log on | off
		配置是否开启URL重写日志的输出功能,默认off,如开启会以notice输出到error.log

	set variable value
		用于设置一个新的变量
		variable 变量名称,注意用 $ 作为变量的第一个字符
		value 变量的值

	uninitialized_variable_warn on | off
		用于配置使用未初始化的变量时,是否记录警告日志,默认开启


	rewrite常用全局变量
		$remote_addr        //获取客户端ip
		$binary_remote_addr //客户端ip（二进制)
		$remote_port        //客户端port，如：50472
		$remote_user        //已经经过Auth Basic Module验证的用户名
		$host           //请求主机头字段，否则为服务器名称，如:blog.sakmon.com
		$request        //用户请求信息，如：GET ?a=1&b=2 HTTP/1.1
		$request_filename   //当前请求的文件的路径名，由root或alias和URI request组合而成，如：/2013/81.html
		$status         //请求的响应状态码,如:200
		$body_bytes_sent        // 响应时送出的body字节数数量。即使连接中断，这个数据也是精确的,如：40
		$content_length        // 等于请求行的“Content_Length”的值
		$content_type          // 等于请求行的“Content_Type”的值
		$http_referer          // 引用地址
		$http_user_agent      // 客户端agent信息,如：Mozilla/5.0 (Windows NT 5.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/29.0.1547.76 Safari/537.36
		$args            //与$query_string相同 等于当中URL的参数(GET)，如a=1&b=2
		$document_uri        //与$uri相同  这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html
		$document_root       //针对当前请求的根路径设置值
		$hostname        //如：centos53.localdomain
		$http_cookie        //客户端cookie信息
		$cookie_COOKIE      //cookie COOKIE变量的值
		$is_args    //如果有$args参数，这个变量等于”?”，否则等于”"，空值，如?
		$limit_rate //这个变量可以限制连接速率，0表示不限速
		$query_string       // 与$args相同 等于当中URL的参数(GET)，如a=1&b=2
		$request_body      // 记录POST过来的数据信息
		$request_body_file  //客户端请求主体信息的临时文件名
		$request_method       //客户端请求的动作，通常为GET或POST,如：GET
		$request_uri          //包含请求参数的原始URI，不包含主机名，如：/2013/81.html?a=1&b=2
		$scheme            //HTTP方法（如http，https）,如：http
		$uri            //这个变量指当前的请求URI，不包括任何参数(见$args) 如:/2013/81.html
		$request_completion //如果请求结束，设置为OK. 当请求未结束或如果该请求不是请求链串的最后一个时，为空(Empty)，如：OK
		$server_protocol    //请求使用的协议，通常是HTTP/1.0或HTTP/1.1，如：HTTP/1.1
		$server_addr        //服务器IP地址，在完成一次系统调用后可以确定这个值
		$server_name        //服务器名称，如：blog.sakmon.com
		$server_port        //请求到达服务器的端口号,如：80


	rewriete 的使用

		server
		{
			listen 80;
			server_name jump.myweb.name;
			rewrite ^/ http://jump.myweb.info/;
		}
		客户端访问jump.myweb.name时,得到的数据其实是 jump.myweb.info响应的数据

		server
		{
			....
			server_name jump.myweb.name jump.myweb.info;
			if ($host ~ myweb\.info)
			{
				rewrite ^(.*) http://jump.myweb.name$1 permanent;
			}
		}
		当访问http://jump.myweb.info/reqsource时,URL将被nginx服务器重写为http://jump.myweb.name/reqsource,得到的数据实际由jump.myweb.name响应

		server
		{
			server_name jump1.myweb.name jump2.myweb.name;
			if ($http_host ~* ^(.*).myweb\.name$)
			{
				rewrite ^(.*) http://jump.myweb.name$1;
				break;
				....
			}
		}
		当访问jump1.myweb.name/reqsource 或jump2.myweb.name/reqsource, URL都将被NGINX重写为 jump.myweb.name/reqsource, 实现了三级域名的跳转

	域名镜像
		镜像网站是指将一个完全相同的网站分别放置到几个服务器上,并分别使用独立的URL,其中一个服务器上的网站叫主站,其他的为镜像网站

		nginx的rewrite功能可以轻松地实现域名镜像的跳转,原理就是在server块中配置rewrite功能,将不同的镜像URL重写到指定的URL就行

		server {
			listen 80;
			server_name mirror1.myweb.name;
			rewrite ^(.*) http://jump1.myweb.name$1 last;
		}

		server {
			listen 80;
			server_name mirror2.myweb.name;
			rewrite ^(.*) http://jump2.myweb.name$1 last;
		}

		不想做整个网站做镜像,只想为某一个子目录下的资源做镜像

		server {
			listen 80;
			server_name jump.myweb.name;
			location ^~ /source1
			{
				rewrite ^/source1(.*) http://jump.myweb.name/websrc2$1 last;
				break;
			}
		}

		独立域名
			当一个网站包含多个板块时,可以为其中的某些板块设置独立域名,原理和子目录镜像一样

			server{
				listen 80;
				server_name bbs.myweb.name;
				rewrite ^(.*) http://www.myweb.name/bbs$1 last;
			}


			server{
				listen 80;
				server_name home.myweb.name;
				rewrite ^(.*) http://www.myweb.name/home$1 last;
			}

		目录自动添加 /
			在访问www.myweb.com 应在浏览器写 www.myweb.com/index.html,若设置了站点首页为index.html，那index.html就可以省略,但如果是二级目录,这样的习惯可能就会无法正常访问,如在访问 www.myweb.com/bbs/index.html时 URL省略为 www.myweb.com/bbs/可以正常访问,但如果是www.myweb.com/bbs  末尾的 / 省略了访问就会出问题, 可以通过设置 自动加 / 解决

			server{
				server_name www.myweb.com;
				location ^~ /bbs
				{
					if (-d $request_filename)     #判断是否存在目录
						rewrite ^/(.*)([^/])$ http://$host/$1$2/ permanet;   #注意[^] 取反
					}
				}
			}

		目录合并
			如要访问 www.myweb.com/server/12/34/56/78/9.htm,这样非常不利于搜索引擎的搜索,可以这样优化

			server{
				server_name www.myweb.com;
				location ^~ /server
				{
					rewrite ^/server-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)-([0-9]+)\.htm$ /server/$1/$2/$3/$4/$5.htm last;
					break
				}
			}
			客户端只要输 www.myweb.com/server-12-34-56-78-9.htm就可以访问到9.html资源文件了,简单优化了不少


		防盗链
			客户端请求网页时,服务器一般不会一次将所有资源完整地传回给客户端.首先会响应传回文本内容,当客户端浏览器在解析文本中发现有图片时,会再次向服务器发起对该图片资源的请求,服务器将存储的图片资源再发送给客户端.这种情况下,服务器并不存储有图片,而是将图片资源链接到别的服务器上,这就是盗链行为.

			要实现防盗链,就要了解HTTP协议中的请求头部,和采用URL的格式表示当前请求的网页或文件的资源地址.通过头域的值,可以检测访问目标资源的源地址,若发现不是自己站点内的URL,就阻止,实现防盗链.(此方法也不是百分百有效,因为头域的值也是可以修改)

			nginx有一个指令valid_referers用来获取Referer头域中的值,并且根据该值的情况给$invalid_refer赋值,如果referers头域中没有符合valid_referers指令的值,$invalid_refer变量将会被赋值为1

			valid_referers none | blocked | server_names | string ....;
				none 检测referer头域不存在的情况
				blocked 检测referer头域的值被防火墙或代理服务器删除或伪装的情况
				server_names 设置一个或多个URL,检测Referer头域的值是否是这些URL的某个,支持通配符 *

			根据请求资源配置

				server {
					...
					server_name www.myweb.com;
					location ~* ^.+\.(gif|jpg|png|swf|flv|rar|zip)$
					{
						....
						valid_referers none blocked server_names *.myweb.com;
						if ($invalid_referer)
						{
							rewrite ^/ http://www.myweb.com/images/forbidden.png;
						}
					}
				}

			根据目录实现防盗链

				server {
					...
					server_name www.myweb.com;
					location /file/
					{
						....
						root /server/file;
						valid_referers none blocked server_names *.myweb.com;
						if ($invalid_referer)
						{
							rewrite ^/ http://www.myweb.com/images/forbidden.png;
						}
					}
				}


nginx 代理服务
	正向代理
		局域网内的客户端通过正向代理访问外部网络,正向代向可以起到一部分防火墙作用,且正向代理机子也可以对局域网内对外网的访问进行监控和管理
		角色是局域网内的机子,目的是访问外网的资源

	反向代理
		局域网内的机子提供WEB服务器等,也可以通过反向代理(Reverse proxy)让internet访问局域内的web服务器
		角色是站点,目的是把站点的资源发布出去让其它客户端访问

nginx正向代理服务配置
	(了解即可,一般用squid做正向代理)
	正向代理服务的指令可以在http, server, location设置,但一般都是在server设置即可

	例子
	server{
		resolver 8.8.8.8;  #必需指令,指定DNS服务器地址
		listen 82;
		location / {
			proxy_pass http://$http_host$request_uri; #自动获取主机和URI的变量
		}
	}

	注意
		不要出现server_name指令
		nginx代理服务器不支持正向代理HTTPS站点
		一般使用上面配置就行,不建议修改,也可以结合缓存提高性能

nginx 反向代理服务配置
	相关的指令也是可以在http, server, location块设置,一般是在server中配置
	指令主要是由ngx_http_proxy_module模块进行解析和处理,标准HTTP模块

	proxy_pass URL;
		设置被代理服务器的地下,可以是主机名称,IP地址加端口号等,也可以是UNIX-DOMAIN套接字路径

		如
		proxy_pass http://www.myweb.name/uri;
		proxy_pass http://localhost:8000/uri/;
		proxy_pass http://unix:/tmp/backend.socket:/uri/;
		传输协议通常是 http 或 https

		如果被代理的是一组服务器,可以使用upstream指令配置后端服务器组，如

			upstream proxy_svrs 
			{
				server http://192.168.1.1:8001/uri/;
				server http://192.168.1.1:8001/uri/;
			}

			server {
				listen 80;
				server_name www.myweb.name;
				location /{
					proxy_pass proxy_srvs;
				}
			}
			注意的是因为在 upstream里有指定 http:// ,所以 proxy_pass 后就不需指明了

			如果 upstream 里的是 server 192.168.1.1:8001/uri/; 那我们就要在proxy里指明 proxy_pass http:/proxy_srvs;
		
		URL中是否包含有URI,nginx处理方式是不同的,如果URL中不包含URI,nginx不会改变原地址的URI,如果URL中包含有URI,nginx会用新的URI替代原来的URI

			server
			{
				server_name www.myweb.name;
				location /server/
				{
				proxy_pass http://192.168.1.1;       # 1
				#proxy_pass http://192.168.1.1/loc/;  #  2
				}
			}
			如果是1的配置,www.myweb.name/server lcation匹配成功后,转向的是 http://192.168.1.1/server
			如果是使用2的配置,www.myweb.name/server 转向的是 http://192.168.1.1/loc/

			所以,在使用proxy_pass时,如果不想改变原地址中的URI,就不要在URL变量中配置URI

		URL 末尾 / 问题
			server{
				server_name www.myweb.name;
				location / {
					proxy_pass http://192.168.1.1;   #  1
					proxy_pass http://192.168.1.1/;  # 2
				}
			}

			location块使用 / 作为uri变量的值,来匹配不包含URI的请求URL,由于请求URL中不包含URI,所以此时配置1与置2的效果是一样的,如 www.myweb.name/index.html

			server{
				server_name www.myweb.name;
				location /server/ {
					proxy_pass http://192.168.1.1;   #  1
					proxy_pass http://192.168.1.1/;  # 2
				}
			}
			此时location的uri变成了/server/,使用配置1的时,proxy_pass中的URL不包含uri,nginx将不改变原地址的URI, 使用配置2时,proxy_pass中包含uri / ,nginx会将原地址的uri改变成 /

			1时 www.myweb.name/server/index.html --> http://192.168.1.1/server/index.html
			2时 www.myweb.name/server/index.html --> http://192.168.1.1/index.html


		proxy_set _header
			更改nginx接收到的客户端请求的请求头信息,然后将新的请求头发送给被代理的服务器

		proxy_redirect
			用于修改被代理服务器返回的响应头中的location头域和refresh头域,与proxy_pass指令配合使用,比如nginx通过proxy_pass指令将客户端的请求地址重写为被代理服务器的地址,那么nginx服务器返回给客户端的响应头中location头域显示的地址就应该和客户端发起请求的地址相对应,
			否则就会出问题

		其它配置使用时再查,先略过


	Proxy Buffer(缓冲) 的配置
		buffer主要用于传输效率不同步或者优先级别不相同的设备之间传递数据,一般通过对一方数据进行临时存放,再统一发送的办法传递给另一方,以降低进程之间的等待时间,保证速较快的进程不发生间断,临时存放的数据一旦传送给另一方,这些数据本身也就没有用处了

		cache主要是将硬盘上已有的数据,在内存中建立缓存数据,提高数据的访问效率,对于过期不用的的缓存可以随时销毁,但不会销毁硬盘上的数据

		buffer相关的指令的配置是针对每一个请求起作用的,不是全局的概念,即每个请求都会按照这些指令的配置来配置各自的buffer,nginx不会生成一个公共的proxy_buffer供代理请求使用

		proxy buffer启用以后,nginx会异步地将被代理服务器的响应数据传递给客户端

		nginx首先尽可能地从被被代理服务器那里接收响应数据放置在proxy buffer中,buffer大小由proxy_bufer_size和proxy_buffers指令决定,如果在接收过程中发现buffer没有足够大小来接收一次响应的数据,nginx会将部分接收到的数据临时存放在硬盘的临时文件中,一次响应数据被接收完成或者buffer已经装满后,nginx开始向客户端传输数据

		每个proxy buffer装满数据后,在从开始和客户端发送一到buffer中的数据全部传完的过程中,它都处理BUSY状态,期间对它进行的其他操作都会失败

		当proxy buffer关闭时,nginx只要接收到响应数据就会同步地传递给客户端,它本身不会读取完整的响应数据

		相关指令略过


	Proxy Cache
		buffer与cache都与代理服务有关,主要用来提供客户端与被代理服务器之间的交互效率

		buffer实现了被代理服务器响应数据的异步传输,cache则实现了nginx服务器对客户端请求的快速响应

		nginx服务器在接收到被代理服务器的响应数据之后,一方面通过buffer把数据传给客户端,另一方面根据cace配置将这些数据缓存到本地硬盘上,当客户端下次要访问相同的数据时,nginx直接从硬盘上检索到相应的数据返回给用户,减少了与被代理服务交互的时间

		proxy cache 依赖于 proxy buffer, 只有buffer开启时cache配置才发挥作用

		nginx还提供了另一种将被代理服务器数据缓存到本地的方法 proxy store , 与cache的区别,它对来自被代理服务器的响应数据,尤其是静态数据只进行简单的缓存,不支持缓存过期更新,内存索引建立等功能,但支持设置用户或用户组对缓存数据的访问权限


		指令
		proxy_cache zone | off;
			用于配置一块公用的区域的名称,该区域可以存放缓存的索引数据
			zone 设置名称
			off 关闭proxy_cache功能,默认设置
			从nginx0.7.66开始,proxy cache机制会检查被代理服务器响应数据HTTP头中的 Cache-control 和 Expire头域,当cache-control的值为 no-cache, no-store , private 或 max-age赋值为0或无意义时,当Expires头域中包含一个过期时间时,该响应数据不会被nginx缓存,这样做的目的是为了防止一些私有数据被其它客户端拿到

		proxy_cache_path
			用于设置nginx存储缓存数据的路径和缓存索引相关的内容
			注意,与其它指令不同,只能在http中设置

		proxy_cache_use_stale
			如果Nginx在访问被代理服务器出现无法访问或错误时,nginx可以使用历史缓存响应客户端的请求,对于更新频率不高的后端服务器来说,该功能在一定程度上能够为客户端提供不间断访问

		proxy_cache_vaild
			针对不同的http响应状态设置不同的缓存时间,如200,302,301状态各缓存多久

		proxy_no_cache
			配置在什么情况下不使用cahce功能

		proxy_store
			配置是否在本地磁盘缓存来自被代理服务的响应数据,nginx提供的另一种缓存数据的方法,相对于cache更简单,它不提供缓存更新,内存索引等功能,不占用内存空间,对静态数据的效果比较好